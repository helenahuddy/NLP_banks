{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import conv\n",
    "#import data_helpers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "#import data_helpers\n",
    "import nltk\n",
    "import word2vec\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from gensim.models import word2vec\n",
    "from tensorflow.contrib import learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data loading params\n",
    "tf.flags.DEFINE_float(\"dev_sample_percentage\", .1, \"Percentage of the training data to use for validation\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 128, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.flags.DEFINE_string(\"filter_sizes\", \"3,4,5\", \"Comma-separated filter sizes (default: '3,4,5')\")\n",
    "tf.flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 128)\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.0, \"L2 regularization lambda (default: 0.0)\")\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 32, \"Batch Size (default: 64)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 20, \"Number of training epochs (default: 200)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 100, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 100, \"Save model after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=32\n",
      "CHECKPOINT_EVERY=100\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=100\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=20\n",
      "NUM_FILTERS=128\n"
     ]
    }
   ],
   "source": [
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning \n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-zа-яА-Я0-9(),:!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_examples = list(open('TREC_all.txt', \"r\").readlines())\n",
    "positive_examples = [s.strip() for s in positive_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"emotional=[]\\nneutral=[]\\nif len(positive_examples)!=len(y_text):\\n    print ('Lengths are not equal')\\nelse:\\n    for i in range (len(y_text)):\\n        if y_text[i]==0:\\n            neutral.append(positive_examples[i])\\n        else:\\n            emotional.append(positive_examples[i])\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"emotional=[]\n",
    "neutral=[]\n",
    "if len(positive_examples)!=len(y_text):\n",
    "    print ('Lengths are not equal')\n",
    "else:\n",
    "    for i in range (len(y_text)):\n",
    "        if y_text[i]==0:\n",
    "            neutral.append(positive_examples[i])\n",
    "        else:\n",
    "            emotional.append(positive_examples[i])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_examples=[clean_str(sent) for sent in positive_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = list(open('label_all.txt', \"r\").readlines())\n",
    "y_text = np.array([[int(re.sub(r\"\\n\", \"\", sent)), 1-int(re.sub(r\"\\n\", \"\", sent))] for sent in labels])\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "max_document_length = max([len(x.split(\" \")) for x in all_examples])\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x_text = np.array(list(vocab_processor.fit_transform(all_examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.preprocessing.text.VocabularyProcessor at 0x11f8f47b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y_text)))\n",
    "x_shuffled = x_text[shuffle_indices]\n",
    "y_shuffled = y_text[shuffle_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_dev = x_shuffled[:-1000], x_shuffled[-1000:]\n",
    "y_train, y_dev = y_shuffled[:-1000], y_shuffled[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = list(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int(data_size/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = (np.array(data))[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\n",
    "                \"W\",\n",
    "                shape=[num_filters_total, num_classes],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # CalculateMean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(tf.argmax(self.scores,1), tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\"cnn = TextCNN(\n",
    "            sequence_length=x_train.shape[1],\n",
    "            num_classes=y_train.shape[1],\n",
    "            vocab_size=len(vocab_processor.vocabulary_),\n",
    "            embedding_size=FLAGS.embedding_dim,\n",
    "            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "            num_filters=FLAGS.num_filters,\n",
    "            l2_reg_lambda=FLAGS.l2_reg_lambda,\n",
    "            )\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /Users/helenahuddy/CNN/runs/1505154151\n",
      "\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "WARNING:tensorflow:From <ipython-input-27-3eb74c8a5497>:48: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "WARNING:tensorflow:From <ipython-input-27-3eb74c8a5497>:51: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "2017-09-11T21:22:33.368259: step 1, loss 0.540964, acc 0.6875\n",
      "2017-09-11T21:22:33.479859: step 2, loss 0.408869, acc 0.78125\n",
      "2017-09-11T21:22:33.569929: step 3, loss 0.707341, acc 0.84375\n",
      "2017-09-11T21:22:33.663227: step 4, loss -0.00210368, acc 0.84375\n",
      "2017-09-11T21:22:33.736869: step 5, loss 0.440023, acc 0.875\n",
      "2017-09-11T21:22:33.813475: step 6, loss 0.462571, acc 0.75\n",
      "2017-09-11T21:22:33.947708: step 7, loss 0.288199, acc 0.84375\n",
      "2017-09-11T21:22:34.093843: step 8, loss -0.809336, acc 0.8125\n",
      "2017-09-11T21:22:34.206348: step 9, loss 0.813685, acc 0.75\n",
      "2017-09-11T21:22:34.285599: step 10, loss -0.200182, acc 0.84375\n",
      "2017-09-11T21:22:34.359581: step 11, loss -0.067299, acc 0.875\n",
      "2017-09-11T21:22:34.450871: step 12, loss -0.316297, acc 0.78125\n",
      "2017-09-11T21:22:34.527505: step 13, loss -1.01592, acc 0.9375\n",
      "2017-09-11T21:22:34.602110: step 14, loss 0.187241, acc 0.875\n",
      "2017-09-11T21:22:34.693064: step 15, loss 0.140608, acc 0.78125\n",
      "2017-09-11T21:22:34.773020: step 16, loss -1.30679, acc 0.875\n",
      "2017-09-11T21:22:34.847766: step 17, loss -1.38935, acc 0.96875\n",
      "2017-09-11T21:22:34.936321: step 18, loss 0.408028, acc 0.84375\n",
      "2017-09-11T21:22:35.057683: step 19, loss -1.83865, acc 0.90625\n",
      "2017-09-11T21:22:35.187974: step 20, loss -1.61071, acc 0.875\n",
      "2017-09-11T21:22:35.309127: step 21, loss 0.851971, acc 0.78125\n",
      "2017-09-11T21:22:35.432004: step 22, loss -1.46526, acc 1\n",
      "2017-09-11T21:22:35.549875: step 23, loss -0.506455, acc 0.90625\n",
      "2017-09-11T21:22:35.626911: step 24, loss -1.14185, acc 0.9375\n",
      "2017-09-11T21:22:35.723887: step 25, loss -1.30427, acc 0.9375\n",
      "2017-09-11T21:22:35.811760: step 26, loss -0.402799, acc 0.96875\n",
      "2017-09-11T21:22:35.898253: step 27, loss -0.717564, acc 0.875\n",
      "2017-09-11T21:22:35.983998: step 28, loss -0.972337, acc 0.90625\n",
      "2017-09-11T21:22:36.060252: step 29, loss -0.50036, acc 0.9375\n",
      "2017-09-11T21:22:36.139086: step 30, loss -1.27344, acc 0.9375\n",
      "2017-09-11T21:22:36.226015: step 31, loss -0.761005, acc 0.90625\n",
      "2017-09-11T21:22:36.303192: step 32, loss -0.532159, acc 0.9375\n",
      "2017-09-11T21:22:36.391629: step 33, loss -1.69064, acc 0.96875\n",
      "2017-09-11T21:22:36.485858: step 34, loss -0.117771, acc 0.9375\n",
      "2017-09-11T21:22:36.566437: step 35, loss -0.989192, acc 0.90625\n",
      "2017-09-11T21:22:36.643738: step 36, loss -2.04064, acc 0.90625\n",
      "2017-09-11T21:22:36.723756: step 37, loss 0.530606, acc 0.84375\n",
      "2017-09-11T21:22:36.797489: step 38, loss -0.258687, acc 0.90625\n",
      "2017-09-11T21:22:36.871900: step 39, loss 0.813033, acc 0.78125\n",
      "2017-09-11T21:22:36.952222: step 40, loss -4.03287, acc 0.96875\n",
      "2017-09-11T21:22:37.028129: step 41, loss -1.4533, acc 1\n",
      "2017-09-11T21:22:37.105089: step 42, loss 0.674384, acc 0.875\n",
      "2017-09-11T21:22:37.196052: step 43, loss -1.14159, acc 0.9375\n",
      "2017-09-11T21:22:37.271709: step 44, loss -1.06409, acc 0.84375\n",
      "2017-09-11T21:22:37.346005: step 45, loss -0.0479281, acc 0.90625\n",
      "2017-09-11T21:22:37.426197: step 46, loss -0.494951, acc 0.9375\n",
      "2017-09-11T21:22:37.501017: step 47, loss -1.5623, acc 1\n",
      "2017-09-11T21:22:37.578310: step 48, loss -0.942973, acc 0.9375\n",
      "2017-09-11T21:22:37.656704: step 49, loss -0.299539, acc 0.875\n",
      "2017-09-11T21:22:37.731389: step 50, loss 0.236861, acc 0.875\n",
      "2017-09-11T21:22:37.805513: step 51, loss -1.29587, acc 1\n",
      "2017-09-11T21:22:37.891576: step 52, loss -0.129405, acc 1\n",
      "2017-09-11T21:22:37.990121: step 53, loss -0.603606, acc 0.90625\n",
      "2017-09-11T21:22:38.075606: step 54, loss -2.56121, acc 0.9375\n",
      "2017-09-11T21:22:38.165853: step 55, loss -1.93662, acc 0.875\n",
      "2017-09-11T21:22:38.255904: step 56, loss -2.25681, acc 0.96875\n",
      "2017-09-11T21:22:38.332946: step 57, loss -2.3798, acc 1\n",
      "2017-09-11T21:22:38.414049: step 58, loss -1.46738, acc 0.90625\n",
      "2017-09-11T21:22:38.504774: step 59, loss -0.508604, acc 0.90625\n",
      "2017-09-11T21:22:38.631758: step 60, loss -2.18337, acc 0.90625\n",
      "2017-09-11T21:22:38.735431: step 61, loss -1.72336, acc 0.90625\n",
      "2017-09-11T21:22:38.824761: step 62, loss 0.359703, acc 0.96875\n",
      "2017-09-11T21:22:38.906190: step 63, loss -0.0556781, acc 0.90625\n",
      "2017-09-11T21:22:38.981450: step 64, loss -2.53728, acc 0.96875\n",
      "2017-09-11T21:22:39.057819: step 65, loss -2.72505, acc 0.96875\n",
      "2017-09-11T21:22:39.182691: step 66, loss -2.37455, acc 0.96875\n",
      "2017-09-11T21:22:39.304595: step 67, loss -1.5116, acc 0.90625\n",
      "2017-09-11T21:22:39.428682: step 68, loss -0.81505, acc 0.84375\n",
      "2017-09-11T21:22:39.531072: step 69, loss -3.74423, acc 1\n",
      "2017-09-11T21:22:39.626577: step 70, loss -0.910775, acc 0.9375\n",
      "2017-09-11T21:22:39.748782: step 71, loss -0.94935, acc 0.875\n",
      "2017-09-11T21:22:39.849820: step 72, loss -1.97436, acc 0.9375\n",
      "2017-09-11T21:22:39.943033: step 73, loss -5.17182, acc 0.96875\n",
      "2017-09-11T21:22:40.084056: step 74, loss -3.2585, acc 0.96875\n",
      "2017-09-11T21:22:40.218077: step 75, loss -1.86748, acc 1\n",
      "2017-09-11T21:22:40.347862: step 76, loss -2.11971, acc 1\n",
      "2017-09-11T21:22:40.460319: step 77, loss -1.91469, acc 0.90625\n",
      "2017-09-11T21:22:40.588690: step 78, loss -0.120159, acc 0.875\n",
      "2017-09-11T21:22:40.723706: step 79, loss -4.12864, acc 0.90625\n",
      "2017-09-11T21:22:40.813021: step 80, loss -2.87721, acc 0.9375\n",
      "2017-09-11T21:22:40.897456: step 81, loss -3.31649, acc 0.96875\n",
      "2017-09-11T21:22:40.970453: step 82, loss -2.40522, acc 0.90625\n",
      "2017-09-11T21:22:41.110729: step 83, loss -1.87139, acc 1\n",
      "2017-09-11T21:22:41.214141: step 84, loss -4.72641, acc 1\n",
      "2017-09-11T21:22:41.325426: step 85, loss -3.03763, acc 1\n",
      "2017-09-11T21:22:41.427472: step 86, loss -3.64818, acc 1\n",
      "2017-09-11T21:22:41.516936: step 87, loss 1.12222, acc 0.875\n",
      "2017-09-11T21:22:41.629918: step 88, loss -2.73543, acc 0.96875\n",
      "2017-09-11T21:22:41.737180: step 89, loss -4.5616, acc 0.9375\n",
      "2017-09-11T21:22:41.828290: step 90, loss -3.23474, acc 1\n",
      "2017-09-11T21:22:41.926515: step 91, loss -2.41445, acc 0.96875\n",
      "2017-09-11T21:22:42.008817: step 92, loss 0.777436, acc 0.8125\n",
      "2017-09-11T21:22:42.090464: step 93, loss -2.9283, acc 0.875\n",
      "2017-09-11T21:22:42.187147: step 94, loss -1.24941, acc 0.9375\n",
      "2017-09-11T21:22:42.283138: step 95, loss -0.499613, acc 0.96875\n",
      "2017-09-11T21:22:42.376393: step 96, loss -7.93105, acc 1\n",
      "2017-09-11T21:22:42.461324: step 97, loss -2.99232, acc 0.9375\n",
      "2017-09-11T21:22:42.538288: step 98, loss -2.33299, acc 0.9375\n",
      "2017-09-11T21:22:42.630367: step 99, loss -5.35101, acc 0.9375\n",
      "2017-09-11T21:22:42.725641: step 100, loss -0.470888, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:22:43.802092: step 100, loss -2.64352, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-100\n",
      "\n",
      "2017-09-11T21:22:44.895570: step 101, loss -0.238771, acc 0.90625\n",
      "2017-09-11T21:22:44.981088: step 102, loss -4.50334, acc 0.90625\n",
      "2017-09-11T21:22:45.069394: step 103, loss 0.144613, acc 0.84375\n",
      "2017-09-11T21:22:45.153245: step 104, loss -0.442667, acc 0.9375\n",
      "2017-09-11T21:22:45.232818: step 105, loss -1.34019, acc 0.90625\n",
      "2017-09-11T21:22:45.310192: step 106, loss 0.665473, acc 0.875\n",
      "2017-09-11T21:22:45.384577: step 107, loss -4.05764, acc 0.9375\n",
      "2017-09-11T21:22:45.460337: step 108, loss 0.534564, acc 0.90625\n",
      "2017-09-11T21:22:45.536997: step 109, loss -0.448992, acc 0.9375\n",
      "2017-09-11T21:22:45.614240: step 110, loss -2.51637, acc 0.9375\n",
      "2017-09-11T21:22:45.689292: step 111, loss -2.7913, acc 0.9375\n",
      "2017-09-11T21:22:45.775091: step 112, loss 0.237549, acc 0.875\n",
      "2017-09-11T21:22:45.853413: step 113, loss -4.13987, acc 0.96875\n",
      "2017-09-11T21:22:45.932526: step 114, loss -1.1011, acc 0.96875\n",
      "2017-09-11T21:22:46.011249: step 115, loss -4.01459, acc 0.875\n",
      "2017-09-11T21:22:46.089630: step 116, loss -7.7393, acc 0.9375\n",
      "2017-09-11T21:22:46.166671: step 117, loss -2.5847, acc 0.90625\n",
      "2017-09-11T21:22:46.246174: step 118, loss -0.0559197, acc 0.90625\n",
      "2017-09-11T21:22:46.327677: step 119, loss -4.47426, acc 0.96875\n",
      "2017-09-11T21:22:46.411526: step 120, loss -0.471413, acc 0.9375\n",
      "2017-09-11T21:22:46.488996: step 121, loss -3.8632, acc 0.9375\n",
      "2017-09-11T21:22:46.571766: step 122, loss -4.90607, acc 0.90625\n",
      "2017-09-11T21:22:46.657494: step 123, loss -1.2463, acc 0.96875\n",
      "2017-09-11T21:22:46.746936: step 124, loss -4.40271, acc 0.9375\n",
      "2017-09-11T21:22:46.822011: step 125, loss -5.44863, acc 0.96875\n",
      "2017-09-11T21:22:46.900665: step 126, loss -2.03735, acc 0.875\n",
      "2017-09-11T21:22:46.988634: step 127, loss -3.9899, acc 0.96875\n",
      "2017-09-11T21:22:47.091369: step 128, loss 1.57594, acc 0.90625\n",
      "2017-09-11T21:22:47.168283: step 129, loss -2.3581, acc 0.9375\n",
      "2017-09-11T21:22:47.245454: step 130, loss -5.36145, acc 0.90625\n",
      "2017-09-11T21:22:47.334289: step 131, loss -4.7566, acc 0.96875\n",
      "2017-09-11T21:22:47.425232: step 132, loss -2.96533, acc 0.9375\n",
      "2017-09-11T21:22:47.511897: step 133, loss -2.28421, acc 0.9375\n",
      "2017-09-11T21:22:47.588032: step 134, loss -2.4769, acc 0.875\n",
      "2017-09-11T21:22:47.665424: step 135, loss -3.73931, acc 0.875\n",
      "2017-09-11T21:22:47.750194: step 136, loss -4.52869, acc 0.875\n",
      "2017-09-11T21:22:47.829158: step 137, loss 2.20201, acc 0.84375\n",
      "2017-09-11T21:22:47.906928: step 138, loss 0.362594, acc 0.90625\n",
      "2017-09-11T21:22:47.983943: step 139, loss -5.1335, acc 0.90625\n",
      "2017-09-11T21:22:48.059162: step 140, loss -3.87988, acc 0.96875\n",
      "2017-09-11T21:22:48.133345: step 141, loss -6.91107, acc 0.96875\n",
      "2017-09-11T21:22:48.210609: step 142, loss -2.34011, acc 0.9375\n",
      "2017-09-11T21:22:48.283204: step 143, loss -7.73562, acc 0.96875\n",
      "2017-09-11T21:22:48.357497: step 144, loss -3.67921, acc 0.9375\n",
      "2017-09-11T21:22:48.433005: step 145, loss -5.30685, acc 0.9375\n",
      "2017-09-11T21:22:48.508903: step 146, loss -5.69492, acc 0.90625\n",
      "2017-09-11T21:22:48.583625: step 147, loss 0.00562358, acc 0.84375\n",
      "2017-09-11T21:22:48.658938: step 148, loss -4.1378, acc 0.9375\n",
      "2017-09-11T21:22:48.732460: step 149, loss -2.78431, acc 0.875\n",
      "2017-09-11T21:22:48.807021: step 150, loss -0.872948, acc 0.84375\n",
      "2017-09-11T21:22:48.896730: step 151, loss 1.8568, acc 0.84375\n",
      "2017-09-11T21:22:48.973771: step 152, loss -4.97434, acc 1\n",
      "2017-09-11T21:22:49.060458: step 153, loss -1.01979, acc 0.90625\n",
      "2017-09-11T21:22:49.148318: step 154, loss -6.85579, acc 0.90625\n",
      "2017-09-11T21:22:49.221891: step 155, loss -2.7469, acc 0.90625\n",
      "2017-09-11T21:22:49.297178: step 156, loss -1.47517, acc 0.90625\n",
      "2017-09-11T21:22:49.382856: step 157, loss -5.25257, acc 1\n",
      "2017-09-11T21:22:49.470606: step 158, loss -2.72759, acc 0.875\n",
      "2017-09-11T21:22:49.556654: step 159, loss -2.06166, acc 0.875\n",
      "2017-09-11T21:22:49.645182: step 160, loss 0.0804012, acc 0.8125\n",
      "2017-09-11T21:22:49.729783: step 161, loss -0.128222, acc 0.90625\n",
      "2017-09-11T21:22:49.808514: step 162, loss -5.7503, acc 0.9375\n",
      "2017-09-11T21:22:49.898654: step 163, loss -4.7984, acc 0.9375\n",
      "2017-09-11T21:22:49.984790: step 164, loss -5.59477, acc 0.9375\n",
      "2017-09-11T21:22:50.068006: step 165, loss -6.65945, acc 0.875\n",
      "2017-09-11T21:22:50.147618: step 166, loss -5.97017, acc 0.90625\n",
      "2017-09-11T21:22:50.221562: step 167, loss -3.1015, acc 0.9375\n",
      "2017-09-11T21:22:50.295877: step 168, loss -5.24156, acc 0.90625\n",
      "2017-09-11T21:22:50.381385: step 169, loss -1.50949, acc 0.9375\n",
      "2017-09-11T21:22:50.474928: step 170, loss -10.8764, acc 1\n",
      "2017-09-11T21:22:50.562460: step 171, loss -6.30337, acc 0.96875\n",
      "2017-09-11T21:22:50.637812: step 172, loss -5.15602, acc 0.875\n",
      "2017-09-11T21:22:50.712860: step 173, loss -4.12898, acc 0.9375\n",
      "2017-09-11T21:22:50.793473: step 174, loss -2.03008, acc 0.90625\n",
      "2017-09-11T21:22:50.883826: step 175, loss -13.1661, acc 0.96875\n",
      "2017-09-11T21:22:50.959598: step 176, loss -4.47997, acc 0.9375\n",
      "2017-09-11T21:22:51.033314: step 177, loss -3.31211, acc 0.9375\n",
      "2017-09-11T21:22:51.110587: step 178, loss -0.928074, acc 0.96875\n",
      "2017-09-11T21:22:51.195255: step 179, loss 0.407196, acc 0.90625\n",
      "2017-09-11T21:22:51.276044: step 180, loss -3.51298, acc 0.96875\n",
      "2017-09-11T21:22:51.354920: step 181, loss 0.347904, acc 0.9375\n",
      "2017-09-11T21:22:51.432604: step 182, loss -6.08096, acc 0.96875\n",
      "2017-09-11T21:22:51.506098: step 183, loss -8.13572, acc 0.96875\n",
      "2017-09-11T21:22:51.590279: step 184, loss -1.00212, acc 0.90625\n",
      "2017-09-11T21:22:51.676682: step 185, loss -3.03412, acc 0.9375\n",
      "2017-09-11T21:22:51.760307: step 186, loss -3.65397, acc 0.84375\n",
      "2017-09-11T21:22:51.843482: step 187, loss -7.66367, acc 0.9375\n",
      "2017-09-11T21:22:51.928689: step 188, loss -4.3425, acc 0.9375\n",
      "2017-09-11T21:22:52.013093: step 189, loss 2.6214, acc 0.84375\n",
      "2017-09-11T21:22:52.102391: step 190, loss -9.55302, acc 0.96875\n",
      "2017-09-11T21:22:52.182218: step 191, loss -7.23794, acc 0.9375\n",
      "2017-09-11T21:22:52.265415: step 192, loss -9.4226, acc 0.9375\n",
      "2017-09-11T21:22:52.350167: step 193, loss -3.49639, acc 0.96875\n",
      "2017-09-11T21:22:52.429518: step 194, loss -3.38649, acc 0.875\n",
      "2017-09-11T21:22:52.510738: step 195, loss -7.11305, acc 0.9375\n",
      "2017-09-11T21:22:52.589815: step 196, loss -4.928, acc 0.9375\n",
      "2017-09-11T21:22:52.672793: step 197, loss -8.18231, acc 0.90625\n",
      "2017-09-11T21:22:52.748789: step 198, loss -1.68498, acc 0.84375\n",
      "2017-09-11T21:22:52.842172: step 199, loss 3.90858, acc 0.8125\n",
      "2017-09-11T21:22:52.941087: step 200, loss 0.426531, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:22:53.652442: step 200, loss -5.62372, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-200\n",
      "\n",
      "2017-09-11T21:22:54.493735: step 201, loss -8.55464, acc 0.9375\n",
      "2017-09-11T21:22:54.589118: step 202, loss -2.79399, acc 0.90625\n",
      "2017-09-11T21:22:54.667747: step 203, loss -4.24003, acc 0.875\n",
      "2017-09-11T21:22:54.767160: step 204, loss 0.403975, acc 0.8125\n",
      "2017-09-11T21:22:54.875920: step 205, loss -11.8194, acc 0.96875\n",
      "2017-09-11T21:22:54.970437: step 206, loss -9.59986, acc 0.9375\n",
      "2017-09-11T21:22:55.055853: step 207, loss -4.16467, acc 0.9375\n",
      "2017-09-11T21:22:55.142272: step 208, loss 2.10704, acc 0.8125\n",
      "2017-09-11T21:22:55.227748: step 209, loss -0.54002, acc 0.875\n",
      "2017-09-11T21:22:55.313205: step 210, loss -6.46497, acc 0.90625\n",
      "2017-09-11T21:22:55.403014: step 211, loss -1.14125, acc 0.9375\n",
      "2017-09-11T21:22:55.521204: step 212, loss 0.665538, acc 0.90625\n",
      "2017-09-11T21:22:55.612229: step 213, loss -3.32589, acc 0.9375\n",
      "2017-09-11T21:22:55.694054: step 214, loss -6.81189, acc 0.90625\n",
      "2017-09-11T21:22:55.776243: step 215, loss -0.217225, acc 0.9375\n",
      "2017-09-11T21:22:55.882760: step 216, loss -3.37918, acc 0.9375\n",
      "2017-09-11T21:22:55.984791: step 217, loss -6.03409, acc 0.96875\n",
      "2017-09-11T21:22:56.082384: step 218, loss -4.95671, acc 0.96875\n",
      "2017-09-11T21:22:56.178732: step 219, loss 0.567474, acc 0.90625\n",
      "2017-09-11T21:22:56.260421: step 220, loss -8.75442, acc 0.9375\n",
      "2017-09-11T21:22:56.341667: step 221, loss -6.28562, acc 0.875\n",
      "2017-09-11T21:22:56.432156: step 222, loss -9.81585, acc 0.96875\n",
      "2017-09-11T21:22:56.531011: step 223, loss 2.75857, acc 0.84375\n",
      "2017-09-11T21:22:56.607266: step 224, loss -7.84213, acc 0.96875\n",
      "2017-09-11T21:22:56.687267: step 225, loss -10.2934, acc 0.90625\n",
      "2017-09-11T21:22:56.777108: step 226, loss -11.8645, acc 0.9375\n",
      "2017-09-11T21:22:56.856044: step 227, loss -7.94881, acc 0.9375\n",
      "2017-09-11T21:22:56.938554: step 228, loss -15.5385, acc 1\n",
      "2017-09-11T21:22:57.053673: step 229, loss -8.54528, acc 1\n",
      "2017-09-11T21:22:57.134581: step 230, loss -9.1635, acc 0.96875\n",
      "2017-09-11T21:22:57.250708: step 231, loss -10.3587, acc 0.96875\n",
      "2017-09-11T21:22:57.368103: step 232, loss -5.9181, acc 0.875\n",
      "2017-09-11T21:22:57.452839: step 233, loss -0.861906, acc 0.9375\n",
      "2017-09-11T21:22:57.551153: step 234, loss -8.20086, acc 0.96875\n",
      "2017-09-11T21:22:57.648494: step 235, loss -6.40064, acc 0.9375\n",
      "2017-09-11T21:22:57.762669: step 236, loss -8.18883, acc 0.9375\n",
      "2017-09-11T21:22:57.874545: step 237, loss -10.7948, acc 0.9375\n",
      "2017-09-11T21:22:57.985246: step 238, loss -5.74667, acc 0.90625\n",
      "2017-09-11T21:22:58.101396: step 239, loss -4.96616, acc 0.9375\n",
      "2017-09-11T21:22:58.224036: step 240, loss -7.06978, acc 0.96875\n",
      "2017-09-11T21:22:58.352912: step 241, loss -13.1764, acc 0.96875\n",
      "2017-09-11T21:22:58.451386: step 242, loss -8.00034, acc 0.90625\n",
      "2017-09-11T21:22:58.541699: step 243, loss 1.04239, acc 0.84375\n",
      "2017-09-11T21:22:58.652794: step 244, loss -5.37335, acc 0.9375\n",
      "2017-09-11T21:22:58.746072: step 245, loss -15.1254, acc 0.9375\n",
      "2017-09-11T21:22:58.834442: step 246, loss -4.27889, acc 0.875\n",
      "2017-09-11T21:22:58.952308: step 247, loss -7.83714, acc 0.90625\n",
      "2017-09-11T21:22:59.043575: step 248, loss -9.40919, acc 1\n",
      "2017-09-11T21:22:59.209778: step 249, loss -9.85232, acc 0.96875\n",
      "2017-09-11T21:22:59.323998: step 250, loss -3.45319, acc 0.875\n",
      "2017-09-11T21:22:59.429852: step 251, loss -15.6909, acc 0.96875\n",
      "2017-09-11T21:22:59.525226: step 252, loss -7.23831, acc 0.9375\n",
      "2017-09-11T21:22:59.620171: step 253, loss -1.91385, acc 0.96875\n",
      "2017-09-11T21:22:59.726965: step 254, loss -2.63066, acc 0.875\n",
      "2017-09-11T21:22:59.843198: step 255, loss -3.57867, acc 0.875\n",
      "2017-09-11T21:23:00.002153: step 256, loss -5.52561, acc 0.96875\n",
      "2017-09-11T21:23:00.096379: step 257, loss -3.36266, acc 0.875\n",
      "2017-09-11T21:23:00.180326: step 258, loss -12.1499, acc 0.96875\n",
      "2017-09-11T21:23:00.261533: step 259, loss -14.6429, acc 1\n",
      "2017-09-11T21:23:00.355598: step 260, loss -6.68641, acc 0.875\n",
      "2017-09-11T21:23:00.455511: step 261, loss 0.0940685, acc 0.90625\n",
      "2017-09-11T21:23:00.551158: step 262, loss 4.96427, acc 0.8125\n",
      "2017-09-11T21:23:00.590629: step 263, loss -6.68178, acc 1\n",
      "2017-09-11T21:23:00.703159: step 264, loss 0.431047, acc 0.875\n",
      "2017-09-11T21:23:00.794102: step 265, loss -1.47192, acc 0.9375\n",
      "2017-09-11T21:23:00.876868: step 266, loss 0.757313, acc 0.9375\n",
      "2017-09-11T21:23:00.957793: step 267, loss -6.44117, acc 0.96875\n",
      "2017-09-11T21:23:01.046725: step 268, loss -10.7158, acc 0.96875\n",
      "2017-09-11T21:23:01.127864: step 269, loss -8.94341, acc 0.9375\n",
      "2017-09-11T21:23:01.215956: step 270, loss -16.785, acc 1\n",
      "2017-09-11T21:23:01.307344: step 271, loss -6.63741, acc 0.96875\n",
      "2017-09-11T21:23:01.405729: step 272, loss -11.9367, acc 0.90625\n",
      "2017-09-11T21:23:01.498023: step 273, loss 2.2754, acc 0.90625\n",
      "2017-09-11T21:23:01.600887: step 274, loss -4.45234, acc 0.9375\n",
      "2017-09-11T21:23:01.714840: step 275, loss -6.08572, acc 0.9375\n",
      "2017-09-11T21:23:01.839813: step 276, loss -10.2444, acc 0.9375\n",
      "2017-09-11T21:23:01.943683: step 277, loss -9.8281, acc 0.9375\n",
      "2017-09-11T21:23:02.028898: step 278, loss -3.55924, acc 0.90625\n",
      "2017-09-11T21:23:02.120085: step 279, loss -15.2782, acc 0.9375\n",
      "2017-09-11T21:23:02.210842: step 280, loss -7.23197, acc 0.9375\n",
      "2017-09-11T21:23:02.307040: step 281, loss -15.1874, acc 0.9375\n",
      "2017-09-11T21:23:02.423368: step 282, loss -17.668, acc 1\n",
      "2017-09-11T21:23:02.509680: step 283, loss -11.1352, acc 0.9375\n",
      "2017-09-11T21:23:02.590463: step 284, loss -17.4888, acc 1\n",
      "2017-09-11T21:23:02.674217: step 285, loss -14.3097, acc 0.90625\n",
      "2017-09-11T21:23:02.757184: step 286, loss -12.3088, acc 0.9375\n",
      "2017-09-11T21:23:02.837242: step 287, loss -8.81836, acc 0.90625\n",
      "2017-09-11T21:23:02.917629: step 288, loss -10.1871, acc 0.96875\n",
      "2017-09-11T21:23:03.003681: step 289, loss -16.1053, acc 0.90625\n",
      "2017-09-11T21:23:03.081602: step 290, loss -5.82528, acc 0.90625\n",
      "2017-09-11T21:23:03.167055: step 291, loss -7.05132, acc 0.9375\n",
      "2017-09-11T21:23:03.263965: step 292, loss -11.6643, acc 0.90625\n",
      "2017-09-11T21:23:03.342008: step 293, loss -14.5386, acc 0.96875\n",
      "2017-09-11T21:23:03.424633: step 294, loss -9.6686, acc 1\n",
      "2017-09-11T21:23:03.511287: step 295, loss -12.4829, acc 0.90625\n",
      "2017-09-11T21:23:03.589929: step 296, loss -3.43439, acc 0.9375\n",
      "2017-09-11T21:23:03.668295: step 297, loss -12.1062, acc 1\n",
      "2017-09-11T21:23:03.748638: step 298, loss -10.3188, acc 0.96875\n",
      "2017-09-11T21:23:03.844955: step 299, loss -18.4229, acc 0.875\n",
      "2017-09-11T21:23:03.947699: step 300, loss -6.51278, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:23:04.933157: step 300, loss -10.2607, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-300\n",
      "\n",
      "2017-09-11T21:23:06.061816: step 301, loss -13.3586, acc 0.9375\n",
      "2017-09-11T21:23:06.141910: step 302, loss -8.08033, acc 0.96875\n",
      "2017-09-11T21:23:06.225281: step 303, loss -10.1038, acc 0.9375\n",
      "2017-09-11T21:23:06.302961: step 304, loss -8.30248, acc 0.90625\n",
      "2017-09-11T21:23:06.381146: step 305, loss -10.6669, acc 0.9375\n",
      "2017-09-11T21:23:06.468829: step 306, loss -13.9937, acc 0.96875\n",
      "2017-09-11T21:23:06.560500: step 307, loss -5.54715, acc 0.9375\n",
      "2017-09-11T21:23:06.642107: step 308, loss -4.77515, acc 0.9375\n",
      "2017-09-11T21:23:06.736672: step 309, loss -3.04306, acc 0.90625\n",
      "2017-09-11T21:23:06.826538: step 310, loss 7.71899, acc 0.78125\n",
      "2017-09-11T21:23:06.914072: step 311, loss -3.73755, acc 0.84375\n",
      "2017-09-11T21:23:06.997990: step 312, loss -17.2943, acc 0.90625\n",
      "2017-09-11T21:23:07.079170: step 313, loss 0.426107, acc 0.875\n",
      "2017-09-11T21:23:07.163702: step 314, loss -8.75322, acc 0.9375\n",
      "2017-09-11T21:23:07.250513: step 315, loss -10.9911, acc 0.90625\n",
      "2017-09-11T21:23:07.330028: step 316, loss -14.1397, acc 0.9375\n",
      "2017-09-11T21:23:07.408556: step 317, loss -12.7233, acc 0.9375\n",
      "2017-09-11T21:23:07.493365: step 318, loss -31.1372, acc 1\n",
      "2017-09-11T21:23:07.573700: step 319, loss -13.626, acc 0.96875\n",
      "2017-09-11T21:23:07.656805: step 320, loss -11.6255, acc 0.9375\n",
      "2017-09-11T21:23:07.749496: step 321, loss -19.9749, acc 0.9375\n",
      "2017-09-11T21:23:07.831658: step 322, loss -0.805261, acc 0.8125\n",
      "2017-09-11T21:23:07.909493: step 323, loss -8.18279, acc 0.96875\n",
      "2017-09-11T21:23:07.991913: step 324, loss -14.1931, acc 0.90625\n",
      "2017-09-11T21:23:08.068474: step 325, loss -12.5132, acc 0.90625\n",
      "2017-09-11T21:23:08.147924: step 326, loss 3.79999, acc 0.90625\n",
      "2017-09-11T21:23:08.230093: step 327, loss -5.3219, acc 0.96875\n",
      "2017-09-11T21:23:08.309254: step 328, loss -0.095484, acc 0.84375\n",
      "2017-09-11T21:23:08.386288: step 329, loss -21.4584, acc 0.875\n",
      "2017-09-11T21:23:08.467729: step 330, loss -2.39517, acc 0.9375\n",
      "2017-09-11T21:23:08.552683: step 331, loss -6.42364, acc 0.84375\n",
      "2017-09-11T21:23:08.642793: step 332, loss -0.554132, acc 0.9375\n",
      "2017-09-11T21:23:08.724862: step 333, loss -31.0214, acc 1\n",
      "2017-09-11T21:23:08.803887: step 334, loss -2.80058, acc 0.84375\n",
      "2017-09-11T21:23:08.882267: step 335, loss -0.616348, acc 0.90625\n",
      "2017-09-11T21:23:08.966838: step 336, loss 2.83265, acc 0.9375\n",
      "2017-09-11T21:23:09.044769: step 337, loss -0.0430768, acc 0.84375\n",
      "2017-09-11T21:23:09.122663: step 338, loss -10.2817, acc 0.90625\n",
      "2017-09-11T21:23:09.205498: step 339, loss -19.1527, acc 0.96875\n",
      "2017-09-11T21:23:09.286615: step 340, loss -6.61718, acc 0.84375\n",
      "2017-09-11T21:23:09.367638: step 341, loss -8.61457, acc 0.9375\n",
      "2017-09-11T21:23:09.452713: step 342, loss -16.2263, acc 0.9375\n",
      "2017-09-11T21:23:09.532662: step 343, loss -15.5958, acc 0.96875\n",
      "2017-09-11T21:23:09.612514: step 344, loss -1.48586, acc 0.875\n",
      "2017-09-11T21:23:09.697917: step 345, loss -4.45865, acc 0.84375\n",
      "2017-09-11T21:23:09.777223: step 346, loss -13.079, acc 0.9375\n",
      "2017-09-11T21:23:09.854823: step 347, loss -4.91428, acc 0.875\n",
      "2017-09-11T21:23:09.935871: step 348, loss -12.1328, acc 0.96875\n",
      "2017-09-11T21:23:10.013005: step 349, loss -10.1911, acc 0.9375\n",
      "2017-09-11T21:23:10.089988: step 350, loss -15.6642, acc 0.875\n",
      "2017-09-11T21:23:10.216102: step 351, loss -9.9577, acc 0.96875\n",
      "2017-09-11T21:23:10.307026: step 352, loss -16.8858, acc 0.9375\n",
      "2017-09-11T21:23:10.411982: step 353, loss -12.4157, acc 0.875\n",
      "2017-09-11T21:23:10.507734: step 354, loss -4.48995, acc 0.875\n",
      "2017-09-11T21:23:10.611061: step 355, loss -4.26901, acc 0.90625\n",
      "2017-09-11T21:23:10.710319: step 356, loss -0.593492, acc 0.84375\n",
      "2017-09-11T21:23:10.801699: step 357, loss -13.5483, acc 0.90625\n",
      "2017-09-11T21:23:10.889458: step 358, loss -6.23696, acc 0.875\n",
      "2017-09-11T21:23:10.974750: step 359, loss -2.41437, acc 0.90625\n",
      "2017-09-11T21:23:11.056148: step 360, loss -13.2487, acc 0.9375\n",
      "2017-09-11T21:23:11.136334: step 361, loss -15.118, acc 0.90625\n",
      "2017-09-11T21:23:11.233157: step 362, loss -8.49212, acc 0.875\n",
      "2017-09-11T21:23:11.312325: step 363, loss -10.8032, acc 0.9375\n",
      "2017-09-11T21:23:11.396284: step 364, loss -22.7884, acc 0.9375\n",
      "2017-09-11T21:23:11.480476: step 365, loss -3.02072, acc 0.84375\n",
      "2017-09-11T21:23:11.558846: step 366, loss -5.70826, acc 0.9375\n",
      "2017-09-11T21:23:11.638539: step 367, loss -11.8672, acc 0.875\n",
      "2017-09-11T21:23:11.725436: step 368, loss -10.2223, acc 0.875\n",
      "2017-09-11T21:23:11.807304: step 369, loss -11.9665, acc 0.90625\n",
      "2017-09-11T21:23:11.887852: step 370, loss -6.21988, acc 0.875\n",
      "2017-09-11T21:23:11.975467: step 371, loss -28.8766, acc 0.9375\n",
      "2017-09-11T21:23:12.056794: step 372, loss -24.2416, acc 0.9375\n",
      "2017-09-11T21:23:12.136812: step 373, loss 3.05442, acc 0.875\n",
      "2017-09-11T21:23:12.217264: step 374, loss 3.27291, acc 0.90625\n",
      "2017-09-11T21:23:12.295725: step 375, loss 4.39233, acc 0.84375\n",
      "2017-09-11T21:23:12.373604: step 376, loss -6.29677, acc 0.9375\n",
      "2017-09-11T21:23:12.461851: step 377, loss -7.45375, acc 0.9375\n",
      "2017-09-11T21:23:12.549786: step 378, loss -18.583, acc 0.9375\n",
      "2017-09-11T21:23:12.627783: step 379, loss -12.7305, acc 0.90625\n",
      "2017-09-11T21:23:12.711508: step 380, loss -11.4926, acc 0.96875\n",
      "2017-09-11T21:23:12.791418: step 381, loss 6.65189, acc 0.84375\n",
      "2017-09-11T21:23:12.875909: step 382, loss -5.83828, acc 0.875\n",
      "2017-09-11T21:23:12.959563: step 383, loss -13.203, acc 0.90625\n",
      "2017-09-11T21:23:13.040186: step 384, loss 4.17528, acc 0.84375\n",
      "2017-09-11T21:23:13.119584: step 385, loss -43.2746, acc 0.96875\n",
      "2017-09-11T21:23:13.202074: step 386, loss -31.6267, acc 0.96875\n",
      "2017-09-11T21:23:13.281267: step 387, loss 15.4241, acc 0.84375\n",
      "2017-09-11T21:23:13.362326: step 388, loss -17.9107, acc 0.9375\n",
      "2017-09-11T21:23:13.445217: step 389, loss -24.2283, acc 0.96875\n",
      "2017-09-11T21:23:13.527619: step 390, loss -23.6907, acc 0.9375\n",
      "2017-09-11T21:23:13.608325: step 391, loss -24.858, acc 0.90625\n",
      "2017-09-11T21:23:13.691316: step 392, loss -35.1712, acc 1\n",
      "2017-09-11T21:23:13.770605: step 393, loss -23.1847, acc 1\n",
      "2017-09-11T21:23:13.861529: step 394, loss -16.2722, acc 0.875\n",
      "2017-09-11T21:23:13.954773: step 395, loss -14.5842, acc 0.9375\n",
      "2017-09-11T21:23:14.035377: step 396, loss -18.4487, acc 0.875\n",
      "2017-09-11T21:23:14.114233: step 397, loss -8.20856, acc 0.96875\n",
      "2017-09-11T21:23:14.199770: step 398, loss -9.22225, acc 0.96875\n",
      "2017-09-11T21:23:14.284416: step 399, loss -22.2466, acc 0.9375\n",
      "2017-09-11T21:23:14.362131: step 400, loss -26.43, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:23:15.379206: step 400, loss -16.1448, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-400\n",
      "\n",
      "2017-09-11T21:23:16.493936: step 401, loss -25.3028, acc 0.96875\n",
      "2017-09-11T21:23:16.575700: step 402, loss -12.3734, acc 0.96875\n",
      "2017-09-11T21:23:16.666698: step 403, loss -1.33466, acc 0.9375\n",
      "2017-09-11T21:23:16.752613: step 404, loss -32.7211, acc 1\n",
      "2017-09-11T21:23:16.843396: step 405, loss -1.60533, acc 0.875\n",
      "2017-09-11T21:23:16.929833: step 406, loss -20.0808, acc 0.96875\n",
      "2017-09-11T21:23:17.017828: step 407, loss -41.4371, acc 0.96875\n",
      "2017-09-11T21:23:17.104403: step 408, loss -45.0312, acc 0.96875\n",
      "2017-09-11T21:23:17.195333: step 409, loss -18.484, acc 0.90625\n",
      "2017-09-11T21:23:17.280473: step 410, loss 3.69395, acc 0.84375\n",
      "2017-09-11T21:23:17.365115: step 411, loss -28.2584, acc 1\n",
      "2017-09-11T21:23:17.453826: step 412, loss -0.0881042, acc 0.875\n",
      "2017-09-11T21:23:17.538826: step 413, loss -24.4812, acc 0.9375\n",
      "2017-09-11T21:23:17.624310: step 414, loss -31.4126, acc 0.96875\n",
      "2017-09-11T21:23:17.724372: step 415, loss -12.5866, acc 0.96875\n",
      "2017-09-11T21:23:17.808767: step 416, loss -15.1348, acc 0.9375\n",
      "2017-09-11T21:23:17.896293: step 417, loss -14.2046, acc 0.90625\n",
      "2017-09-11T21:23:17.974692: step 418, loss -15.0434, acc 0.9375\n",
      "2017-09-11T21:23:18.050029: step 419, loss -9.29102, acc 0.90625\n",
      "2017-09-11T21:23:18.123785: step 420, loss -26.1103, acc 0.9375\n",
      "2017-09-11T21:23:18.201897: step 421, loss -19.536, acc 0.84375\n",
      "2017-09-11T21:23:18.277329: step 422, loss -13.597, acc 0.96875\n",
      "2017-09-11T21:23:18.353950: step 423, loss -33.8128, acc 1\n",
      "2017-09-11T21:23:18.432368: step 424, loss -26.9149, acc 0.96875\n",
      "2017-09-11T21:23:18.505343: step 425, loss -9.96031, acc 0.9375\n",
      "2017-09-11T21:23:18.582182: step 426, loss 9.51405, acc 0.90625\n",
      "2017-09-11T21:23:18.659933: step 427, loss -9.08306, acc 0.875\n",
      "2017-09-11T21:23:18.736566: step 428, loss -28.2314, acc 0.9375\n",
      "2017-09-11T21:23:18.810124: step 429, loss -12.7759, acc 0.875\n",
      "2017-09-11T21:23:18.885335: step 430, loss -29.8259, acc 0.96875\n",
      "2017-09-11T21:23:18.962054: step 431, loss 9.19837, acc 0.90625\n",
      "2017-09-11T21:23:19.036008: step 432, loss -1.60939, acc 0.84375\n",
      "2017-09-11T21:23:19.116328: step 433, loss -3.06335, acc 0.9375\n",
      "2017-09-11T21:23:19.190079: step 434, loss -21.9291, acc 0.96875\n",
      "2017-09-11T21:23:19.263270: step 435, loss -26.738, acc 0.9375\n",
      "2017-09-11T21:23:19.339224: step 436, loss -15.8036, acc 0.96875\n",
      "2017-09-11T21:23:19.413960: step 437, loss -27.0473, acc 0.9375\n",
      "2017-09-11T21:23:19.488770: step 438, loss -0.494421, acc 0.9375\n",
      "2017-09-11T21:23:19.566141: step 439, loss -11.9899, acc 0.84375\n",
      "2017-09-11T21:23:19.639848: step 440, loss -14.5748, acc 1\n",
      "2017-09-11T21:23:19.720366: step 441, loss -10.203, acc 0.90625\n",
      "2017-09-11T21:23:19.809527: step 442, loss -28.2112, acc 0.96875\n",
      "2017-09-11T21:23:19.894819: step 443, loss 6.73521, acc 0.8125\n",
      "2017-09-11T21:23:19.980495: step 444, loss -27.0029, acc 0.96875\n",
      "2017-09-11T21:23:20.070603: step 445, loss -27.9546, acc 0.96875\n",
      "2017-09-11T21:23:20.161669: step 446, loss -6.63822, acc 0.9375\n",
      "2017-09-11T21:23:20.247675: step 447, loss -36.2733, acc 0.96875\n",
      "2017-09-11T21:23:20.332884: step 448, loss 9.70029, acc 0.8125\n",
      "2017-09-11T21:23:20.411127: step 449, loss -20.5889, acc 0.96875\n",
      "2017-09-11T21:23:20.488673: step 450, loss -1.30887, acc 0.9375\n",
      "2017-09-11T21:23:20.611200: step 451, loss -4.15109, acc 0.90625\n",
      "2017-09-11T21:23:20.731049: step 452, loss -34.5145, acc 1\n",
      "2017-09-11T21:23:20.828151: step 453, loss -16.578, acc 0.9375\n",
      "2017-09-11T21:23:20.919318: step 454, loss -5.34563, acc 0.9375\n",
      "2017-09-11T21:23:21.005269: step 455, loss -26.4968, acc 0.96875\n",
      "2017-09-11T21:23:21.097097: step 456, loss -23.7361, acc 0.90625\n",
      "2017-09-11T21:23:21.185587: step 457, loss -22.5817, acc 0.9375\n",
      "2017-09-11T21:23:21.273086: step 458, loss -9.54776, acc 0.90625\n",
      "2017-09-11T21:23:21.358439: step 459, loss -16.5923, acc 0.9375\n",
      "2017-09-11T21:23:21.439916: step 460, loss -27.6214, acc 1\n",
      "2017-09-11T21:23:21.536772: step 461, loss -26.3104, acc 0.9375\n",
      "2017-09-11T21:23:21.664364: step 462, loss -16.523, acc 0.96875\n",
      "2017-09-11T21:23:21.776974: step 463, loss -16.2689, acc 0.96875\n",
      "2017-09-11T21:23:21.874126: step 464, loss -56.4809, acc 1\n",
      "2017-09-11T21:23:21.964028: step 465, loss -15.9558, acc 0.90625\n",
      "2017-09-11T21:23:22.050284: step 466, loss -22.4392, acc 0.90625\n",
      "2017-09-11T21:23:22.140516: step 467, loss -51.6142, acc 0.9375\n",
      "2017-09-11T21:23:22.224080: step 468, loss 6.97681, acc 0.8125\n",
      "2017-09-11T21:23:22.298722: step 469, loss -34.6582, acc 0.9375\n",
      "2017-09-11T21:23:22.387696: step 470, loss -2.95656, acc 0.90625\n",
      "2017-09-11T21:23:22.516161: step 471, loss -31.9323, acc 1\n",
      "2017-09-11T21:23:22.640587: step 472, loss -35.6525, acc 1\n",
      "2017-09-11T21:23:22.754281: step 473, loss -17.84, acc 0.9375\n",
      "2017-09-11T21:23:22.867068: step 474, loss -19.0288, acc 0.9375\n",
      "2017-09-11T21:23:22.968629: step 475, loss -44.2622, acc 0.96875\n",
      "2017-09-11T21:23:23.052358: step 476, loss -40.2559, acc 0.9375\n",
      "2017-09-11T21:23:23.142766: step 477, loss -17.2496, acc 0.96875\n",
      "2017-09-11T21:23:23.231405: step 478, loss -30.4015, acc 0.96875\n",
      "2017-09-11T21:23:23.318582: step 479, loss -13.247, acc 0.96875\n",
      "2017-09-11T21:23:23.406169: step 480, loss -29.6462, acc 0.9375\n",
      "2017-09-11T21:23:23.486625: step 481, loss -5.51784, acc 0.96875\n",
      "2017-09-11T21:23:23.581152: step 482, loss -23.7992, acc 0.96875\n",
      "2017-09-11T21:23:23.674952: step 483, loss -19.3067, acc 0.9375\n",
      "2017-09-11T21:23:23.756279: step 484, loss -1.35035, acc 0.78125\n",
      "2017-09-11T21:23:23.829755: step 485, loss -19.055, acc 0.90625\n",
      "2017-09-11T21:23:23.908493: step 486, loss -47.8244, acc 0.90625\n",
      "2017-09-11T21:23:23.985414: step 487, loss -13.602, acc 0.875\n",
      "2017-09-11T21:23:24.058354: step 488, loss -21.6234, acc 0.875\n",
      "2017-09-11T21:23:24.141969: step 489, loss -19.4548, acc 0.9375\n",
      "2017-09-11T21:23:24.226608: step 490, loss -33.7009, acc 0.9375\n",
      "2017-09-11T21:23:24.301845: step 491, loss 0.0511217, acc 0.875\n",
      "2017-09-11T21:23:24.380960: step 492, loss -12.2242, acc 0.875\n",
      "2017-09-11T21:23:24.511244: step 493, loss -37.4544, acc 0.9375\n",
      "2017-09-11T21:23:24.620150: step 494, loss -15.1681, acc 0.9375\n",
      "2017-09-11T21:23:24.715264: step 495, loss -29.1364, acc 1\n",
      "2017-09-11T21:23:24.809041: step 496, loss -6.14474, acc 0.96875\n",
      "2017-09-11T21:23:24.903664: step 497, loss 16.9335, acc 0.84375\n",
      "2017-09-11T21:23:24.991430: step 498, loss -35.9637, acc 0.96875\n",
      "2017-09-11T21:23:25.087832: step 499, loss -44.2613, acc 0.9375\n",
      "2017-09-11T21:23:25.186045: step 500, loss -22.5512, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:23:26.049407: step 500, loss -25.2968, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-500\n",
      "\n",
      "2017-09-11T21:23:26.858251: step 501, loss -12.2234, acc 0.9375\n",
      "2017-09-11T21:23:26.941318: step 502, loss -18.6447, acc 0.90625\n",
      "2017-09-11T21:23:27.033220: step 503, loss -13.4829, acc 0.8125\n",
      "2017-09-11T21:23:27.114094: step 504, loss 25.1765, acc 0.84375\n",
      "2017-09-11T21:23:27.205014: step 505, loss -24.3453, acc 0.96875\n",
      "2017-09-11T21:23:27.298451: step 506, loss 0.599419, acc 0.875\n",
      "2017-09-11T21:23:27.387828: step 507, loss 5.57265, acc 0.875\n",
      "2017-09-11T21:23:27.482491: step 508, loss -2.53457, acc 0.90625\n",
      "2017-09-11T21:23:27.574703: step 509, loss 20.157, acc 0.84375\n",
      "2017-09-11T21:23:27.663337: step 510, loss -8.56388, acc 0.875\n",
      "2017-09-11T21:23:27.752241: step 511, loss -30.1038, acc 0.96875\n",
      "2017-09-11T21:23:27.842691: step 512, loss -22.2684, acc 0.90625\n",
      "2017-09-11T21:23:27.929931: step 513, loss -19.2765, acc 0.9375\n",
      "2017-09-11T21:23:28.034048: step 514, loss -21.7969, acc 0.96875\n",
      "2017-09-11T21:23:28.132178: step 515, loss -31.1991, acc 0.9375\n",
      "2017-09-11T21:23:28.223542: step 516, loss -38.8423, acc 0.96875\n",
      "2017-09-11T21:23:28.342145: step 517, loss -21.2928, acc 0.9375\n",
      "2017-09-11T21:23:28.433209: step 518, loss -19.6365, acc 0.9375\n",
      "2017-09-11T21:23:28.520020: step 519, loss -6.70856, acc 0.84375\n",
      "2017-09-11T21:23:28.617658: step 520, loss -33.0324, acc 0.9375\n",
      "2017-09-11T21:23:28.709667: step 521, loss -28.994, acc 0.90625\n",
      "2017-09-11T21:23:28.796684: step 522, loss -76.7865, acc 1\n",
      "2017-09-11T21:23:28.887507: step 523, loss -5.13639, acc 0.90625\n",
      "2017-09-11T21:23:28.980199: step 524, loss -14.8428, acc 0.90625\n",
      "2017-09-11T21:23:29.067116: step 525, loss -46.0204, acc 1\n",
      "2017-09-11T21:23:29.106910: step 526, loss -54.3898, acc 1\n",
      "2017-09-11T21:23:29.198048: step 527, loss 14.8837, acc 0.8125\n",
      "2017-09-11T21:23:29.283731: step 528, loss -33.2797, acc 0.90625\n",
      "2017-09-11T21:23:29.391059: step 529, loss -16.936, acc 0.90625\n",
      "2017-09-11T21:23:29.631536: step 530, loss -19.7228, acc 0.9375\n",
      "2017-09-11T21:23:29.785833: step 531, loss -19.6188, acc 0.90625\n",
      "2017-09-11T21:23:29.917698: step 532, loss -44.3292, acc 0.9375\n",
      "2017-09-11T21:23:30.082388: step 533, loss -21.0703, acc 0.9375\n",
      "2017-09-11T21:23:30.252606: step 534, loss -35.4704, acc 0.90625\n",
      "2017-09-11T21:23:30.387959: step 535, loss -5.93713, acc 0.9375\n",
      "2017-09-11T21:23:30.531510: step 536, loss -23.3551, acc 0.90625\n",
      "2017-09-11T21:23:30.665453: step 537, loss -30.1026, acc 0.875\n",
      "2017-09-11T21:23:30.796925: step 538, loss -64.0078, acc 1\n",
      "2017-09-11T21:23:30.943184: step 539, loss -37.9566, acc 1\n",
      "2017-09-11T21:23:31.088020: step 540, loss -20.8966, acc 0.9375\n",
      "2017-09-11T21:23:31.232042: step 541, loss -29.2491, acc 0.90625\n",
      "2017-09-11T21:23:31.375735: step 542, loss -32.8355, acc 0.96875\n",
      "2017-09-11T21:23:31.508145: step 543, loss -59.8634, acc 1\n",
      "2017-09-11T21:23:31.645147: step 544, loss -28.521, acc 0.90625\n",
      "2017-09-11T21:23:31.795781: step 545, loss -12.7274, acc 0.875\n",
      "2017-09-11T21:23:31.945402: step 546, loss -30.5364, acc 0.9375\n",
      "2017-09-11T21:23:32.068527: step 547, loss -2.66688, acc 0.90625\n",
      "2017-09-11T21:23:32.210696: step 548, loss 8.38384, acc 0.8125\n",
      "2017-09-11T21:23:32.352773: step 549, loss -30.9158, acc 0.90625\n",
      "2017-09-11T21:23:32.495753: step 550, loss 8.93185, acc 0.84375\n",
      "2017-09-11T21:23:32.642255: step 551, loss 9.11053, acc 0.9375\n",
      "2017-09-11T21:23:32.785329: step 552, loss -23.0376, acc 0.96875\n",
      "2017-09-11T21:23:32.932470: step 553, loss -20.8656, acc 0.90625\n",
      "2017-09-11T21:23:33.080233: step 554, loss -17.2784, acc 0.9375\n",
      "2017-09-11T21:23:33.211797: step 555, loss -64.455, acc 0.90625\n",
      "2017-09-11T21:23:33.356320: step 556, loss -27.9546, acc 0.9375\n",
      "2017-09-11T21:23:33.498494: step 557, loss -0.879376, acc 0.9375\n",
      "2017-09-11T21:23:33.643939: step 558, loss -16.4739, acc 0.875\n",
      "2017-09-11T21:23:33.790983: step 559, loss -52.3906, acc 0.9375\n",
      "2017-09-11T21:23:33.937648: step 560, loss -25.7923, acc 0.9375\n",
      "2017-09-11T21:23:34.091884: step 561, loss -81.2742, acc 1\n",
      "2017-09-11T21:23:34.361743: step 562, loss -17.2988, acc 0.90625\n",
      "2017-09-11T21:23:34.496597: step 563, loss -37.9328, acc 0.9375\n",
      "2017-09-11T21:23:34.639207: step 564, loss -26.8206, acc 1\n",
      "2017-09-11T21:23:34.805210: step 565, loss -48.1636, acc 0.90625\n",
      "2017-09-11T21:23:34.944263: step 566, loss -33.3771, acc 0.9375\n",
      "2017-09-11T21:23:35.093918: step 567, loss -38.8288, acc 0.96875\n",
      "2017-09-11T21:23:35.412923: step 568, loss -58.9447, acc 0.96875\n",
      "2017-09-11T21:23:35.586386: step 569, loss -16.5905, acc 0.9375\n",
      "2017-09-11T21:23:35.777417: step 570, loss -35.4573, acc 0.9375\n",
      "2017-09-11T21:23:35.921144: step 571, loss -31.423, acc 0.9375\n",
      "2017-09-11T21:23:36.066374: step 572, loss 29.6436, acc 0.8125\n",
      "2017-09-11T21:23:36.206678: step 573, loss -57.903, acc 0.96875\n",
      "2017-09-11T21:23:36.373228: step 574, loss -57.5944, acc 0.96875\n",
      "2017-09-11T21:23:36.510380: step 575, loss -27.4661, acc 0.9375\n",
      "2017-09-11T21:23:36.656844: step 576, loss -15.2116, acc 0.90625\n",
      "2017-09-11T21:23:36.804020: step 577, loss -25.0247, acc 0.90625\n",
      "2017-09-11T21:23:36.950944: step 578, loss -18.1489, acc 0.90625\n",
      "2017-09-11T21:23:37.099011: step 579, loss -40.3829, acc 0.96875\n",
      "2017-09-11T21:23:37.243022: step 580, loss 0.684413, acc 0.84375\n",
      "2017-09-11T21:23:37.400022: step 581, loss -32.8163, acc 1\n",
      "2017-09-11T21:23:37.550326: step 582, loss -41.8446, acc 1\n",
      "2017-09-11T21:23:37.699445: step 583, loss 16.0307, acc 0.84375\n",
      "2017-09-11T21:23:37.839626: step 584, loss 6.6083, acc 0.875\n",
      "2017-09-11T21:23:37.992924: step 585, loss -33.6564, acc 0.96875\n",
      "2017-09-11T21:23:38.130454: step 586, loss -46.1833, acc 0.9375\n",
      "2017-09-11T21:23:38.282312: step 587, loss -24.3973, acc 0.96875\n",
      "2017-09-11T21:23:38.428677: step 588, loss -25.9598, acc 0.9375\n",
      "2017-09-11T21:23:38.576940: step 589, loss -46.3939, acc 0.90625\n",
      "2017-09-11T21:23:38.725316: step 590, loss -1.2753, acc 0.875\n",
      "2017-09-11T21:23:38.869189: step 591, loss -75.0631, acc 1\n",
      "2017-09-11T21:23:39.023383: step 592, loss -27.5069, acc 0.9375\n",
      "2017-09-11T21:23:39.168529: step 593, loss -9.00185, acc 0.875\n",
      "2017-09-11T21:23:39.318671: step 594, loss -44.6352, acc 0.9375\n",
      "2017-09-11T21:23:39.470614: step 595, loss 17.476, acc 0.90625\n",
      "2017-09-11T21:23:39.616575: step 596, loss 11.4817, acc 0.84375\n",
      "2017-09-11T21:23:39.768153: step 597, loss -45.9717, acc 0.90625\n",
      "2017-09-11T21:23:39.896744: step 598, loss 16.2995, acc 0.8125\n",
      "2017-09-11T21:23:40.053072: step 599, loss -33.6568, acc 0.875\n",
      "2017-09-11T21:23:40.186994: step 600, loss -9.92689, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:23:41.813254: step 600, loss -35.6857, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-600\n",
      "\n",
      "2017-09-11T21:23:43.970719: step 601, loss -38.1783, acc 0.875\n",
      "2017-09-11T21:23:44.065848: step 602, loss -26.4496, acc 0.9375\n",
      "2017-09-11T21:23:44.169742: step 603, loss -36.4984, acc 0.90625\n",
      "2017-09-11T21:23:44.311686: step 604, loss -54.2504, acc 0.96875\n",
      "2017-09-11T21:23:44.443466: step 605, loss -46.722, acc 1\n",
      "2017-09-11T21:23:44.575595: step 606, loss -61.0378, acc 0.9375\n",
      "2017-09-11T21:23:44.720019: step 607, loss -11.7181, acc 0.84375\n",
      "2017-09-11T21:23:44.839477: step 608, loss -2.36015, acc 0.9375\n",
      "2017-09-11T21:23:44.938759: step 609, loss -29.2296, acc 0.9375\n",
      "2017-09-11T21:23:45.042065: step 610, loss -31.9208, acc 0.90625\n",
      "2017-09-11T21:23:45.134540: step 611, loss -16.4562, acc 0.90625\n",
      "2017-09-11T21:23:45.228190: step 612, loss -15.0856, acc 0.9375\n",
      "2017-09-11T21:23:45.317199: step 613, loss -24.7848, acc 0.90625\n",
      "2017-09-11T21:23:45.411041: step 614, loss -72.9565, acc 1\n",
      "2017-09-11T21:23:45.499585: step 615, loss -50.8907, acc 0.96875\n",
      "2017-09-11T21:23:45.595242: step 616, loss -45.3513, acc 0.96875\n",
      "2017-09-11T21:23:45.686394: step 617, loss -48.6541, acc 0.90625\n",
      "2017-09-11T21:23:45.780355: step 618, loss -35.2019, acc 0.875\n",
      "2017-09-11T21:23:45.876656: step 619, loss 5.0477, acc 0.84375\n",
      "2017-09-11T21:23:45.971438: step 620, loss -6.68571, acc 0.9375\n",
      "2017-09-11T21:23:46.063091: step 621, loss -10.7469, acc 0.84375\n",
      "2017-09-11T21:23:46.152065: step 622, loss -39.9785, acc 0.96875\n",
      "2017-09-11T21:23:46.245704: step 623, loss -69.1113, acc 0.9375\n",
      "2017-09-11T21:23:46.349533: step 624, loss -38.3034, acc 0.9375\n",
      "2017-09-11T21:23:46.430322: step 625, loss -60.2258, acc 0.96875\n",
      "2017-09-11T21:23:46.519797: step 626, loss -58.5179, acc 0.96875\n",
      "2017-09-11T21:23:46.614250: step 627, loss -23.0598, acc 0.90625\n",
      "2017-09-11T21:23:46.700662: step 628, loss -35.2392, acc 0.96875\n",
      "2017-09-11T21:23:46.786138: step 629, loss -76.576, acc 0.96875\n",
      "2017-09-11T21:23:46.881370: step 630, loss -58.2638, acc 0.9375\n",
      "2017-09-11T21:23:46.968968: step 631, loss -37.6285, acc 0.9375\n",
      "2017-09-11T21:23:47.223110: step 632, loss 19.1008, acc 0.875\n",
      "2017-09-11T21:23:47.378869: step 633, loss -38.36, acc 0.96875\n",
      "2017-09-11T21:23:47.525702: step 634, loss -83.4247, acc 1\n",
      "2017-09-11T21:23:47.675562: step 635, loss -35.0755, acc 0.9375\n",
      "2017-09-11T21:23:47.837045: step 636, loss 4.74203, acc 0.8125\n",
      "2017-09-11T21:23:47.970748: step 637, loss -89.1058, acc 1\n",
      "2017-09-11T21:23:48.114350: step 638, loss -25.1183, acc 0.84375\n",
      "2017-09-11T21:23:48.253227: step 639, loss -70.1843, acc 0.9375\n",
      "2017-09-11T21:23:48.399643: step 640, loss -32.5203, acc 0.90625\n",
      "2017-09-11T21:23:48.542069: step 641, loss 39.3008, acc 0.875\n",
      "2017-09-11T21:23:48.678276: step 642, loss -28.1787, acc 0.84375\n",
      "2017-09-11T21:23:48.826828: step 643, loss -13.681, acc 0.90625\n",
      "2017-09-11T21:23:48.965578: step 644, loss -66.02, acc 0.96875\n",
      "2017-09-11T21:23:49.099713: step 645, loss -57.6515, acc 0.90625\n",
      "2017-09-11T21:23:49.274637: step 646, loss -21.5507, acc 0.90625\n",
      "2017-09-11T21:23:49.406249: step 647, loss -39.5903, acc 0.875\n",
      "2017-09-11T21:23:49.553252: step 648, loss -38.458, acc 0.96875\n",
      "2017-09-11T21:23:49.700951: step 649, loss -43.6651, acc 0.9375\n",
      "2017-09-11T21:23:49.847248: step 650, loss -32.9928, acc 0.96875\n",
      "2017-09-11T21:23:49.987228: step 651, loss -53.6374, acc 0.96875\n",
      "2017-09-11T21:23:50.146997: step 652, loss -75.9571, acc 0.96875\n",
      "2017-09-11T21:23:50.285918: step 653, loss -35.9649, acc 0.84375\n",
      "2017-09-11T21:23:50.437642: step 654, loss -52.7921, acc 0.90625\n",
      "2017-09-11T21:23:50.567984: step 655, loss -20.736, acc 0.9375\n",
      "2017-09-11T21:23:50.716436: step 656, loss 20.9498, acc 0.84375\n",
      "2017-09-11T21:23:50.860668: step 657, loss -19.6339, acc 0.875\n",
      "2017-09-11T21:23:50.993963: step 658, loss -67.2909, acc 0.9375\n",
      "2017-09-11T21:23:51.134689: step 659, loss -30.4308, acc 0.90625\n",
      "2017-09-11T21:23:51.273225: step 660, loss -93.6152, acc 0.90625\n",
      "2017-09-11T21:23:51.411715: step 661, loss -68.7819, acc 0.96875\n",
      "2017-09-11T21:23:51.551790: step 662, loss -50.1561, acc 1\n",
      "2017-09-11T21:23:51.692463: step 663, loss -58.1191, acc 0.96875\n",
      "2017-09-11T21:23:51.829684: step 664, loss 1.41695, acc 0.96875\n",
      "2017-09-11T21:23:51.972441: step 665, loss -0.773947, acc 0.90625\n",
      "2017-09-11T21:23:52.103885: step 666, loss -37.1269, acc 0.9375\n",
      "2017-09-11T21:23:52.254186: step 667, loss -67.8637, acc 0.9375\n",
      "2017-09-11T21:23:52.382242: step 668, loss -59.6063, acc 0.96875\n",
      "2017-09-11T21:23:52.523019: step 669, loss -76.1469, acc 0.96875\n",
      "2017-09-11T21:23:52.667886: step 670, loss -50.8228, acc 0.90625\n",
      "2017-09-11T21:23:52.826339: step 671, loss -4.28557, acc 0.90625\n",
      "2017-09-11T21:23:52.973368: step 672, loss -12.7817, acc 0.90625\n",
      "2017-09-11T21:23:53.113618: step 673, loss -36.8429, acc 0.96875\n",
      "2017-09-11T21:23:53.257874: step 674, loss -61.0131, acc 0.96875\n",
      "2017-09-11T21:23:53.404705: step 675, loss -48.8952, acc 0.9375\n",
      "2017-09-11T21:23:53.551789: step 676, loss -50.3143, acc 0.96875\n",
      "2017-09-11T21:23:53.696162: step 677, loss -79.3863, acc 0.9375\n",
      "2017-09-11T21:23:53.820946: step 678, loss -90.734, acc 0.96875\n",
      "2017-09-11T21:23:53.961325: step 679, loss -31.231, acc 0.84375\n",
      "2017-09-11T21:23:54.115929: step 680, loss -30.1442, acc 0.875\n",
      "2017-09-11T21:23:54.260508: step 681, loss -80.3075, acc 0.96875\n",
      "2017-09-11T21:23:54.392412: step 682, loss -84.9278, acc 0.875\n",
      "2017-09-11T21:23:54.550107: step 683, loss -38.7431, acc 0.9375\n",
      "2017-09-11T21:23:54.696945: step 684, loss -55.9252, acc 0.90625\n",
      "2017-09-11T21:23:54.843920: step 685, loss -9.78431, acc 0.9375\n",
      "2017-09-11T21:23:54.979090: step 686, loss -49.5535, acc 0.9375\n",
      "2017-09-11T21:23:55.127532: step 687, loss -58.7238, acc 0.96875\n",
      "2017-09-11T21:23:55.269367: step 688, loss -22.6573, acc 0.96875\n",
      "2017-09-11T21:23:55.404417: step 689, loss -79.6623, acc 0.9375\n",
      "2017-09-11T21:23:55.531815: step 690, loss -13.6296, acc 0.90625\n",
      "2017-09-11T21:23:55.676955: step 691, loss 25.3767, acc 0.84375\n",
      "2017-09-11T21:23:55.802295: step 692, loss -49.5705, acc 0.96875\n",
      "2017-09-11T21:23:55.947096: step 693, loss 13.3934, acc 0.90625\n",
      "2017-09-11T21:23:56.085239: step 694, loss -58.1223, acc 0.96875\n",
      "2017-09-11T21:23:56.229836: step 695, loss -51.986, acc 0.9375\n",
      "2017-09-11T21:23:56.369792: step 696, loss -98.4265, acc 0.96875\n",
      "2017-09-11T21:23:56.513106: step 697, loss -66.7529, acc 0.9375\n",
      "2017-09-11T21:23:56.643427: step 698, loss -87.3605, acc 0.90625\n",
      "2017-09-11T21:23:56.784013: step 699, loss -17.7072, acc 0.9375\n",
      "2017-09-11T21:23:56.922659: step 700, loss -52.2865, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:23:58.393456: step 700, loss -50.8379, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-700\n",
      "\n",
      "2017-09-11T21:24:00.174094: step 701, loss -12.1439, acc 0.90625\n",
      "2017-09-11T21:24:00.260623: step 702, loss -76.4681, acc 0.96875\n",
      "2017-09-11T21:24:00.361907: step 703, loss -13.0259, acc 0.9375\n",
      "2017-09-11T21:24:00.505879: step 704, loss -30.7325, acc 0.90625\n",
      "2017-09-11T21:24:00.637244: step 705, loss -39.2501, acc 0.9375\n",
      "2017-09-11T21:24:00.762997: step 706, loss -64.0981, acc 1\n",
      "2017-09-11T21:24:00.898753: step 707, loss 2.43176, acc 0.84375\n",
      "2017-09-11T21:24:01.030518: step 708, loss 7.96438, acc 0.875\n",
      "2017-09-11T21:24:01.164250: step 709, loss -80.0002, acc 1\n",
      "2017-09-11T21:24:01.319592: step 710, loss -88.1429, acc 0.96875\n",
      "2017-09-11T21:24:01.453894: step 711, loss -18.4593, acc 0.84375\n",
      "2017-09-11T21:24:01.610367: step 712, loss -110.532, acc 0.9375\n",
      "2017-09-11T21:24:01.765198: step 713, loss -92.0913, acc 1\n",
      "2017-09-11T21:24:01.884023: step 714, loss -63.9144, acc 1\n",
      "2017-09-11T21:24:01.982770: step 715, loss -38.0392, acc 0.84375\n",
      "2017-09-11T21:24:02.077655: step 716, loss -37.9098, acc 0.96875\n",
      "2017-09-11T21:24:02.165483: step 717, loss -26.1727, acc 0.90625\n",
      "2017-09-11T21:24:02.257196: step 718, loss -59.9154, acc 0.9375\n",
      "2017-09-11T21:24:02.348955: step 719, loss -40.1381, acc 0.9375\n",
      "2017-09-11T21:24:02.438510: step 720, loss -2.57986, acc 0.90625\n",
      "2017-09-11T21:24:02.529186: step 721, loss -51.6379, acc 0.96875\n",
      "2017-09-11T21:24:02.615372: step 722, loss -42.5161, acc 0.90625\n",
      "2017-09-11T21:24:02.701150: step 723, loss -43.4051, acc 0.96875\n",
      "2017-09-11T21:24:02.786732: step 724, loss -39.4582, acc 0.9375\n",
      "2017-09-11T21:24:02.874394: step 725, loss -23.2936, acc 0.9375\n",
      "2017-09-11T21:24:02.963443: step 726, loss -87.1571, acc 0.96875\n",
      "2017-09-11T21:24:03.056613: step 727, loss -43.4703, acc 0.9375\n",
      "2017-09-11T21:24:03.146995: step 728, loss -60.652, acc 0.9375\n",
      "2017-09-11T21:24:03.232191: step 729, loss -29.5438, acc 0.90625\n",
      "2017-09-11T21:24:03.313750: step 730, loss -49.139, acc 0.9375\n",
      "2017-09-11T21:24:03.526402: step 731, loss -104.801, acc 0.9375\n",
      "2017-09-11T21:24:03.684809: step 732, loss -44.7838, acc 0.96875\n",
      "2017-09-11T21:24:03.861726: step 733, loss -56.8163, acc 0.9375\n",
      "2017-09-11T21:24:04.001298: step 734, loss -31.0135, acc 0.8125\n",
      "2017-09-11T21:24:04.159791: step 735, loss 3.50377, acc 0.84375\n",
      "2017-09-11T21:24:04.297507: step 736, loss -15.7389, acc 0.875\n",
      "2017-09-11T21:24:04.449555: step 737, loss -14.9748, acc 0.9375\n",
      "2017-09-11T21:24:04.585969: step 738, loss -30.7046, acc 0.90625\n",
      "2017-09-11T21:24:04.749456: step 739, loss 29.6737, acc 0.90625\n",
      "2017-09-11T21:24:04.874054: step 740, loss -44.5425, acc 0.90625\n",
      "2017-09-11T21:24:05.021808: step 741, loss -54.8793, acc 0.96875\n",
      "2017-09-11T21:24:05.168273: step 742, loss 16.5841, acc 0.90625\n",
      "2017-09-11T21:24:05.314865: step 743, loss -60.6866, acc 0.90625\n",
      "2017-09-11T21:24:05.450449: step 744, loss -101.348, acc 1\n",
      "2017-09-11T21:24:05.592496: step 745, loss -44.3442, acc 0.96875\n",
      "2017-09-11T21:24:05.751515: step 746, loss -61.6763, acc 0.96875\n",
      "2017-09-11T21:24:05.899374: step 747, loss -51.4676, acc 0.90625\n",
      "2017-09-11T21:24:06.050879: step 748, loss -3.14872, acc 0.84375\n",
      "2017-09-11T21:24:06.188832: step 749, loss -86.8698, acc 0.875\n",
      "2017-09-11T21:24:06.339266: step 750, loss -93.2215, acc 0.9375\n",
      "2017-09-11T21:24:06.482511: step 751, loss -64.0253, acc 0.9375\n",
      "2017-09-11T21:24:06.628362: step 752, loss -86.0039, acc 0.9375\n",
      "2017-09-11T21:24:06.803854: step 753, loss -61.9538, acc 0.9375\n",
      "2017-09-11T21:24:06.942143: step 754, loss -44.1056, acc 0.9375\n",
      "2017-09-11T21:24:07.074331: step 755, loss 8.09058, acc 0.84375\n",
      "2017-09-11T21:24:07.229184: step 756, loss -108.14, acc 0.9375\n",
      "2017-09-11T21:24:07.382534: step 757, loss -78.8045, acc 0.9375\n",
      "2017-09-11T21:24:07.514086: step 758, loss -36.7216, acc 0.875\n",
      "2017-09-11T21:24:07.662870: step 759, loss -18.2544, acc 0.90625\n",
      "2017-09-11T21:24:07.785079: step 760, loss -5.15517, acc 0.90625\n",
      "2017-09-11T21:24:07.926412: step 761, loss -65.9169, acc 0.96875\n",
      "2017-09-11T21:24:08.060712: step 762, loss 90.2666, acc 0.75\n",
      "2017-09-11T21:24:08.185498: step 763, loss -63.0078, acc 0.875\n",
      "2017-09-11T21:24:08.331462: step 764, loss -76.703, acc 0.90625\n",
      "2017-09-11T21:24:08.455037: step 765, loss 16.4171, acc 0.84375\n",
      "2017-09-11T21:24:08.585970: step 766, loss -17.8988, acc 0.875\n",
      "2017-09-11T21:24:08.735366: step 767, loss -59.0909, acc 0.96875\n",
      "2017-09-11T21:24:08.867998: step 768, loss 15.4897, acc 0.90625\n",
      "2017-09-11T21:24:09.003925: step 769, loss -148.24, acc 1\n",
      "2017-09-11T21:24:09.166235: step 770, loss -15.9944, acc 0.9375\n",
      "2017-09-11T21:24:09.295591: step 771, loss -42.1963, acc 0.9375\n",
      "2017-09-11T21:24:09.436537: step 772, loss -48.0064, acc 0.9375\n",
      "2017-09-11T21:24:09.591341: step 773, loss -2.75919, acc 0.875\n",
      "2017-09-11T21:24:09.734472: step 774, loss -106.753, acc 0.9375\n",
      "2017-09-11T21:24:09.891924: step 775, loss -38.3136, acc 0.84375\n",
      "2017-09-11T21:24:10.050672: step 776, loss -75.2691, acc 0.875\n",
      "2017-09-11T21:24:10.189370: step 777, loss -64.9958, acc 0.96875\n",
      "2017-09-11T21:24:10.335921: step 778, loss -31.3697, acc 0.9375\n",
      "2017-09-11T21:24:10.476024: step 779, loss -95.2798, acc 0.96875\n",
      "2017-09-11T21:24:10.633492: step 780, loss -48.9186, acc 0.9375\n",
      "2017-09-11T21:24:10.770808: step 781, loss -119.176, acc 0.9375\n",
      "2017-09-11T21:24:10.897006: step 782, loss -66.2012, acc 0.9375\n",
      "2017-09-11T21:24:11.044529: step 783, loss -34.4122, acc 0.875\n",
      "2017-09-11T21:24:11.206716: step 784, loss -130.001, acc 1\n",
      "2017-09-11T21:24:11.343175: step 785, loss -162.137, acc 1\n",
      "2017-09-11T21:24:11.469302: step 786, loss -37.3649, acc 0.9375\n",
      "2017-09-11T21:24:11.631046: step 787, loss -122.72, acc 1\n",
      "2017-09-11T21:24:11.763626: step 788, loss -27.3247, acc 0.8125\n",
      "2017-09-11T21:24:11.805784: step 789, loss -130.244, acc 1\n",
      "2017-09-11T21:24:11.965772: step 790, loss -34.2004, acc 0.96875\n",
      "2017-09-11T21:24:12.108507: step 791, loss -104.335, acc 0.96875\n",
      "2017-09-11T21:24:12.234540: step 792, loss -136.877, acc 1\n",
      "2017-09-11T21:24:12.401656: step 793, loss -20.869, acc 0.9375\n",
      "2017-09-11T21:24:12.538308: step 794, loss -65.2313, acc 0.84375\n",
      "2017-09-11T21:24:12.692133: step 795, loss -0.223602, acc 0.875\n",
      "2017-09-11T21:24:12.834512: step 796, loss -122.964, acc 1\n",
      "2017-09-11T21:24:12.982766: step 797, loss -38.1569, acc 0.875\n",
      "2017-09-11T21:24:13.123681: step 798, loss -67.3823, acc 0.9375\n",
      "2017-09-11T21:24:13.269996: step 799, loss -51.379, acc 0.9375\n",
      "2017-09-11T21:24:13.412566: step 800, loss -1.55602, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-11T21:24:14.723735: step 800, loss -68.804, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-800\n",
      "\n",
      "2017-09-11T21:24:17.557156: step 801, loss -36.8805, acc 0.90625\n",
      "2017-09-11T21:24:17.665555: step 802, loss -56.1039, acc 0.9375\n",
      "2017-09-11T21:24:17.810064: step 803, loss -34.2891, acc 0.875\n",
      "2017-09-12T00:17:16.044063: step 804, loss -86.7639, acc 0.96875\n",
      "2017-09-12T00:17:16.607278: step 805, loss -83.0874, acc 0.96875\n",
      "2017-09-12T00:17:17.144961: step 806, loss -58.3211, acc 0.9375\n",
      "2017-09-12T00:17:17.305819: step 807, loss -55.0039, acc 0.9375\n",
      "2017-09-12T00:17:17.481951: step 808, loss -102.812, acc 0.96875\n",
      "2017-09-12T00:17:17.718979: step 809, loss -36.8621, acc 0.96875\n",
      "2017-09-12T00:17:17.855947: step 810, loss -14.8829, acc 0.96875\n",
      "2017-09-12T00:17:17.969392: step 811, loss -70.4875, acc 0.96875\n",
      "2017-09-12T00:17:18.131110: step 812, loss -13.2521, acc 0.875\n",
      "2017-09-12T00:17:18.275436: step 813, loss -66.583, acc 0.9375\n",
      "2017-09-12T00:17:18.420725: step 814, loss -120.908, acc 0.9375\n",
      "2017-09-12T00:17:18.521035: step 815, loss -19.9147, acc 0.90625\n",
      "2017-09-12T00:17:18.667943: step 816, loss -146.848, acc 1\n",
      "2017-09-12T00:17:18.771613: step 817, loss -102.777, acc 0.96875\n",
      "2017-09-12T00:17:18.862880: step 818, loss 2.16675, acc 0.84375\n",
      "2017-09-12T00:17:18.969919: step 819, loss -18.9102, acc 0.9375\n",
      "2017-09-12T00:17:19.150064: step 820, loss -74.5656, acc 0.96875\n",
      "2017-09-12T00:17:19.278025: step 821, loss -20.1927, acc 0.9375\n",
      "2017-09-12T00:17:19.565046: step 822, loss -239.226, acc 0.96875\n",
      "2017-09-12T00:17:19.950045: step 823, loss -58.2696, acc 0.96875\n",
      "2017-09-12T00:17:20.092736: step 824, loss -58.0598, acc 0.9375\n",
      "2017-09-12T00:17:20.205612: step 825, loss -65.2513, acc 0.90625\n",
      "2017-09-12T00:17:20.313296: step 826, loss -56.18, acc 0.96875\n",
      "2017-09-12T00:17:20.503406: step 827, loss -21.8434, acc 0.84375\n",
      "2017-09-12T00:17:20.616193: step 828, loss -113.757, acc 0.96875\n",
      "2017-09-12T00:17:20.716847: step 829, loss -157.995, acc 0.96875\n",
      "2017-09-12T00:17:20.827216: step 830, loss -97.5139, acc 0.9375\n",
      "2017-09-12T00:17:21.127096: step 831, loss -40.0755, acc 0.9375\n",
      "2017-09-12T00:17:21.271642: step 832, loss -56.582, acc 0.9375\n",
      "2017-09-12T00:17:21.436803: step 833, loss 11.0145, acc 0.90625\n",
      "2017-09-12T00:17:21.574348: step 834, loss -52.9187, acc 0.9375\n",
      "2017-09-12T00:17:21.743251: step 835, loss -79.7746, acc 0.9375\n",
      "2017-09-12T00:17:21.905169: step 836, loss -19.9917, acc 0.96875\n",
      "2017-09-12T00:17:22.068336: step 837, loss 10.5417, acc 0.84375\n",
      "2017-09-12T00:17:22.220325: step 838, loss -118.88, acc 0.9375\n",
      "2017-09-12T00:17:22.380418: step 839, loss -63.2753, acc 0.9375\n",
      "2017-09-12T00:17:22.524084: step 840, loss -131.909, acc 0.90625\n",
      "2017-09-12T00:17:22.683969: step 841, loss -91.2915, acc 0.875\n",
      "2017-09-12T00:17:22.955703: step 842, loss -53.0407, acc 0.875\n",
      "2017-09-12T00:17:23.103289: step 843, loss 11.6416, acc 0.8125\n",
      "2017-09-12T00:17:23.240510: step 844, loss -115.342, acc 0.96875\n",
      "2017-09-12T00:17:23.405916: step 845, loss -122.254, acc 0.875\n",
      "2017-09-12T00:17:23.550331: step 846, loss -163.76, acc 1\n",
      "2017-09-12T00:17:23.701478: step 847, loss -93.3812, acc 0.9375\n",
      "2017-09-12T00:17:23.850789: step 848, loss -8.47537, acc 0.875\n",
      "2017-09-12T00:17:23.994433: step 849, loss -114.82, acc 0.9375\n",
      "2017-09-12T00:17:24.163433: step 850, loss -21.0203, acc 0.875\n",
      "2017-09-12T00:17:24.318311: step 851, loss -70.0845, acc 0.96875\n",
      "2017-09-12T00:17:24.480655: step 852, loss -99.2785, acc 0.96875\n",
      "2017-09-12T00:17:24.624460: step 853, loss -44.5261, acc 0.90625\n",
      "2017-09-12T00:17:24.778946: step 854, loss -15.3323, acc 0.9375\n",
      "2017-09-12T00:17:24.924693: step 855, loss -12.1851, acc 0.875\n",
      "2017-09-12T00:17:25.075696: step 856, loss -58.3113, acc 0.9375\n",
      "2017-09-12T00:17:25.228164: step 857, loss -78.1607, acc 0.96875\n",
      "2017-09-12T00:17:25.385145: step 858, loss -152.492, acc 0.9375\n",
      "2017-09-12T00:17:25.538576: step 859, loss -61.0698, acc 0.90625\n",
      "2017-09-12T00:17:25.696604: step 860, loss 23.2746, acc 0.875\n",
      "2017-09-12T00:17:25.842024: step 861, loss -65.3671, acc 0.9375\n",
      "2017-09-12T00:17:26.007083: step 862, loss -19.4933, acc 0.90625\n",
      "2017-09-12T00:17:26.131900: step 863, loss 20.1345, acc 0.9375\n",
      "2017-09-12T00:17:26.299720: step 864, loss -80.8371, acc 0.9375\n",
      "2017-09-12T00:17:26.444047: step 865, loss -28.7508, acc 0.90625\n",
      "2017-09-12T00:17:26.604565: step 866, loss -192.108, acc 1\n",
      "2017-09-12T00:17:26.740172: step 867, loss 3.53411, acc 0.875\n",
      "2017-09-12T00:17:26.898948: step 868, loss -21.8985, acc 0.9375\n",
      "2017-09-12T00:17:27.047983: step 869, loss -62.0319, acc 0.96875\n",
      "2017-09-12T00:17:27.205320: step 870, loss 7.18826, acc 0.78125\n",
      "2017-09-12T00:17:27.351480: step 871, loss 22.3425, acc 0.875\n",
      "2017-09-12T00:17:27.540182: step 872, loss -60.2888, acc 0.9375\n",
      "2017-09-12T00:17:27.683029: step 873, loss 1.45956, acc 0.84375\n",
      "2017-09-12T00:17:27.836314: step 874, loss -47.4454, acc 0.875\n",
      "2017-09-12T00:17:27.996252: step 875, loss -21.0258, acc 0.875\n",
      "2017-09-12T00:17:28.154177: step 876, loss -87.7412, acc 0.9375\n",
      "2017-09-12T00:17:28.307894: step 877, loss -57.0567, acc 0.96875\n",
      "2017-09-12T00:17:28.458342: step 878, loss -25.316, acc 0.875\n",
      "2017-09-12T00:17:28.623013: step 879, loss 84.5545, acc 0.8125\n",
      "2017-09-12T00:17:28.808912: step 880, loss -159.049, acc 0.96875\n",
      "2017-09-12T00:17:29.112462: step 881, loss -32.4346, acc 0.875\n",
      "2017-09-12T00:17:29.290992: step 882, loss 53.1517, acc 0.8125\n",
      "2017-09-12T00:17:29.628473: step 883, loss -19.0689, acc 0.875\n",
      "2017-09-12T00:17:29.801303: step 884, loss -186.501, acc 0.96875\n",
      "2017-09-12T00:17:29.982148: step 885, loss -130.502, acc 0.96875\n",
      "2017-09-12T00:17:30.136996: step 886, loss -3.14148, acc 0.90625\n",
      "2017-09-12T00:17:30.325604: step 887, loss -80.805, acc 0.875\n",
      "2017-09-12T00:17:30.486896: step 888, loss -74.0595, acc 0.90625\n",
      "2017-09-12T00:17:30.679783: step 889, loss -87.1695, acc 0.9375\n",
      "2017-09-12T00:17:30.832444: step 890, loss -60.8395, acc 0.9375\n",
      "2017-09-12T00:17:31.012876: step 891, loss -73.527, acc 0.9375\n",
      "2017-09-12T00:17:31.191693: step 892, loss -135.143, acc 0.9375\n",
      "2017-09-12T00:17:31.371545: step 893, loss -19.7866, acc 0.9375\n",
      "2017-09-12T00:17:31.499992: step 894, loss -27.1024, acc 0.90625\n",
      "2017-09-12T00:17:31.656038: step 895, loss -71.7746, acc 0.9375\n",
      "2017-09-12T00:17:31.816297: step 896, loss -2.87427, acc 0.90625\n",
      "2017-09-12T00:17:31.988480: step 897, loss -73.3131, acc 0.96875\n",
      "2017-09-12T00:17:32.132597: step 898, loss -114.249, acc 0.96875\n",
      "2017-09-12T00:17:32.298016: step 899, loss -0.139439, acc 0.84375\n",
      "2017-09-12T00:17:32.507382: step 900, loss -143.75, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:17:34.001879: step 900, loss -88.7682, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-900\n",
      "\n",
      "2017-09-12T00:17:37.391247: step 901, loss -47.6668, acc 0.90625\n",
      "2017-09-12T00:17:37.499590: step 902, loss 22.9824, acc 0.90625\n",
      "2017-09-12T00:17:37.624947: step 903, loss -91.218, acc 1\n",
      "2017-09-12T00:17:37.734195: step 904, loss -132.618, acc 0.96875\n",
      "2017-09-12T00:17:37.874014: step 905, loss -143.718, acc 1\n",
      "2017-09-12T00:17:37.988902: step 906, loss -108.628, acc 0.9375\n",
      "2017-09-12T00:17:38.092584: step 907, loss -23.622, acc 0.96875\n",
      "2017-09-12T00:17:38.191983: step 908, loss -124.401, acc 0.90625\n",
      "2017-09-12T00:17:38.379005: step 909, loss -184.917, acc 0.96875\n",
      "2017-09-12T00:17:38.484953: step 910, loss -109.022, acc 0.96875\n",
      "2017-09-12T00:17:38.579064: step 911, loss -135.673, acc 0.90625\n",
      "2017-09-12T00:17:38.671384: step 912, loss -168.863, acc 0.9375\n",
      "2017-09-12T00:17:38.786623: step 913, loss -14.1094, acc 0.875\n",
      "2017-09-12T00:17:38.879663: step 914, loss -26.5421, acc 0.9375\n",
      "2017-09-12T00:17:38.976025: step 915, loss -49.8348, acc 0.90625\n",
      "2017-09-12T00:17:39.071474: step 916, loss -122.476, acc 0.96875\n",
      "2017-09-12T00:17:39.181412: step 917, loss -71.5386, acc 0.90625\n",
      "2017-09-12T00:17:39.278021: step 918, loss -240.183, acc 0.96875\n",
      "2017-09-12T00:17:39.365372: step 919, loss -312.053, acc 1\n",
      "2017-09-12T00:17:39.455233: step 920, loss -75.2689, acc 0.96875\n",
      "2017-09-12T00:17:39.542570: step 921, loss -99.5571, acc 0.90625\n",
      "2017-09-12T00:17:39.631023: step 922, loss -16.9518, acc 0.875\n",
      "2017-09-12T00:17:39.718063: step 923, loss -137.523, acc 0.9375\n",
      "2017-09-12T00:17:39.804886: step 924, loss -87.7487, acc 0.96875\n",
      "2017-09-12T00:17:40.060586: step 925, loss -167.463, acc 0.96875\n",
      "2017-09-12T00:17:40.202518: step 926, loss -29.4676, acc 0.875\n",
      "2017-09-12T00:17:40.334959: step 927, loss -212.759, acc 0.9375\n",
      "2017-09-12T00:17:40.483449: step 928, loss -6.53001, acc 0.84375\n",
      "2017-09-12T00:17:40.630935: step 929, loss -48.391, acc 0.875\n",
      "2017-09-12T00:17:40.790666: step 930, loss -150.304, acc 0.9375\n",
      "2017-09-12T00:17:40.957383: step 931, loss -125.373, acc 0.9375\n",
      "2017-09-12T00:17:41.140047: step 932, loss -192.374, acc 0.96875\n",
      "2017-09-12T00:17:41.303179: step 933, loss -130.573, acc 0.9375\n",
      "2017-09-12T00:17:41.454473: step 934, loss -103.157, acc 0.9375\n",
      "2017-09-12T00:17:41.627079: step 935, loss -178.342, acc 0.96875\n",
      "2017-09-12T00:17:41.778415: step 936, loss -39.5817, acc 0.9375\n",
      "2017-09-12T00:17:41.981615: step 937, loss -53.4932, acc 0.90625\n",
      "2017-09-12T00:17:42.142426: step 938, loss -102.604, acc 0.96875\n",
      "2017-09-12T00:17:42.290907: step 939, loss -150.18, acc 0.9375\n",
      "2017-09-12T00:17:42.430938: step 940, loss 38.5477, acc 0.8125\n",
      "2017-09-12T00:17:42.605790: step 941, loss -55.1516, acc 0.90625\n",
      "2017-09-12T00:17:42.754404: step 942, loss -118.069, acc 0.9375\n",
      "2017-09-12T00:17:42.894746: step 943, loss -109.182, acc 0.96875\n",
      "2017-09-12T00:17:43.035035: step 944, loss -133.323, acc 0.9375\n",
      "2017-09-12T00:17:43.187462: step 945, loss -83.8452, acc 0.96875\n",
      "2017-09-12T00:17:43.374209: step 946, loss -156.107, acc 0.9375\n",
      "2017-09-12T00:17:43.516407: step 947, loss -222.414, acc 1\n",
      "2017-09-12T00:17:43.670786: step 948, loss -145.505, acc 0.875\n",
      "2017-09-12T00:17:43.814574: step 949, loss -161.12, acc 0.9375\n",
      "2017-09-12T00:17:43.981270: step 950, loss -81.5327, acc 0.90625\n",
      "2017-09-12T00:17:44.118305: step 951, loss -104.781, acc 0.90625\n",
      "2017-09-12T00:17:44.273737: step 952, loss -85.2485, acc 0.9375\n",
      "2017-09-12T00:17:44.420890: step 953, loss -81.323, acc 0.84375\n",
      "2017-09-12T00:17:44.573117: step 954, loss 86.1393, acc 0.8125\n",
      "2017-09-12T00:17:44.727012: step 955, loss 25.1838, acc 0.84375\n",
      "2017-09-12T00:17:44.880165: step 956, loss -51.6248, acc 0.90625\n",
      "2017-09-12T00:17:45.038814: step 957, loss -78.8235, acc 0.9375\n",
      "2017-09-12T00:17:45.176920: step 958, loss -131.46, acc 0.90625\n",
      "2017-09-12T00:17:45.328864: step 959, loss -190.13, acc 1\n",
      "2017-09-12T00:17:45.474438: step 960, loss -95.0728, acc 0.90625\n",
      "2017-09-12T00:17:45.633500: step 961, loss -136.251, acc 0.9375\n",
      "2017-09-12T00:17:45.764841: step 962, loss -223.078, acc 0.9375\n",
      "2017-09-12T00:17:45.922836: step 963, loss -83.6526, acc 0.96875\n",
      "2017-09-12T00:17:46.063529: step 964, loss -126.39, acc 0.96875\n",
      "2017-09-12T00:17:46.221265: step 965, loss 31.0216, acc 0.84375\n",
      "2017-09-12T00:17:46.371622: step 966, loss -245.223, acc 1\n",
      "2017-09-12T00:17:46.543480: step 967, loss -65.7286, acc 0.875\n",
      "2017-09-12T00:17:46.697490: step 968, loss -82.6951, acc 0.9375\n",
      "2017-09-12T00:17:46.848393: step 969, loss -130.644, acc 0.96875\n",
      "2017-09-12T00:17:46.995295: step 970, loss -129.4, acc 0.90625\n",
      "2017-09-12T00:17:47.150105: step 971, loss -162.416, acc 1\n",
      "2017-09-12T00:17:47.301449: step 972, loss -54.694, acc 0.90625\n",
      "2017-09-12T00:17:47.453947: step 973, loss -111.534, acc 0.90625\n",
      "2017-09-12T00:17:47.608555: step 974, loss 4.46932, acc 0.9375\n",
      "2017-09-12T00:17:47.743980: step 975, loss -119.891, acc 0.9375\n",
      "2017-09-12T00:17:47.905130: step 976, loss -146.813, acc 0.90625\n",
      "2017-09-12T00:17:48.043608: step 977, loss -55.5966, acc 0.9375\n",
      "2017-09-12T00:17:48.191833: step 978, loss -229.331, acc 0.96875\n",
      "2017-09-12T00:17:48.340900: step 979, loss -46.1688, acc 0.875\n",
      "2017-09-12T00:17:48.496298: step 980, loss -272.787, acc 1\n",
      "2017-09-12T00:17:48.658886: step 981, loss -82.1077, acc 1\n",
      "2017-09-12T00:17:48.799870: step 982, loss -76.3083, acc 0.875\n",
      "2017-09-12T00:17:48.937427: step 983, loss -117.382, acc 0.96875\n",
      "2017-09-12T00:17:49.101427: step 984, loss -52.2151, acc 0.96875\n",
      "2017-09-12T00:17:49.266136: step 985, loss -91.0954, acc 0.9375\n",
      "2017-09-12T00:17:49.431199: step 986, loss -65.6562, acc 0.875\n",
      "2017-09-12T00:17:49.568143: step 987, loss -67.3572, acc 0.96875\n",
      "2017-09-12T00:17:49.720065: step 988, loss -212.404, acc 0.90625\n",
      "2017-09-12T00:17:49.871466: step 989, loss -85.9834, acc 0.9375\n",
      "2017-09-12T00:17:50.012067: step 990, loss -256.17, acc 1\n",
      "2017-09-12T00:17:50.182063: step 991, loss 10.8532, acc 0.90625\n",
      "2017-09-12T00:17:50.323575: step 992, loss -62.2015, acc 0.90625\n",
      "2017-09-12T00:17:50.489293: step 993, loss -205.239, acc 0.96875\n",
      "2017-09-12T00:17:50.673200: step 994, loss -147.781, acc 0.9375\n",
      "2017-09-12T00:17:50.831020: step 995, loss 0.445396, acc 0.9375\n",
      "2017-09-12T00:17:51.017433: step 996, loss -197.431, acc 1\n",
      "2017-09-12T00:17:51.144977: step 997, loss -46.3398, acc 0.875\n",
      "2017-09-12T00:17:51.328442: step 998, loss -123.703, acc 0.90625\n",
      "2017-09-12T00:17:51.504165: step 999, loss -124.875, acc 0.9375\n",
      "2017-09-12T00:17:51.671726: step 1000, loss -123.845, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:17:53.086628: step 1000, loss -119.518, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1000\n",
      "\n",
      "2017-09-12T00:17:55.576534: step 1001, loss -209.482, acc 0.96875\n",
      "2017-09-12T00:17:55.664975: step 1002, loss -62.3975, acc 0.875\n",
      "2017-09-12T00:17:55.788653: step 1003, loss -93.589, acc 0.9375\n",
      "2017-09-12T00:17:55.947467: step 1004, loss -90.271, acc 0.96875\n",
      "2017-09-12T00:17:56.103270: step 1005, loss -147.606, acc 0.9375\n",
      "2017-09-12T00:17:56.201893: step 1006, loss -63.4198, acc 0.90625\n",
      "2017-09-12T00:17:56.325746: step 1007, loss -94.0247, acc 0.9375\n",
      "2017-09-12T00:17:56.451866: step 1008, loss -88.6971, acc 0.9375\n",
      "2017-09-12T00:17:56.542710: step 1009, loss -285.424, acc 1\n",
      "2017-09-12T00:17:56.640988: step 1010, loss -218.145, acc 0.96875\n",
      "2017-09-12T00:17:56.838543: step 1011, loss -131.451, acc 0.875\n",
      "2017-09-12T00:17:56.927358: step 1012, loss -9.97044, acc 0.90625\n",
      "2017-09-12T00:17:57.110132: step 1013, loss -102.514, acc 0.9375\n",
      "2017-09-12T00:17:57.200149: step 1014, loss -99.7102, acc 0.9375\n",
      "2017-09-12T00:17:57.287914: step 1015, loss 38.1801, acc 0.875\n",
      "2017-09-12T00:17:57.378200: step 1016, loss -59.9214, acc 0.875\n",
      "2017-09-12T00:17:57.523852: step 1017, loss 133.913, acc 0.78125\n",
      "2017-09-12T00:17:57.645201: step 1018, loss -1.6891, acc 0.875\n",
      "2017-09-12T00:17:57.737883: step 1019, loss -104.781, acc 0.9375\n",
      "2017-09-12T00:17:57.830712: step 1020, loss -127.976, acc 0.96875\n",
      "2017-09-12T00:17:57.923820: step 1021, loss -102.751, acc 0.90625\n",
      "2017-09-12T00:17:58.017535: step 1022, loss -61.0966, acc 0.875\n",
      "2017-09-12T00:17:58.109001: step 1023, loss -248.78, acc 1\n",
      "2017-09-12T00:17:58.200136: step 1024, loss -167.637, acc 0.9375\n",
      "2017-09-12T00:17:58.290253: step 1025, loss -125.705, acc 0.90625\n",
      "2017-09-12T00:17:58.378254: step 1026, loss -259.089, acc 1\n",
      "2017-09-12T00:17:58.465464: step 1027, loss 23.04, acc 0.875\n",
      "2017-09-12T00:17:58.555141: step 1028, loss -197.42, acc 0.90625\n",
      "2017-09-12T00:17:58.644321: step 1029, loss 69.7874, acc 0.8125\n",
      "2017-09-12T00:17:58.865541: step 1030, loss -101.784, acc 0.90625\n",
      "2017-09-12T00:17:59.046460: step 1031, loss -134.002, acc 1\n",
      "2017-09-12T00:17:59.205153: step 1032, loss 57.5487, acc 0.84375\n",
      "2017-09-12T00:17:59.363542: step 1033, loss -232.899, acc 0.96875\n",
      "2017-09-12T00:17:59.514945: step 1034, loss -176.933, acc 0.875\n",
      "2017-09-12T00:17:59.647265: step 1035, loss 18.0374, acc 0.84375\n",
      "2017-09-12T00:17:59.811521: step 1036, loss -153.808, acc 0.96875\n",
      "2017-09-12T00:17:59.965646: step 1037, loss -1.98109, acc 0.84375\n",
      "2017-09-12T00:18:00.127380: step 1038, loss -0.0564156, acc 0.84375\n",
      "2017-09-12T00:18:00.267397: step 1039, loss -161.94, acc 0.9375\n",
      "2017-09-12T00:18:00.421548: step 1040, loss -30.3969, acc 0.9375\n",
      "2017-09-12T00:18:00.559105: step 1041, loss -48.3475, acc 0.875\n",
      "2017-09-12T00:18:00.724539: step 1042, loss -235.33, acc 0.90625\n",
      "2017-09-12T00:18:00.852264: step 1043, loss -70.3727, acc 0.9375\n",
      "2017-09-12T00:18:00.996339: step 1044, loss -62.2726, acc 0.90625\n",
      "2017-09-12T00:18:01.152174: step 1045, loss 61.3081, acc 0.875\n",
      "2017-09-12T00:18:01.300786: step 1046, loss -196.414, acc 0.96875\n",
      "2017-09-12T00:18:01.452453: step 1047, loss -159.673, acc 0.875\n",
      "2017-09-12T00:18:01.613917: step 1048, loss -106.464, acc 0.96875\n",
      "2017-09-12T00:18:01.753317: step 1049, loss -66.2602, acc 0.9375\n",
      "2017-09-12T00:18:01.910821: step 1050, loss -64.6326, acc 0.9375\n",
      "2017-09-12T00:18:02.046547: step 1051, loss -219.049, acc 0.96875\n",
      "2017-09-12T00:18:02.096791: step 1052, loss -421.107, acc 1\n",
      "2017-09-12T00:18:02.249397: step 1053, loss -108.04, acc 0.96875\n",
      "2017-09-12T00:18:02.409254: step 1054, loss -268.013, acc 1\n",
      "2017-09-12T00:18:02.551097: step 1055, loss -129.911, acc 0.96875\n",
      "2017-09-12T00:18:02.720101: step 1056, loss -159.68, acc 0.96875\n",
      "2017-09-12T00:18:02.880869: step 1057, loss -213.569, acc 0.9375\n",
      "2017-09-12T00:18:03.008724: step 1058, loss -282.543, acc 0.96875\n",
      "2017-09-12T00:18:03.164157: step 1059, loss -62.7478, acc 0.9375\n",
      "2017-09-12T00:18:03.329900: step 1060, loss -107.788, acc 0.90625\n",
      "2017-09-12T00:18:03.485109: step 1061, loss -205.732, acc 0.9375\n",
      "2017-09-12T00:18:03.637538: step 1062, loss -46.3042, acc 0.90625\n",
      "2017-09-12T00:18:03.794847: step 1063, loss -82.736, acc 0.90625\n",
      "2017-09-12T00:18:03.949015: step 1064, loss -48.1112, acc 0.9375\n",
      "2017-09-12T00:18:04.100010: step 1065, loss -76.1443, acc 0.9375\n",
      "2017-09-12T00:18:04.241722: step 1066, loss -31.7866, acc 0.9375\n",
      "2017-09-12T00:18:04.392776: step 1067, loss -143.527, acc 0.9375\n",
      "2017-09-12T00:18:04.542060: step 1068, loss -261.545, acc 1\n",
      "2017-09-12T00:18:04.698536: step 1069, loss 39.1626, acc 0.84375\n",
      "2017-09-12T00:18:04.855302: step 1070, loss -320.56, acc 0.96875\n",
      "2017-09-12T00:18:05.023359: step 1071, loss -173.756, acc 1\n",
      "2017-09-12T00:18:05.172479: step 1072, loss -271.323, acc 0.96875\n",
      "2017-09-12T00:18:05.343596: step 1073, loss -256.531, acc 1\n",
      "2017-09-12T00:18:05.483842: step 1074, loss -205.842, acc 0.9375\n",
      "2017-09-12T00:18:05.638101: step 1075, loss -246.028, acc 0.96875\n",
      "2017-09-12T00:18:05.796950: step 1076, loss -28.0247, acc 0.875\n",
      "2017-09-12T00:18:05.939554: step 1077, loss -68.9427, acc 0.9375\n",
      "2017-09-12T00:18:06.097941: step 1078, loss -148.515, acc 0.9375\n",
      "2017-09-12T00:18:06.244479: step 1079, loss -104.934, acc 0.9375\n",
      "2017-09-12T00:18:06.387992: step 1080, loss -22.1539, acc 0.84375\n",
      "2017-09-12T00:18:06.548299: step 1081, loss -74.4809, acc 0.875\n",
      "2017-09-12T00:18:06.701640: step 1082, loss 19.3116, acc 0.875\n",
      "2017-09-12T00:18:06.863263: step 1083, loss -451.647, acc 1\n",
      "2017-09-12T00:18:06.997144: step 1084, loss 34.0567, acc 0.875\n",
      "2017-09-12T00:18:07.146422: step 1085, loss -112.907, acc 0.90625\n",
      "2017-09-12T00:18:07.289413: step 1086, loss -141.923, acc 0.90625\n",
      "2017-09-12T00:18:07.451599: step 1087, loss -258.044, acc 1\n",
      "2017-09-12T00:18:07.608239: step 1088, loss -71.1317, acc 0.90625\n",
      "2017-09-12T00:18:07.745034: step 1089, loss -211.688, acc 0.9375\n",
      "2017-09-12T00:18:07.891801: step 1090, loss -228.405, acc 0.9375\n",
      "2017-09-12T00:18:08.017697: step 1091, loss 67.8968, acc 0.84375\n",
      "2017-09-12T00:18:08.173717: step 1092, loss 75.2732, acc 0.84375\n",
      "2017-09-12T00:18:08.331171: step 1093, loss -79.2552, acc 1\n",
      "2017-09-12T00:18:08.467467: step 1094, loss -272.371, acc 1\n",
      "2017-09-12T00:18:08.631991: step 1095, loss -218.7, acc 0.96875\n",
      "2017-09-12T00:18:08.775599: step 1096, loss -33.8517, acc 0.90625\n",
      "2017-09-12T00:18:08.927362: step 1097, loss 37.0052, acc 0.875\n",
      "2017-09-12T00:18:09.087795: step 1098, loss 65.4818, acc 0.90625\n",
      "2017-09-12T00:18:09.243661: step 1099, loss -168.547, acc 0.9375\n",
      "2017-09-12T00:18:09.387370: step 1100, loss 36.2163, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:18:10.838861: step 1100, loss -151.686, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1100\n",
      "\n",
      "2017-09-12T00:18:13.139384: step 1101, loss -11.2998, acc 0.875\n",
      "2017-09-12T00:18:13.222982: step 1102, loss -102.984, acc 0.9375\n",
      "2017-09-12T00:18:13.323299: step 1103, loss -242.543, acc 1\n",
      "2017-09-12T00:18:13.454037: step 1104, loss -170.779, acc 0.90625\n",
      "2017-09-12T00:18:13.588861: step 1105, loss -7.95677, acc 0.90625\n",
      "2017-09-12T00:18:13.729073: step 1106, loss -76.2015, acc 0.90625\n",
      "2017-09-12T00:18:13.909271: step 1107, loss -95.0147, acc 0.9375\n",
      "2017-09-12T00:18:14.032507: step 1108, loss -152.193, acc 0.90625\n",
      "2017-09-12T00:18:14.132358: step 1109, loss 109.701, acc 0.84375\n",
      "2017-09-12T00:18:14.247724: step 1110, loss -32.6845, acc 0.84375\n",
      "2017-09-12T00:18:14.344071: step 1111, loss -251.735, acc 0.9375\n",
      "2017-09-12T00:18:14.440742: step 1112, loss -111.268, acc 0.90625\n",
      "2017-09-12T00:18:14.538443: step 1113, loss -284.732, acc 0.9375\n",
      "2017-09-12T00:18:14.625504: step 1114, loss 97.5077, acc 0.8125\n",
      "2017-09-12T00:18:14.755453: step 1115, loss -14.8277, acc 0.84375\n",
      "2017-09-12T00:18:14.855774: step 1116, loss -84.4471, acc 0.90625\n",
      "2017-09-12T00:18:14.958446: step 1117, loss -108.771, acc 0.875\n",
      "2017-09-12T00:18:15.070573: step 1118, loss -251.848, acc 0.96875\n",
      "2017-09-12T00:18:15.158631: step 1119, loss -83.2685, acc 0.9375\n",
      "2017-09-12T00:18:15.242252: step 1120, loss -155.367, acc 0.90625\n",
      "2017-09-12T00:18:15.331390: step 1121, loss -238.506, acc 1\n",
      "2017-09-12T00:18:15.421491: step 1122, loss -112.318, acc 0.9375\n",
      "2017-09-12T00:18:15.510635: step 1123, loss -419.492, acc 0.96875\n",
      "2017-09-12T00:18:15.597739: step 1124, loss -368.147, acc 1\n",
      "2017-09-12T00:18:15.689132: step 1125, loss -204.245, acc 0.9375\n",
      "2017-09-12T00:18:15.792756: step 1126, loss 42.5538, acc 0.875\n",
      "2017-09-12T00:18:15.876155: step 1127, loss -202.203, acc 0.96875\n",
      "2017-09-12T00:18:16.133228: step 1128, loss 10.9589, acc 0.90625\n",
      "2017-09-12T00:18:16.274001: step 1129, loss 38.1431, acc 0.875\n",
      "2017-09-12T00:18:16.423124: step 1130, loss -88.9448, acc 0.90625\n",
      "2017-09-12T00:18:16.564710: step 1131, loss -40.1034, acc 0.96875\n",
      "2017-09-12T00:18:16.710236: step 1132, loss -250.592, acc 0.9375\n",
      "2017-09-12T00:18:16.864386: step 1133, loss -423.156, acc 0.9375\n",
      "2017-09-12T00:18:17.007114: step 1134, loss 139.351, acc 0.75\n",
      "2017-09-12T00:18:17.180470: step 1135, loss -116.613, acc 0.9375\n",
      "2017-09-12T00:18:17.325832: step 1136, loss -0.27314, acc 0.9375\n",
      "2017-09-12T00:18:17.481465: step 1137, loss 80.7742, acc 0.875\n",
      "2017-09-12T00:18:17.627236: step 1138, loss -170.111, acc 0.96875\n",
      "2017-09-12T00:18:17.789091: step 1139, loss -326.477, acc 0.96875\n",
      "2017-09-12T00:18:17.945405: step 1140, loss -18.0177, acc 0.84375\n",
      "2017-09-12T00:18:18.085397: step 1141, loss -124.515, acc 0.96875\n",
      "2017-09-12T00:18:18.236817: step 1142, loss -234.374, acc 0.9375\n",
      "2017-09-12T00:18:18.381144: step 1143, loss -157.474, acc 0.96875\n",
      "2017-09-12T00:18:18.545415: step 1144, loss -302.338, acc 0.96875\n",
      "2017-09-12T00:18:18.691636: step 1145, loss -185.624, acc 0.875\n",
      "2017-09-12T00:18:18.839136: step 1146, loss 86.2368, acc 0.90625\n",
      "2017-09-12T00:18:18.994205: step 1147, loss -253.99, acc 0.96875\n",
      "2017-09-12T00:18:19.135145: step 1148, loss -238.925, acc 0.9375\n",
      "2017-09-12T00:18:19.271280: step 1149, loss -35.1282, acc 0.84375\n",
      "2017-09-12T00:18:19.424001: step 1150, loss -48.6169, acc 0.9375\n",
      "2017-09-12T00:18:19.590883: step 1151, loss -113.75, acc 0.9375\n",
      "2017-09-12T00:18:19.721633: step 1152, loss -126.848, acc 1\n",
      "2017-09-12T00:18:19.873842: step 1153, loss -270.049, acc 1\n",
      "2017-09-12T00:18:20.022106: step 1154, loss -269.703, acc 0.90625\n",
      "2017-09-12T00:18:20.169174: step 1155, loss -320.275, acc 0.9375\n",
      "2017-09-12T00:18:20.329694: step 1156, loss -47.0007, acc 0.90625\n",
      "2017-09-12T00:18:20.462891: step 1157, loss -292.887, acc 0.9375\n",
      "2017-09-12T00:18:20.605802: step 1158, loss -138.864, acc 0.9375\n",
      "2017-09-12T00:18:20.761051: step 1159, loss -42.4067, acc 0.875\n",
      "2017-09-12T00:18:20.900339: step 1160, loss -137.762, acc 0.9375\n",
      "2017-09-12T00:18:21.065739: step 1161, loss -236.817, acc 0.9375\n",
      "2017-09-12T00:18:21.210783: step 1162, loss -404.49, acc 0.96875\n",
      "2017-09-12T00:18:21.364685: step 1163, loss -98.9402, acc 0.90625\n",
      "2017-09-12T00:18:21.504643: step 1164, loss -230.099, acc 0.96875\n",
      "2017-09-12T00:18:21.648276: step 1165, loss 83.6128, acc 0.90625\n",
      "2017-09-12T00:18:21.812859: step 1166, loss -140.897, acc 0.9375\n",
      "2017-09-12T00:18:21.972101: step 1167, loss -188.852, acc 0.9375\n",
      "2017-09-12T00:18:22.120130: step 1168, loss 128.559, acc 0.90625\n",
      "2017-09-12T00:18:22.289287: step 1169, loss -232.064, acc 0.875\n",
      "2017-09-12T00:18:22.438649: step 1170, loss -145.681, acc 0.90625\n",
      "2017-09-12T00:18:22.572212: step 1171, loss -309.624, acc 0.96875\n",
      "2017-09-12T00:18:22.795469: step 1172, loss -181.935, acc 0.96875\n",
      "2017-09-12T00:18:22.951415: step 1173, loss -111.498, acc 0.875\n",
      "2017-09-12T00:18:23.100590: step 1174, loss -393.287, acc 0.9375\n",
      "2017-09-12T00:18:23.268904: step 1175, loss -216.895, acc 0.9375\n",
      "2017-09-12T00:18:23.426579: step 1176, loss -360.587, acc 0.96875\n",
      "2017-09-12T00:18:23.565604: step 1177, loss -39.7872, acc 0.96875\n",
      "2017-09-12T00:18:23.719925: step 1178, loss -35.5272, acc 0.875\n",
      "2017-09-12T00:18:23.876571: step 1179, loss -1.49719, acc 0.84375\n",
      "2017-09-12T00:18:24.039392: step 1180, loss -154.45, acc 0.90625\n",
      "2017-09-12T00:18:24.177972: step 1181, loss -461.439, acc 0.9375\n",
      "2017-09-12T00:18:24.346936: step 1182, loss -144.142, acc 0.96875\n",
      "2017-09-12T00:18:24.512417: step 1183, loss -42.0585, acc 0.875\n",
      "2017-09-12T00:18:24.669454: step 1184, loss -188.101, acc 0.90625\n",
      "2017-09-12T00:18:24.831032: step 1185, loss -126.111, acc 0.875\n",
      "2017-09-12T00:18:24.982556: step 1186, loss -374.958, acc 0.9375\n",
      "2017-09-12T00:18:25.127592: step 1187, loss -183.879, acc 0.96875\n",
      "2017-09-12T00:18:25.276637: step 1188, loss -94.9055, acc 0.90625\n",
      "2017-09-12T00:18:25.419067: step 1189, loss -184.177, acc 0.90625\n",
      "2017-09-12T00:18:25.569504: step 1190, loss 55.4046, acc 0.84375\n",
      "2017-09-12T00:18:25.732388: step 1191, loss 54.0764, acc 0.8125\n",
      "2017-09-12T00:18:25.879532: step 1192, loss -178.244, acc 0.9375\n",
      "2017-09-12T00:18:26.038321: step 1193, loss -143.243, acc 0.9375\n",
      "2017-09-12T00:18:26.202694: step 1194, loss -141.461, acc 0.96875\n",
      "2017-09-12T00:18:26.350073: step 1195, loss -235.985, acc 0.96875\n",
      "2017-09-12T00:18:26.502284: step 1196, loss 135.627, acc 0.875\n",
      "2017-09-12T00:18:26.643770: step 1197, loss -372.774, acc 1\n",
      "2017-09-12T00:18:26.802605: step 1198, loss -412.872, acc 1\n",
      "2017-09-12T00:18:26.953594: step 1199, loss -318.742, acc 1\n",
      "2017-09-12T00:18:27.113525: step 1200, loss -227.775, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:18:28.588946: step 1200, loss -186.499, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1200\n",
      "\n",
      "2017-09-12T00:18:30.692517: step 1201, loss -139.117, acc 0.90625\n",
      "2017-09-12T00:18:30.776990: step 1202, loss -278.759, acc 0.9375\n",
      "2017-09-12T00:18:30.902956: step 1203, loss -99.4651, acc 0.875\n",
      "2017-09-12T00:18:31.042034: step 1204, loss -182.329, acc 0.90625\n",
      "2017-09-12T00:18:31.203019: step 1205, loss -211.947, acc 0.90625\n",
      "2017-09-12T00:18:31.385055: step 1206, loss -317.23, acc 0.84375\n",
      "2017-09-12T00:18:31.530950: step 1207, loss -388.092, acc 0.9375\n",
      "2017-09-12T00:18:31.668659: step 1208, loss -149.555, acc 0.96875\n",
      "2017-09-12T00:18:31.798655: step 1209, loss -60.0541, acc 0.84375\n",
      "2017-09-12T00:18:31.898498: step 1210, loss -241.198, acc 0.9375\n",
      "2017-09-12T00:18:31.991718: step 1211, loss -357.921, acc 0.96875\n",
      "2017-09-12T00:18:32.101616: step 1212, loss -130.195, acc 0.9375\n",
      "2017-09-12T00:18:32.226114: step 1213, loss -286.755, acc 0.96875\n",
      "2017-09-12T00:18:32.327322: step 1214, loss -11.1655, acc 0.875\n",
      "2017-09-12T00:18:32.422642: step 1215, loss -404.973, acc 1\n",
      "2017-09-12T00:18:32.519278: step 1216, loss -228.433, acc 0.9375\n",
      "2017-09-12T00:18:32.609702: step 1217, loss 103.385, acc 0.8125\n",
      "2017-09-12T00:18:32.700397: step 1218, loss -320.244, acc 0.90625\n",
      "2017-09-12T00:18:32.789904: step 1219, loss -244.06, acc 0.96875\n",
      "2017-09-12T00:18:32.879076: step 1220, loss -252.452, acc 0.9375\n",
      "2017-09-12T00:18:32.981011: step 1221, loss -153.505, acc 0.9375\n",
      "2017-09-12T00:18:33.073566: step 1222, loss 5.98407, acc 0.875\n",
      "2017-09-12T00:18:33.165903: step 1223, loss -296.602, acc 0.96875\n",
      "2017-09-12T00:18:33.250678: step 1224, loss -290.546, acc 0.90625\n",
      "2017-09-12T00:18:33.338805: step 1225, loss -263.682, acc 0.90625\n",
      "2017-09-12T00:18:33.575756: step 1226, loss -132.768, acc 0.90625\n",
      "2017-09-12T00:18:33.722042: step 1227, loss 300.108, acc 0.78125\n",
      "2017-09-12T00:18:33.873439: step 1228, loss -421.063, acc 0.96875\n",
      "2017-09-12T00:18:34.013824: step 1229, loss -324.765, acc 0.96875\n",
      "2017-09-12T00:18:34.160214: step 1230, loss 29.0704, acc 0.875\n",
      "2017-09-12T00:18:34.312205: step 1231, loss -107.748, acc 0.96875\n",
      "2017-09-12T00:18:34.456564: step 1232, loss -43.4563, acc 0.96875\n",
      "2017-09-12T00:18:34.609166: step 1233, loss -346.837, acc 1\n",
      "2017-09-12T00:18:34.760672: step 1234, loss -306.823, acc 0.9375\n",
      "2017-09-12T00:18:34.893562: step 1235, loss -32.4652, acc 0.9375\n",
      "2017-09-12T00:18:35.041065: step 1236, loss -302.761, acc 0.96875\n",
      "2017-09-12T00:18:35.180644: step 1237, loss -13.4338, acc 0.875\n",
      "2017-09-12T00:18:35.356660: step 1238, loss -110.907, acc 0.875\n",
      "2017-09-12T00:18:35.518796: step 1239, loss -297.614, acc 0.90625\n",
      "2017-09-12T00:18:35.680958: step 1240, loss -169.946, acc 0.875\n",
      "2017-09-12T00:18:35.822039: step 1241, loss 41.8875, acc 0.875\n",
      "2017-09-12T00:18:35.996168: step 1242, loss -214.394, acc 0.9375\n",
      "2017-09-12T00:18:36.128624: step 1243, loss -150.317, acc 0.9375\n",
      "2017-09-12T00:18:36.285147: step 1244, loss 64.3878, acc 0.9375\n",
      "2017-09-12T00:18:36.428613: step 1245, loss -105.053, acc 0.9375\n",
      "2017-09-12T00:18:36.575156: step 1246, loss -104.801, acc 0.96875\n",
      "2017-09-12T00:18:36.762760: step 1247, loss -55.3347, acc 0.90625\n",
      "2017-09-12T00:18:36.912615: step 1248, loss -473.438, acc 1\n",
      "2017-09-12T00:18:37.051015: step 1249, loss -327.483, acc 0.90625\n",
      "2017-09-12T00:18:37.235680: step 1250, loss -136.334, acc 0.84375\n",
      "2017-09-12T00:18:37.358222: step 1251, loss 41.8795, acc 0.875\n",
      "2017-09-12T00:18:37.533563: step 1252, loss 9.87213, acc 0.84375\n",
      "2017-09-12T00:18:37.672705: step 1253, loss 97.69, acc 0.90625\n",
      "2017-09-12T00:18:37.852087: step 1254, loss -407.455, acc 0.96875\n",
      "2017-09-12T00:18:37.981699: step 1255, loss -118.933, acc 0.90625\n",
      "2017-09-12T00:18:38.151196: step 1256, loss -281.352, acc 0.96875\n",
      "2017-09-12T00:18:38.292469: step 1257, loss 16.6883, acc 0.875\n",
      "2017-09-12T00:18:38.457648: step 1258, loss -88.487, acc 0.90625\n",
      "2017-09-12T00:18:38.605589: step 1259, loss -378.563, acc 0.9375\n",
      "2017-09-12T00:18:38.764559: step 1260, loss -153.632, acc 0.96875\n",
      "2017-09-12T00:18:38.958876: step 1261, loss -86.4132, acc 0.84375\n",
      "2017-09-12T00:18:39.101098: step 1262, loss -38.7387, acc 0.9375\n",
      "2017-09-12T00:18:39.245683: step 1263, loss -285.566, acc 0.9375\n",
      "2017-09-12T00:18:39.401489: step 1264, loss -104.21, acc 0.875\n",
      "2017-09-12T00:18:39.548587: step 1265, loss -264.457, acc 0.9375\n",
      "2017-09-12T00:18:39.705863: step 1266, loss -270.121, acc 0.96875\n",
      "2017-09-12T00:18:39.840438: step 1267, loss -451.356, acc 1\n",
      "2017-09-12T00:18:39.982619: step 1268, loss -0.699638, acc 0.90625\n",
      "2017-09-12T00:18:40.154752: step 1269, loss -326.11, acc 1\n",
      "2017-09-12T00:18:40.292425: step 1270, loss -239.167, acc 0.875\n",
      "2017-09-12T00:18:40.444802: step 1271, loss -234.323, acc 0.96875\n",
      "2017-09-12T00:18:40.593318: step 1272, loss -293.335, acc 0.9375\n",
      "2017-09-12T00:18:40.765262: step 1273, loss -448.345, acc 0.96875\n",
      "2017-09-12T00:18:40.912150: step 1274, loss -177.401, acc 0.96875\n",
      "2017-09-12T00:18:41.059381: step 1275, loss -270.748, acc 1\n",
      "2017-09-12T00:18:41.204461: step 1276, loss -284.581, acc 0.875\n",
      "2017-09-12T00:18:41.354922: step 1277, loss -207.426, acc 0.90625\n",
      "2017-09-12T00:18:41.501489: step 1278, loss -259.223, acc 1\n",
      "2017-09-12T00:18:41.645666: step 1279, loss -283.122, acc 0.96875\n",
      "2017-09-12T00:18:41.809724: step 1280, loss -36.7726, acc 0.875\n",
      "2017-09-12T00:18:41.952657: step 1281, loss -108.785, acc 0.875\n",
      "2017-09-12T00:18:42.184688: step 1282, loss -54.3491, acc 0.875\n",
      "2017-09-12T00:18:42.311290: step 1283, loss -469.749, acc 0.96875\n",
      "2017-09-12T00:18:42.456928: step 1284, loss -61.9158, acc 0.875\n",
      "2017-09-12T00:18:42.611997: step 1285, loss -565.336, acc 0.96875\n",
      "2017-09-12T00:18:42.799132: step 1286, loss -191.517, acc 0.9375\n",
      "2017-09-12T00:18:42.944662: step 1287, loss -291.986, acc 0.90625\n",
      "2017-09-12T00:18:43.086189: step 1288, loss -460.035, acc 1\n",
      "2017-09-12T00:18:43.230904: step 1289, loss -298.238, acc 0.875\n",
      "2017-09-12T00:18:43.422294: step 1290, loss -180.777, acc 0.9375\n",
      "2017-09-12T00:18:43.567100: step 1291, loss -53.7136, acc 0.90625\n",
      "2017-09-12T00:18:43.728803: step 1292, loss -108.964, acc 0.9375\n",
      "2017-09-12T00:18:43.861033: step 1293, loss 48.6991, acc 0.84375\n",
      "2017-09-12T00:18:43.994042: step 1294, loss -12.0221, acc 0.90625\n",
      "2017-09-12T00:18:44.167482: step 1295, loss -114.363, acc 0.9375\n",
      "2017-09-12T00:18:44.319732: step 1296, loss -116.194, acc 0.9375\n",
      "2017-09-12T00:18:44.469953: step 1297, loss -183.399, acc 0.96875\n",
      "2017-09-12T00:18:44.617520: step 1298, loss -260.279, acc 0.9375\n",
      "2017-09-12T00:18:44.771348: step 1299, loss -283.296, acc 0.96875\n",
      "2017-09-12T00:18:44.934041: step 1300, loss -48.0863, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:18:46.343067: step 1300, loss -230.489, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1300\n",
      "\n",
      "2017-09-12T00:18:49.356788: step 1301, loss -187.963, acc 0.96875\n",
      "2017-09-12T00:18:49.451513: step 1302, loss -283.188, acc 0.96875\n",
      "2017-09-12T00:18:49.554510: step 1303, loss -181.189, acc 0.90625\n",
      "2017-09-12T00:18:49.775330: step 1304, loss -387.516, acc 0.96875\n",
      "2017-09-12T00:18:50.068245: step 1305, loss -200.039, acc 0.875\n",
      "2017-09-12T00:18:50.223868: step 1306, loss -74.391, acc 0.875\n",
      "2017-09-12T00:18:50.411386: step 1307, loss -32.5644, acc 0.875\n",
      "2017-09-12T00:18:50.570535: step 1308, loss -244.54, acc 0.9375\n",
      "2017-09-12T00:18:50.693693: step 1309, loss -18.2666, acc 0.875\n",
      "2017-09-12T00:18:50.806470: step 1310, loss -171.34, acc 0.96875\n",
      "2017-09-12T00:18:50.937236: step 1311, loss -227.541, acc 0.90625\n",
      "2017-09-12T00:18:51.076440: step 1312, loss 25.9627, acc 0.875\n",
      "2017-09-12T00:18:51.227970: step 1313, loss -423.78, acc 0.96875\n",
      "2017-09-12T00:18:51.350902: step 1314, loss -246.763, acc 0.9375\n",
      "2017-09-12T00:18:51.394848: step 1315, loss 16.2755, acc 0.875\n",
      "2017-09-12T00:18:51.546340: step 1316, loss -138.501, acc 0.96875\n",
      "2017-09-12T00:18:51.726098: step 1317, loss -371.169, acc 0.9375\n",
      "2017-09-12T00:18:51.856269: step 1318, loss -172.085, acc 0.90625\n",
      "2017-09-12T00:18:51.997926: step 1319, loss 106.275, acc 0.90625\n",
      "2017-09-12T00:18:52.111031: step 1320, loss -169.719, acc 0.9375\n",
      "2017-09-12T00:18:52.225680: step 1321, loss -178.02, acc 0.90625\n",
      "2017-09-12T00:18:52.352867: step 1322, loss -16.5496, acc 0.9375\n",
      "2017-09-12T00:18:52.477344: step 1323, loss 297.234, acc 0.8125\n",
      "2017-09-12T00:18:52.616586: step 1324, loss -494.937, acc 0.90625\n",
      "2017-09-12T00:18:52.762319: step 1325, loss -380.868, acc 0.96875\n",
      "2017-09-12T00:18:53.107653: step 1326, loss -129.924, acc 0.875\n",
      "2017-09-12T00:18:53.366492: step 1327, loss 43.7889, acc 0.875\n",
      "2017-09-12T00:18:53.589014: step 1328, loss -376.114, acc 0.96875\n",
      "2017-09-12T00:18:53.836274: step 1329, loss -427.922, acc 0.96875\n",
      "2017-09-12T00:18:54.143098: step 1330, loss -258.365, acc 0.90625\n",
      "2017-09-12T00:18:54.351088: step 1331, loss -434.838, acc 0.90625\n",
      "2017-09-12T00:18:54.549307: step 1332, loss -447.35, acc 0.96875\n",
      "2017-09-12T00:18:54.780157: step 1333, loss -422.933, acc 0.96875\n",
      "2017-09-12T00:18:54.956035: step 1334, loss -270.587, acc 0.90625\n",
      "2017-09-12T00:18:55.160624: step 1335, loss -411.041, acc 0.96875\n",
      "2017-09-12T00:18:55.357994: step 1336, loss -162.056, acc 0.84375\n",
      "2017-09-12T00:18:55.518240: step 1337, loss -186.962, acc 1\n",
      "2017-09-12T00:18:55.684180: step 1338, loss -212.836, acc 0.96875\n",
      "2017-09-12T00:18:55.864588: step 1339, loss -443.334, acc 0.9375\n",
      "2017-09-12T00:18:56.027646: step 1340, loss -131.889, acc 0.96875\n",
      "2017-09-12T00:18:56.194788: step 1341, loss -509.04, acc 0.9375\n",
      "2017-09-12T00:18:56.370930: step 1342, loss -322.957, acc 0.96875\n",
      "2017-09-12T00:18:56.534056: step 1343, loss -239.204, acc 0.90625\n",
      "2017-09-12T00:18:56.713438: step 1344, loss -267.173, acc 0.96875\n",
      "2017-09-12T00:18:56.888622: step 1345, loss -71.0088, acc 0.96875\n",
      "2017-09-12T00:18:57.088657: step 1346, loss -58.0604, acc 0.9375\n",
      "2017-09-12T00:18:57.239614: step 1347, loss 35.4005, acc 0.78125\n",
      "2017-09-12T00:18:57.410486: step 1348, loss -124.392, acc 0.9375\n",
      "2017-09-12T00:18:57.595746: step 1349, loss -206.324, acc 0.90625\n",
      "2017-09-12T00:18:57.774832: step 1350, loss -258.607, acc 0.96875\n",
      "2017-09-12T00:18:57.938714: step 1351, loss -391.17, acc 0.9375\n",
      "2017-09-12T00:18:58.118289: step 1352, loss -117.757, acc 0.90625\n",
      "2017-09-12T00:18:58.302393: step 1353, loss -305.624, acc 0.96875\n",
      "2017-09-12T00:18:58.456946: step 1354, loss -597.325, acc 1\n",
      "2017-09-12T00:18:58.614674: step 1355, loss -328.887, acc 0.96875\n",
      "2017-09-12T00:18:58.769552: step 1356, loss -135.005, acc 0.9375\n",
      "2017-09-12T00:18:58.964480: step 1357, loss -133.324, acc 0.90625\n",
      "2017-09-12T00:18:59.110155: step 1358, loss -455.021, acc 0.90625\n",
      "2017-09-12T00:18:59.266558: step 1359, loss -203.886, acc 0.9375\n",
      "2017-09-12T00:18:59.445842: step 1360, loss -265.872, acc 0.96875\n",
      "2017-09-12T00:18:59.734594: step 1361, loss -375.3, acc 0.90625\n",
      "2017-09-12T00:18:59.948382: step 1362, loss -405.019, acc 0.9375\n",
      "2017-09-12T00:19:00.150011: step 1363, loss -203.577, acc 0.96875\n",
      "2017-09-12T00:19:00.308900: step 1364, loss -274.945, acc 0.96875\n",
      "2017-09-12T00:19:00.493755: step 1365, loss -400.59, acc 0.90625\n",
      "2017-09-12T00:19:00.793528: step 1366, loss -390.14, acc 0.9375\n",
      "2017-09-12T00:19:00.985585: step 1367, loss -281.301, acc 0.9375\n",
      "2017-09-12T00:19:01.177228: step 1368, loss -131.112, acc 0.90625\n",
      "2017-09-12T00:19:01.327336: step 1369, loss -146.33, acc 0.90625\n",
      "2017-09-12T00:19:01.518631: step 1370, loss -65.0404, acc 0.84375\n",
      "2017-09-12T00:19:01.715671: step 1371, loss -415.159, acc 0.9375\n",
      "2017-09-12T00:19:02.009295: step 1372, loss -227.113, acc 0.875\n",
      "2017-09-12T00:19:02.167044: step 1373, loss -717.09, acc 0.96875\n",
      "2017-09-12T00:19:02.415817: step 1374, loss 154.324, acc 0.84375\n",
      "2017-09-12T00:19:02.632062: step 1375, loss 9.44193, acc 0.90625\n",
      "2017-09-12T00:19:02.932402: step 1376, loss -265.572, acc 0.9375\n",
      "2017-09-12T00:19:03.185514: step 1377, loss -286.003, acc 0.96875\n",
      "2017-09-12T00:19:03.381727: step 1378, loss -439.867, acc 1\n",
      "2017-09-12T00:19:03.626286: step 1379, loss -196.222, acc 0.90625\n",
      "2017-09-12T00:19:03.844227: step 1380, loss 123.279, acc 0.8125\n",
      "2017-09-12T00:19:04.097085: step 1381, loss -384.838, acc 0.9375\n",
      "2017-09-12T00:19:04.371722: step 1382, loss -194.258, acc 0.9375\n",
      "2017-09-12T00:19:04.737750: step 1383, loss 7.25974, acc 0.9375\n",
      "2017-09-12T00:19:05.095885: step 1384, loss -332.22, acc 0.96875\n",
      "2017-09-12T00:19:05.371512: step 1385, loss 63.5005, acc 0.84375\n",
      "2017-09-12T00:19:05.599569: step 1386, loss -333.809, acc 1\n",
      "2017-09-12T00:19:05.953928: step 1387, loss -220.632, acc 0.96875\n",
      "2017-09-12T00:19:06.311355: step 1388, loss 118.661, acc 0.875\n",
      "2017-09-12T00:19:06.698134: step 1389, loss -410.414, acc 0.9375\n",
      "2017-09-12T00:19:07.012945: step 1390, loss -281.773, acc 0.875\n",
      "2017-09-12T00:19:07.332266: step 1391, loss -35.534, acc 0.78125\n",
      "2017-09-12T00:19:07.969268: step 1392, loss -279.882, acc 0.9375\n",
      "2017-09-12T00:19:08.355552: step 1393, loss -399.528, acc 0.96875\n",
      "2017-09-12T00:19:08.776849: step 1394, loss -315.735, acc 0.96875\n",
      "2017-09-12T00:19:09.260944: step 1395, loss -540.379, acc 0.9375\n",
      "2017-09-12T00:19:09.613454: step 1396, loss -144.142, acc 0.96875\n",
      "2017-09-12T00:19:09.869684: step 1397, loss -205.654, acc 0.96875\n",
      "2017-09-12T00:19:10.258965: step 1398, loss 69.4209, acc 0.90625\n",
      "2017-09-12T00:19:10.527320: step 1399, loss -275.505, acc 0.90625\n",
      "2017-09-12T00:19:10.944522: step 1400, loss -144.037, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:19:14.100454: step 1400, loss -279.553, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1400\n",
      "\n",
      "2017-09-12T00:19:18.937705: step 1401, loss -145.77, acc 0.96875\n",
      "2017-09-12T00:19:19.076528: step 1402, loss -586.43, acc 0.9375\n",
      "2017-09-12T00:19:19.268546: step 1403, loss -229.033, acc 0.9375\n",
      "2017-09-12T00:19:19.396598: step 1404, loss -74.339, acc 0.96875\n",
      "2017-09-12T00:19:19.480918: step 1405, loss -410.694, acc 0.90625\n",
      "2017-09-12T00:19:19.565086: step 1406, loss -156.67, acc 0.9375\n",
      "2017-09-12T00:19:19.678331: step 1407, loss -597.347, acc 0.9375\n",
      "2017-09-12T00:19:19.819269: step 1408, loss -135.041, acc 0.90625\n",
      "2017-09-12T00:19:19.912481: step 1409, loss 263.821, acc 0.75\n",
      "2017-09-12T00:19:20.011677: step 1410, loss -362.911, acc 0.9375\n",
      "2017-09-12T00:19:20.107383: step 1411, loss -296.456, acc 0.90625\n",
      "2017-09-12T00:19:20.208735: step 1412, loss -199.883, acc 0.9375\n",
      "2017-09-12T00:19:20.300885: step 1413, loss -312.04, acc 0.875\n",
      "2017-09-12T00:19:20.392293: step 1414, loss -312.74, acc 0.9375\n",
      "2017-09-12T00:19:20.488380: step 1415, loss -316.96, acc 0.90625\n",
      "2017-09-12T00:19:20.576805: step 1416, loss 79.5704, acc 0.84375\n",
      "2017-09-12T00:19:20.677410: step 1417, loss 144.808, acc 0.875\n",
      "2017-09-12T00:19:20.774740: step 1418, loss -455.678, acc 0.96875\n",
      "2017-09-12T00:19:20.872876: step 1419, loss -71.3228, acc 0.875\n",
      "2017-09-12T00:19:20.975415: step 1420, loss -255.464, acc 0.90625\n",
      "2017-09-12T00:19:21.078844: step 1421, loss -358.93, acc 0.9375\n",
      "2017-09-12T00:19:21.167554: step 1422, loss -547.459, acc 0.9375\n",
      "2017-09-12T00:19:21.259749: step 1423, loss -372.53, acc 0.96875\n",
      "2017-09-12T00:19:21.347493: step 1424, loss -239.524, acc 0.90625\n",
      "2017-09-12T00:19:21.438866: step 1425, loss -658.599, acc 0.90625\n",
      "2017-09-12T00:19:21.540473: step 1426, loss -146.411, acc 0.9375\n",
      "2017-09-12T00:19:21.638910: step 1427, loss -199.446, acc 0.90625\n",
      "2017-09-12T00:19:21.734018: step 1428, loss -172.438, acc 0.90625\n",
      "2017-09-12T00:19:21.891082: step 1429, loss -373.088, acc 0.9375\n",
      "2017-09-12T00:19:22.013776: step 1430, loss -392.368, acc 0.9375\n",
      "2017-09-12T00:19:22.105500: step 1431, loss -523.284, acc 1\n",
      "2017-09-12T00:19:22.196726: step 1432, loss -664.307, acc 1\n",
      "2017-09-12T00:19:22.298129: step 1433, loss -674.665, acc 0.96875\n",
      "2017-09-12T00:19:22.420975: step 1434, loss -387.227, acc 0.9375\n",
      "2017-09-12T00:19:22.653861: step 1435, loss -301.291, acc 0.90625\n",
      "2017-09-12T00:19:22.831035: step 1436, loss -228.226, acc 0.9375\n",
      "2017-09-12T00:19:22.947830: step 1437, loss -315.018, acc 0.9375\n",
      "2017-09-12T00:19:23.117321: step 1438, loss -470.683, acc 0.96875\n",
      "2017-09-12T00:19:23.249122: step 1439, loss -29.6516, acc 0.9375\n",
      "2017-09-12T00:19:23.419623: step 1440, loss -493.724, acc 0.96875\n",
      "2017-09-12T00:19:23.564345: step 1441, loss -233.649, acc 0.90625\n",
      "2017-09-12T00:19:23.704724: step 1442, loss -386.926, acc 0.9375\n",
      "2017-09-12T00:19:23.855377: step 1443, loss -82.7054, acc 0.84375\n",
      "2017-09-12T00:19:23.995978: step 1444, loss -367.883, acc 0.96875\n",
      "2017-09-12T00:19:24.175687: step 1445, loss -150.723, acc 0.90625\n",
      "2017-09-12T00:19:24.321102: step 1446, loss -127.535, acc 0.9375\n",
      "2017-09-12T00:19:24.464556: step 1447, loss 144.207, acc 0.78125\n",
      "2017-09-12T00:19:24.627538: step 1448, loss -428.132, acc 0.90625\n",
      "2017-09-12T00:19:24.799559: step 1449, loss -157.999, acc 0.875\n",
      "2017-09-12T00:19:24.951631: step 1450, loss -13.4761, acc 0.875\n",
      "2017-09-12T00:19:25.086090: step 1451, loss -555.047, acc 0.96875\n",
      "2017-09-12T00:19:25.246265: step 1452, loss -109.709, acc 0.90625\n",
      "2017-09-12T00:19:25.403890: step 1453, loss -527.461, acc 0.96875\n",
      "2017-09-12T00:19:25.629481: step 1454, loss -124.559, acc 0.84375\n",
      "2017-09-12T00:19:25.762048: step 1455, loss -369.708, acc 0.90625\n",
      "2017-09-12T00:19:25.932051: step 1456, loss -202.687, acc 0.9375\n",
      "2017-09-12T00:19:26.081465: step 1457, loss -396.171, acc 0.96875\n",
      "2017-09-12T00:19:26.236492: step 1458, loss -237.594, acc 0.9375\n",
      "2017-09-12T00:19:26.413876: step 1459, loss -221.739, acc 0.9375\n",
      "2017-09-12T00:19:26.601096: step 1460, loss -223.873, acc 0.90625\n",
      "2017-09-12T00:19:26.751049: step 1461, loss -492.285, acc 1\n",
      "2017-09-12T00:19:26.892772: step 1462, loss -103.334, acc 0.90625\n",
      "2017-09-12T00:19:27.066055: step 1463, loss -565.247, acc 0.9375\n",
      "2017-09-12T00:19:27.203818: step 1464, loss -98.3087, acc 0.9375\n",
      "2017-09-12T00:19:27.411808: step 1465, loss -7.98716, acc 0.90625\n",
      "2017-09-12T00:19:27.532012: step 1466, loss -235.694, acc 0.9375\n",
      "2017-09-12T00:19:27.688996: step 1467, loss -389.317, acc 0.96875\n",
      "2017-09-12T00:19:27.930804: step 1468, loss -250.495, acc 1\n",
      "2017-09-12T00:19:28.109416: step 1469, loss -7.6329, acc 0.8125\n",
      "2017-09-12T00:19:28.282537: step 1470, loss -195.649, acc 0.9375\n",
      "2017-09-12T00:19:28.605809: step 1471, loss -566.572, acc 1\n",
      "2017-09-12T00:19:28.907389: step 1472, loss -412.962, acc 0.875\n",
      "2017-09-12T00:19:29.218170: step 1473, loss 120.267, acc 0.875\n",
      "2017-09-12T00:19:29.420282: step 1474, loss 75.5857, acc 0.90625\n",
      "2017-09-12T00:19:29.647117: step 1475, loss -185.472, acc 0.9375\n",
      "2017-09-12T00:19:29.952641: step 1476, loss -409.721, acc 0.96875\n",
      "2017-09-12T00:19:30.181033: step 1477, loss -662.42, acc 0.96875\n",
      "2017-09-12T00:19:30.420307: step 1478, loss -335.306, acc 0.9375\n",
      "2017-09-12T00:19:30.643649: step 1479, loss -227.209, acc 0.90625\n",
      "2017-09-12T00:19:30.940318: step 1480, loss -401.604, acc 1\n",
      "2017-09-12T00:19:31.250920: step 1481, loss -52.6881, acc 0.90625\n",
      "2017-09-12T00:19:31.493196: step 1482, loss 50.0227, acc 0.875\n",
      "2017-09-12T00:19:31.734588: step 1483, loss -162.234, acc 0.9375\n",
      "2017-09-12T00:19:31.960294: step 1484, loss 6.67083, acc 0.875\n",
      "2017-09-12T00:19:32.221929: step 1485, loss -308.126, acc 0.9375\n",
      "2017-09-12T00:19:32.475439: step 1486, loss -329.11, acc 0.90625\n",
      "2017-09-12T00:19:32.886486: step 1487, loss -91.3779, acc 0.9375\n",
      "2017-09-12T00:19:33.153604: step 1488, loss -472.94, acc 0.9375\n",
      "2017-09-12T00:19:33.432023: step 1489, loss -500.476, acc 1\n",
      "2017-09-12T00:19:33.797102: step 1490, loss -349.181, acc 0.96875\n",
      "2017-09-12T00:19:34.076959: step 1491, loss -17.3574, acc 0.90625\n",
      "2017-09-12T00:19:34.337556: step 1492, loss 48.3346, acc 0.90625\n",
      "2017-09-12T00:19:34.622219: step 1493, loss -84.6486, acc 0.875\n",
      "2017-09-12T00:19:34.851048: step 1494, loss -75.6475, acc 0.90625\n",
      "2017-09-12T00:19:35.128864: step 1495, loss -182.888, acc 0.90625\n",
      "2017-09-12T00:19:35.397185: step 1496, loss -316.193, acc 0.96875\n",
      "2017-09-12T00:19:35.657787: step 1497, loss -286.72, acc 0.9375\n",
      "2017-09-12T00:19:35.836446: step 1498, loss -355.292, acc 0.96875\n",
      "2017-09-12T00:19:35.980020: step 1499, loss -75.1854, acc 0.875\n",
      "2017-09-12T00:19:36.104169: step 1500, loss -15.1772, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:19:37.863175: step 1500, loss -333.334, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1500\n",
      "\n",
      "2017-09-12T00:19:41.259048: step 1501, loss -268.934, acc 0.9375\n",
      "2017-09-12T00:19:41.338088: step 1502, loss -181.439, acc 0.875\n",
      "2017-09-12T00:19:41.460034: step 1503, loss -416.103, acc 0.875\n",
      "2017-09-12T00:19:41.613975: step 1504, loss -81.7582, acc 0.9375\n",
      "2017-09-12T00:19:41.748198: step 1505, loss 312.991, acc 0.8125\n",
      "2017-09-12T00:19:41.845840: step 1506, loss -307.86, acc 0.96875\n",
      "2017-09-12T00:19:41.944391: step 1507, loss -165.489, acc 0.9375\n",
      "2017-09-12T00:19:42.036906: step 1508, loss -213.646, acc 0.9375\n",
      "2017-09-12T00:19:42.149386: step 1509, loss -448.089, acc 0.9375\n",
      "2017-09-12T00:19:42.263148: step 1510, loss -208.109, acc 0.9375\n",
      "2017-09-12T00:19:42.373607: step 1511, loss -423.56, acc 0.90625\n",
      "2017-09-12T00:19:42.483220: step 1512, loss -441.835, acc 0.9375\n",
      "2017-09-12T00:19:42.596294: step 1513, loss 93.8881, acc 0.875\n",
      "2017-09-12T00:19:42.701848: step 1514, loss -623.773, acc 0.9375\n",
      "2017-09-12T00:19:42.816027: step 1515, loss -547.293, acc 0.90625\n",
      "2017-09-12T00:19:42.916717: step 1516, loss -156.769, acc 0.9375\n",
      "2017-09-12T00:19:43.025859: step 1517, loss 81.1091, acc 0.875\n",
      "2017-09-12T00:19:43.153168: step 1518, loss -412.978, acc 1\n",
      "2017-09-12T00:19:43.274292: step 1519, loss -93.8393, acc 0.9375\n",
      "2017-09-12T00:19:43.426213: step 1520, loss -234.703, acc 0.90625\n",
      "2017-09-12T00:19:43.573258: step 1521, loss -254.089, acc 0.96875\n",
      "2017-09-12T00:19:43.695906: step 1522, loss -564.721, acc 0.96875\n",
      "2017-09-12T00:19:43.870790: step 1523, loss -651.876, acc 0.96875\n",
      "2017-09-12T00:19:43.982625: step 1524, loss -195.402, acc 0.875\n",
      "2017-09-12T00:19:44.082304: step 1525, loss -429.252, acc 0.96875\n",
      "2017-09-12T00:19:44.210812: step 1526, loss -220.309, acc 0.9375\n",
      "2017-09-12T00:19:44.298945: step 1527, loss -378.012, acc 0.96875\n",
      "2017-09-12T00:19:44.397057: step 1528, loss -222.904, acc 0.90625\n",
      "2017-09-12T00:19:44.493679: step 1529, loss -294.939, acc 0.96875\n",
      "2017-09-12T00:19:44.597736: step 1530, loss -460.83, acc 0.9375\n",
      "2017-09-12T00:19:44.743922: step 1531, loss -123.65, acc 0.84375\n",
      "2017-09-12T00:19:44.836543: step 1532, loss -646.212, acc 0.9375\n",
      "2017-09-12T00:19:45.092056: step 1533, loss -550.529, acc 0.90625\n",
      "2017-09-12T00:19:45.234945: step 1534, loss -0.0230789, acc 0.875\n",
      "2017-09-12T00:19:45.380884: step 1535, loss -194.418, acc 0.90625\n",
      "2017-09-12T00:19:45.541899: step 1536, loss -379.222, acc 0.96875\n",
      "2017-09-12T00:19:45.680846: step 1537, loss -406.553, acc 0.9375\n",
      "2017-09-12T00:19:45.846691: step 1538, loss 413.78, acc 0.8125\n",
      "2017-09-12T00:19:46.019614: step 1539, loss -423.023, acc 0.96875\n",
      "2017-09-12T00:19:46.186097: step 1540, loss -437.939, acc 0.96875\n",
      "2017-09-12T00:19:46.323338: step 1541, loss -218.623, acc 0.9375\n",
      "2017-09-12T00:19:46.477133: step 1542, loss -201.371, acc 0.9375\n",
      "2017-09-12T00:19:46.619758: step 1543, loss -252.843, acc 0.90625\n",
      "2017-09-12T00:19:46.770861: step 1544, loss -94.8271, acc 0.90625\n",
      "2017-09-12T00:19:46.926582: step 1545, loss -107.283, acc 0.9375\n",
      "2017-09-12T00:19:47.067489: step 1546, loss 224.141, acc 0.8125\n",
      "2017-09-12T00:19:47.218969: step 1547, loss -106.369, acc 0.84375\n",
      "2017-09-12T00:19:47.366176: step 1548, loss -465.278, acc 0.9375\n",
      "2017-09-12T00:19:47.522436: step 1549, loss -72.9961, acc 0.9375\n",
      "2017-09-12T00:19:47.681249: step 1550, loss -344.709, acc 0.90625\n",
      "2017-09-12T00:19:47.876168: step 1551, loss -172.946, acc 0.9375\n",
      "2017-09-12T00:19:48.019913: step 1552, loss -246.095, acc 0.9375\n",
      "2017-09-12T00:19:48.243266: step 1553, loss -250.07, acc 0.96875\n",
      "2017-09-12T00:19:48.336681: step 1554, loss -187.779, acc 0.90625\n",
      "2017-09-12T00:19:48.509037: step 1555, loss -580.179, acc 0.96875\n",
      "2017-09-12T00:19:48.658270: step 1556, loss -818.078, acc 0.96875\n",
      "2017-09-12T00:19:48.811410: step 1557, loss -167.73, acc 0.9375\n",
      "2017-09-12T00:19:49.007533: step 1558, loss -628.797, acc 0.90625\n",
      "2017-09-12T00:19:49.175297: step 1559, loss -244.114, acc 0.9375\n",
      "2017-09-12T00:19:49.357372: step 1560, loss -46.2934, acc 0.875\n",
      "2017-09-12T00:19:49.520518: step 1561, loss -451.751, acc 0.9375\n",
      "2017-09-12T00:19:49.689954: step 1562, loss -561.602, acc 0.9375\n",
      "2017-09-12T00:19:49.866480: step 1563, loss -285.414, acc 0.9375\n",
      "2017-09-12T00:19:50.096821: step 1564, loss -794.772, acc 0.96875\n",
      "2017-09-12T00:19:50.238775: step 1565, loss -698.125, acc 0.9375\n",
      "2017-09-12T00:19:50.388215: step 1566, loss -667.364, acc 0.96875\n",
      "2017-09-12T00:19:50.536520: step 1567, loss -485.553, acc 0.9375\n",
      "2017-09-12T00:19:50.678874: step 1568, loss -658.356, acc 0.96875\n",
      "2017-09-12T00:19:50.823014: step 1569, loss -281.977, acc 0.90625\n",
      "2017-09-12T00:19:50.973187: step 1570, loss -422.447, acc 0.90625\n",
      "2017-09-12T00:19:51.122724: step 1571, loss -212.252, acc 0.875\n",
      "2017-09-12T00:19:51.260024: step 1572, loss -97.9259, acc 0.9375\n",
      "2017-09-12T00:19:51.427393: step 1573, loss -566.11, acc 0.96875\n",
      "2017-09-12T00:19:51.591192: step 1574, loss -551.54, acc 0.90625\n",
      "2017-09-12T00:19:51.723182: step 1575, loss -680.292, acc 0.96875\n",
      "2017-09-12T00:19:51.860380: step 1576, loss -213.161, acc 0.8125\n",
      "2017-09-12T00:19:51.999683: step 1577, loss -171.986, acc 0.90625\n",
      "2017-09-12T00:19:52.044870: step 1578, loss -467.515, acc 0.875\n",
      "2017-09-12T00:19:52.195502: step 1579, loss -373.68, acc 0.9375\n",
      "2017-09-12T00:19:52.348653: step 1580, loss -418.504, acc 0.9375\n",
      "2017-09-12T00:19:52.501657: step 1581, loss -478.093, acc 0.90625\n",
      "2017-09-12T00:19:52.639486: step 1582, loss -86.5735, acc 0.90625\n",
      "2017-09-12T00:19:52.794626: step 1583, loss -402.485, acc 0.90625\n",
      "2017-09-12T00:19:52.949131: step 1584, loss -164.308, acc 0.875\n",
      "2017-09-12T00:19:53.093103: step 1585, loss -491.411, acc 0.9375\n",
      "2017-09-12T00:19:53.242617: step 1586, loss -900.696, acc 0.96875\n",
      "2017-09-12T00:19:53.384822: step 1587, loss -317.202, acc 0.90625\n",
      "2017-09-12T00:19:53.534779: step 1588, loss -585.008, acc 0.96875\n",
      "2017-09-12T00:19:53.675839: step 1589, loss -407.063, acc 0.96875\n",
      "2017-09-12T00:19:53.817097: step 1590, loss -499.759, acc 0.84375\n",
      "2017-09-12T00:19:53.959205: step 1591, loss -131.998, acc 0.90625\n",
      "2017-09-12T00:19:54.115555: step 1592, loss -580.938, acc 0.96875\n",
      "2017-09-12T00:19:54.284763: step 1593, loss -390.196, acc 0.96875\n",
      "2017-09-12T00:19:54.430261: step 1594, loss -298.391, acc 0.96875\n",
      "2017-09-12T00:19:54.576864: step 1595, loss -382.63, acc 0.9375\n",
      "2017-09-12T00:19:54.719318: step 1596, loss 207.274, acc 0.84375\n",
      "2017-09-12T00:19:54.884808: step 1597, loss 111.9, acc 0.90625\n",
      "2017-09-12T00:19:55.051121: step 1598, loss -601.234, acc 1\n",
      "2017-09-12T00:19:55.192183: step 1599, loss -155.867, acc 0.90625\n",
      "2017-09-12T00:19:55.352197: step 1600, loss -800.334, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:19:56.903648: step 1600, loss -394.662, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1600\n",
      "\n",
      "2017-09-12T00:19:59.347860: step 1601, loss -414.495, acc 0.90625\n",
      "2017-09-12T00:19:59.470228: step 1602, loss -653.202, acc 1\n",
      "2017-09-12T00:19:59.628234: step 1603, loss -321.717, acc 0.96875\n",
      "2017-09-12T00:19:59.765511: step 1604, loss -107.968, acc 0.90625\n",
      "2017-09-12T00:19:59.935636: step 1605, loss -15.2984, acc 0.96875\n",
      "2017-09-12T00:20:00.099615: step 1606, loss -403.586, acc 0.9375\n",
      "2017-09-12T00:20:00.260421: step 1607, loss -555.626, acc 0.90625\n",
      "2017-09-12T00:20:00.392150: step 1608, loss 88.4707, acc 0.90625\n",
      "2017-09-12T00:20:00.521185: step 1609, loss -232.342, acc 0.90625\n",
      "2017-09-12T00:20:00.644831: step 1610, loss -22.7129, acc 0.8125\n",
      "2017-09-12T00:20:00.763074: step 1611, loss -339.767, acc 0.9375\n",
      "2017-09-12T00:20:00.871658: step 1612, loss -748.199, acc 0.96875\n",
      "2017-09-12T00:20:00.971460: step 1613, loss -421.611, acc 0.875\n",
      "2017-09-12T00:20:01.075850: step 1614, loss 94.5059, acc 0.84375\n",
      "2017-09-12T00:20:01.199473: step 1615, loss -661.654, acc 0.9375\n",
      "2017-09-12T00:20:01.299591: step 1616, loss -540.719, acc 0.96875\n",
      "2017-09-12T00:20:01.407842: step 1617, loss -952.714, acc 1\n",
      "2017-09-12T00:20:01.511765: step 1618, loss -621.428, acc 0.96875\n",
      "2017-09-12T00:20:01.628318: step 1619, loss -2.86862, acc 0.9375\n",
      "2017-09-12T00:20:01.740752: step 1620, loss -568.882, acc 0.96875\n",
      "2017-09-12T00:20:01.838842: step 1621, loss -677.67, acc 1\n",
      "2017-09-12T00:20:01.952208: step 1622, loss -414.839, acc 0.90625\n",
      "2017-09-12T00:20:02.088089: step 1623, loss -87.4487, acc 0.90625\n",
      "2017-09-12T00:20:02.176059: step 1624, loss -324.069, acc 1\n",
      "2017-09-12T00:20:02.262024: step 1625, loss -535.774, acc 0.90625\n",
      "2017-09-12T00:20:02.350974: step 1626, loss -321.722, acc 0.9375\n",
      "2017-09-12T00:20:02.441581: step 1627, loss 168.01, acc 0.90625\n",
      "2017-09-12T00:20:02.565187: step 1628, loss -220.836, acc 0.90625\n",
      "2017-09-12T00:20:02.865585: step 1629, loss -409.049, acc 0.90625\n",
      "2017-09-12T00:20:03.003211: step 1630, loss -444.32, acc 0.9375\n",
      "2017-09-12T00:20:03.143036: step 1631, loss -538.499, acc 0.9375\n",
      "2017-09-12T00:20:03.300302: step 1632, loss -1125.45, acc 0.96875\n",
      "2017-09-12T00:20:03.474699: step 1633, loss -549.294, acc 0.90625\n",
      "2017-09-12T00:20:03.681390: step 1634, loss -576.524, acc 0.9375\n",
      "2017-09-12T00:20:03.841876: step 1635, loss -323.349, acc 0.90625\n",
      "2017-09-12T00:20:04.006876: step 1636, loss -7.37042, acc 0.90625\n",
      "2017-09-12T00:20:04.192203: step 1637, loss -315.184, acc 0.90625\n",
      "2017-09-12T00:20:04.368783: step 1638, loss -88.1361, acc 0.9375\n",
      "2017-09-12T00:20:04.542096: step 1639, loss -449.785, acc 0.96875\n",
      "2017-09-12T00:20:04.721932: step 1640, loss -207.547, acc 0.875\n",
      "2017-09-12T00:20:04.852459: step 1641, loss -456.184, acc 0.9375\n",
      "2017-09-12T00:20:04.999061: step 1642, loss -205.701, acc 0.90625\n",
      "2017-09-12T00:20:05.160583: step 1643, loss -19.1133, acc 0.90625\n",
      "2017-09-12T00:20:05.319117: step 1644, loss 6.35357, acc 0.90625\n",
      "2017-09-12T00:20:05.461999: step 1645, loss -136.973, acc 0.875\n",
      "2017-09-12T00:20:05.614196: step 1646, loss -347.392, acc 0.9375\n",
      "2017-09-12T00:20:05.795138: step 1647, loss -40.2976, acc 0.875\n",
      "2017-09-12T00:20:05.949223: step 1648, loss -425.352, acc 0.90625\n",
      "2017-09-12T00:20:06.093307: step 1649, loss -113.29, acc 0.90625\n",
      "2017-09-12T00:20:06.240908: step 1650, loss -783.197, acc 1\n",
      "2017-09-12T00:20:06.391024: step 1651, loss -436.514, acc 0.90625\n",
      "2017-09-12T00:20:06.536991: step 1652, loss -225.642, acc 0.96875\n",
      "2017-09-12T00:20:06.678967: step 1653, loss -44.1325, acc 0.9375\n",
      "2017-09-12T00:20:06.837614: step 1654, loss -905.039, acc 1\n",
      "2017-09-12T00:20:06.987868: step 1655, loss -653.132, acc 1\n",
      "2017-09-12T00:20:07.151762: step 1656, loss -677.454, acc 0.90625\n",
      "2017-09-12T00:20:07.328038: step 1657, loss -528.176, acc 0.9375\n",
      "2017-09-12T00:20:07.487340: step 1658, loss -339.673, acc 0.9375\n",
      "2017-09-12T00:20:07.646402: step 1659, loss -213.271, acc 0.9375\n",
      "2017-09-12T00:20:07.796811: step 1660, loss -749.959, acc 1\n",
      "2017-09-12T00:20:07.971182: step 1661, loss -1085.01, acc 0.96875\n",
      "2017-09-12T00:20:08.097801: step 1662, loss -983.131, acc 0.90625\n",
      "2017-09-12T00:20:08.251383: step 1663, loss -538.508, acc 0.96875\n",
      "2017-09-12T00:20:08.402481: step 1664, loss 228.306, acc 0.84375\n",
      "2017-09-12T00:20:08.568622: step 1665, loss -594.543, acc 1\n",
      "2017-09-12T00:20:08.709277: step 1666, loss -123.795, acc 0.875\n",
      "2017-09-12T00:20:08.850240: step 1667, loss 223.6, acc 0.875\n",
      "2017-09-12T00:20:09.011586: step 1668, loss -564.126, acc 1\n",
      "2017-09-12T00:20:09.148927: step 1669, loss -452.962, acc 0.9375\n",
      "2017-09-12T00:20:09.295733: step 1670, loss -1216.31, acc 0.9375\n",
      "2017-09-12T00:20:09.436783: step 1671, loss -363.91, acc 0.96875\n",
      "2017-09-12T00:20:09.619525: step 1672, loss -772.528, acc 0.90625\n",
      "2017-09-12T00:20:09.763499: step 1673, loss -35.4662, acc 0.875\n",
      "2017-09-12T00:20:09.920896: step 1674, loss -358.904, acc 0.96875\n",
      "2017-09-12T00:20:10.077975: step 1675, loss -541.778, acc 0.96875\n",
      "2017-09-12T00:20:10.215629: step 1676, loss 0, acc 1\n",
      "2017-09-12T00:20:10.363964: step 1677, loss -76.1093, acc 0.90625\n",
      "2017-09-12T00:20:10.500270: step 1678, loss -914.807, acc 0.96875\n",
      "2017-09-12T00:20:10.649286: step 1679, loss -438.139, acc 0.875\n",
      "2017-09-12T00:20:10.785219: step 1680, loss -1128.38, acc 0.96875\n",
      "2017-09-12T00:20:10.931173: step 1681, loss -142.835, acc 0.84375\n",
      "2017-09-12T00:20:11.095522: step 1682, loss -961.297, acc 0.90625\n",
      "2017-09-12T00:20:11.242773: step 1683, loss -685.316, acc 1\n",
      "2017-09-12T00:20:11.393512: step 1684, loss -375.856, acc 0.9375\n",
      "2017-09-12T00:20:11.522810: step 1685, loss -519.595, acc 0.9375\n",
      "2017-09-12T00:20:11.665048: step 1686, loss -731.623, acc 0.875\n",
      "2017-09-12T00:20:11.810513: step 1687, loss -443.11, acc 0.96875\n",
      "2017-09-12T00:20:11.954912: step 1688, loss -247.002, acc 0.84375\n",
      "2017-09-12T00:20:12.089811: step 1689, loss 115.738, acc 0.8125\n",
      "2017-09-12T00:20:12.254616: step 1690, loss -304.917, acc 0.9375\n",
      "2017-09-12T00:20:12.406133: step 1691, loss -132.798, acc 0.875\n",
      "2017-09-12T00:20:12.544804: step 1692, loss -266.564, acc 0.875\n",
      "2017-09-12T00:20:12.687351: step 1693, loss -607.373, acc 0.9375\n",
      "2017-09-12T00:20:12.865029: step 1694, loss -116.423, acc 0.875\n",
      "2017-09-12T00:20:13.035113: step 1695, loss -634.236, acc 0.9375\n",
      "2017-09-12T00:20:13.171572: step 1696, loss -823.53, acc 0.9375\n",
      "2017-09-12T00:20:13.305106: step 1697, loss -566.76, acc 1\n",
      "2017-09-12T00:20:13.449627: step 1698, loss -485.556, acc 0.9375\n",
      "2017-09-12T00:20:13.596620: step 1699, loss -771.584, acc 0.9375\n",
      "2017-09-12T00:20:13.741953: step 1700, loss -455.697, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:20:15.218426: step 1700, loss -468.138, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1700\n",
      "\n",
      "2017-09-12T00:20:19.157526: step 1701, loss -255.326, acc 0.875\n",
      "2017-09-12T00:20:19.285529: step 1702, loss -439.51, acc 0.9375\n",
      "2017-09-12T00:20:19.452069: step 1703, loss -225.537, acc 0.9375\n",
      "2017-09-12T00:20:19.670159: step 1704, loss -717.297, acc 1\n",
      "2017-09-12T00:20:19.927903: step 1705, loss -991.798, acc 1\n",
      "2017-09-12T00:20:20.158862: step 1706, loss -719.707, acc 0.9375\n",
      "2017-09-12T00:20:20.370173: step 1707, loss -284.43, acc 0.90625\n",
      "2017-09-12T00:20:20.534916: step 1708, loss -686.631, acc 0.9375\n",
      "2017-09-12T00:20:20.645287: step 1709, loss -711.921, acc 0.9375\n",
      "2017-09-12T00:20:20.774909: step 1710, loss -973.926, acc 0.9375\n",
      "2017-09-12T00:20:20.892741: step 1711, loss -493.538, acc 1\n",
      "2017-09-12T00:20:21.007322: step 1712, loss -150.171, acc 0.875\n",
      "2017-09-12T00:20:21.181566: step 1713, loss -497.129, acc 0.96875\n",
      "2017-09-12T00:20:21.354676: step 1714, loss -610.078, acc 0.96875\n",
      "2017-09-12T00:20:21.520578: step 1715, loss -613.346, acc 0.9375\n",
      "2017-09-12T00:20:21.683286: step 1716, loss -1367.57, acc 1\n",
      "2017-09-12T00:20:21.848956: step 1717, loss -615.722, acc 0.875\n",
      "2017-09-12T00:20:22.017035: step 1718, loss -151.199, acc 0.84375\n",
      "2017-09-12T00:20:22.114937: step 1719, loss -28.9849, acc 0.96875\n",
      "2017-09-12T00:20:22.212562: step 1720, loss -230.209, acc 0.875\n",
      "2017-09-12T00:20:22.321276: step 1721, loss -477.718, acc 0.90625\n",
      "2017-09-12T00:20:22.478536: step 1722, loss -546.91, acc 0.96875\n",
      "2017-09-12T00:20:22.604205: step 1723, loss -254.477, acc 0.9375\n",
      "2017-09-12T00:20:22.819252: step 1724, loss 8.23337, acc 0.9375\n",
      "2017-09-12T00:20:22.971987: step 1725, loss -563.692, acc 0.90625\n",
      "2017-09-12T00:20:23.095995: step 1726, loss -377.31, acc 0.90625\n",
      "2017-09-12T00:20:23.316937: step 1727, loss -620.007, acc 0.9375\n",
      "2017-09-12T00:20:23.555765: step 1728, loss -1178.04, acc 0.96875\n",
      "2017-09-12T00:20:23.665949: step 1729, loss 10.3123, acc 0.8125\n",
      "2017-09-12T00:20:23.782409: step 1730, loss 372.344, acc 0.84375\n",
      "2017-09-12T00:20:23.894557: step 1731, loss -521.586, acc 0.90625\n",
      "2017-09-12T00:20:23.999177: step 1732, loss 500.15, acc 0.84375\n",
      "2017-09-12T00:20:24.136174: step 1733, loss -1685.27, acc 1\n",
      "2017-09-12T00:20:24.242591: step 1734, loss -504.574, acc 0.96875\n",
      "2017-09-12T00:20:24.352098: step 1735, loss 246.054, acc 0.875\n",
      "2017-09-12T00:20:24.683003: step 1736, loss -482.496, acc 1\n",
      "2017-09-12T00:20:24.846739: step 1737, loss -387.942, acc 0.96875\n",
      "2017-09-12T00:20:24.998744: step 1738, loss -518.004, acc 0.90625\n",
      "2017-09-12T00:20:25.147839: step 1739, loss -389.267, acc 0.9375\n",
      "2017-09-12T00:20:25.332470: step 1740, loss -778.735, acc 0.84375\n",
      "2017-09-12T00:20:25.500888: step 1741, loss 13.8594, acc 0.78125\n",
      "2017-09-12T00:20:25.706893: step 1742, loss -541.208, acc 0.96875\n",
      "2017-09-12T00:20:25.890681: step 1743, loss -123.157, acc 0.90625\n",
      "2017-09-12T00:20:26.061241: step 1744, loss -906.301, acc 0.9375\n",
      "2017-09-12T00:20:26.274968: step 1745, loss -544.546, acc 0.9375\n",
      "2017-09-12T00:20:26.446480: step 1746, loss -366.56, acc 0.96875\n",
      "2017-09-12T00:20:26.688846: step 1747, loss -352.447, acc 0.96875\n",
      "2017-09-12T00:20:26.850495: step 1748, loss -362.176, acc 0.96875\n",
      "2017-09-12T00:20:27.001617: step 1749, loss -538.91, acc 0.9375\n",
      "2017-09-12T00:20:27.166007: step 1750, loss 471.175, acc 0.84375\n",
      "2017-09-12T00:20:27.322120: step 1751, loss -1195.04, acc 1\n",
      "2017-09-12T00:20:27.481366: step 1752, loss -267.903, acc 0.9375\n",
      "2017-09-12T00:20:27.643355: step 1753, loss 10.5049, acc 0.90625\n",
      "2017-09-12T00:20:27.813931: step 1754, loss -377.448, acc 0.9375\n",
      "2017-09-12T00:20:28.024688: step 1755, loss 0.297195, acc 0.875\n",
      "2017-09-12T00:20:28.209506: step 1756, loss 56.6368, acc 0.84375\n",
      "2017-09-12T00:20:28.357038: step 1757, loss -920.339, acc 0.96875\n",
      "2017-09-12T00:20:28.579671: step 1758, loss -757.541, acc 0.96875\n",
      "2017-09-12T00:20:28.734409: step 1759, loss 612.497, acc 0.8125\n",
      "2017-09-12T00:20:28.950642: step 1760, loss -819.526, acc 0.90625\n",
      "2017-09-12T00:20:29.114364: step 1761, loss -589.125, acc 0.84375\n",
      "2017-09-12T00:20:29.405170: step 1762, loss -286.442, acc 0.875\n",
      "2017-09-12T00:20:29.618775: step 1763, loss -284.416, acc 0.96875\n",
      "2017-09-12T00:20:29.807268: step 1764, loss -431.031, acc 0.90625\n",
      "2017-09-12T00:20:30.170818: step 1765, loss -273.544, acc 0.9375\n",
      "2017-09-12T00:20:30.447116: step 1766, loss -363.097, acc 0.96875\n",
      "2017-09-12T00:20:30.662475: step 1767, loss -141.304, acc 0.8125\n",
      "2017-09-12T00:20:30.806939: step 1768, loss -664.27, acc 0.96875\n",
      "2017-09-12T00:20:30.954286: step 1769, loss -932.897, acc 0.90625\n",
      "2017-09-12T00:20:31.096849: step 1770, loss -155.733, acc 0.90625\n",
      "2017-09-12T00:20:31.248172: step 1771, loss -522.473, acc 0.9375\n",
      "2017-09-12T00:20:31.435366: step 1772, loss -268.847, acc 0.90625\n",
      "2017-09-12T00:20:31.593789: step 1773, loss -381.519, acc 0.875\n",
      "2017-09-12T00:20:31.729981: step 1774, loss -377.097, acc 0.9375\n",
      "2017-09-12T00:20:31.888511: step 1775, loss -305.71, acc 0.90625\n",
      "2017-09-12T00:20:32.029722: step 1776, loss -7.10962, acc 0.9375\n",
      "2017-09-12T00:20:32.186095: step 1777, loss -394.821, acc 1\n",
      "2017-09-12T00:20:32.330120: step 1778, loss -454.319, acc 0.875\n",
      "2017-09-12T00:20:32.479708: step 1779, loss -1166.24, acc 0.96875\n",
      "2017-09-12T00:20:32.643259: step 1780, loss -504.862, acc 0.96875\n",
      "2017-09-12T00:20:32.792240: step 1781, loss -534.982, acc 0.9375\n",
      "2017-09-12T00:20:32.949110: step 1782, loss -689.487, acc 0.96875\n",
      "2017-09-12T00:20:33.104695: step 1783, loss -423.888, acc 0.90625\n",
      "2017-09-12T00:20:33.284525: step 1784, loss -253.811, acc 0.90625\n",
      "2017-09-12T00:20:33.430141: step 1785, loss -803.437, acc 0.96875\n",
      "2017-09-12T00:20:33.595464: step 1786, loss -523.394, acc 0.96875\n",
      "2017-09-12T00:20:33.752183: step 1787, loss -0.171234, acc 0.9375\n",
      "2017-09-12T00:20:33.912146: step 1788, loss -1074.85, acc 1\n",
      "2017-09-12T00:20:34.079280: step 1789, loss -139.125, acc 0.875\n",
      "2017-09-12T00:20:34.212087: step 1790, loss -297.8, acc 0.9375\n",
      "2017-09-12T00:20:34.382485: step 1791, loss -704.104, acc 1\n",
      "2017-09-12T00:20:34.520458: step 1792, loss -546.942, acc 0.9375\n",
      "2017-09-12T00:20:34.658901: step 1793, loss -311.488, acc 0.875\n",
      "2017-09-12T00:20:34.829299: step 1794, loss -668.307, acc 0.90625\n",
      "2017-09-12T00:20:34.981283: step 1795, loss 95.0497, acc 0.8125\n",
      "2017-09-12T00:20:35.136955: step 1796, loss -340.872, acc 0.9375\n",
      "2017-09-12T00:20:35.311211: step 1797, loss -519.764, acc 0.9375\n",
      "2017-09-12T00:20:35.444455: step 1798, loss -197.055, acc 0.90625\n",
      "2017-09-12T00:20:35.610738: step 1799, loss -424.347, acc 0.90625\n",
      "2017-09-12T00:20:35.747204: step 1800, loss -518.063, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:20:37.540798: step 1800, loss -543.263, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1800\n",
      "\n",
      "2017-09-12T00:20:40.726834: step 1801, loss -264.508, acc 0.90625\n",
      "2017-09-12T00:20:40.832067: step 1802, loss -305.178, acc 0.875\n",
      "2017-09-12T00:20:40.975954: step 1803, loss -681.165, acc 0.90625\n",
      "2017-09-12T00:20:41.114587: step 1804, loss -459.091, acc 0.9375\n",
      "2017-09-12T00:20:41.248288: step 1805, loss -445.201, acc 0.875\n",
      "2017-09-12T00:20:41.358703: step 1806, loss -688.844, acc 0.96875\n",
      "2017-09-12T00:20:41.463744: step 1807, loss -486.706, acc 0.90625\n",
      "2017-09-12T00:20:41.557463: step 1808, loss -826.96, acc 0.9375\n",
      "2017-09-12T00:20:41.680404: step 1809, loss -401.26, acc 0.90625\n",
      "2017-09-12T00:20:41.852402: step 1810, loss -121.414, acc 0.9375\n",
      "2017-09-12T00:20:41.996113: step 1811, loss -1177.28, acc 0.96875\n",
      "2017-09-12T00:20:42.100435: step 1812, loss -741.28, acc 0.90625\n",
      "2017-09-12T00:20:42.203855: step 1813, loss 116.464, acc 0.875\n",
      "2017-09-12T00:20:42.297026: step 1814, loss -159.462, acc 0.9375\n",
      "2017-09-12T00:20:42.398322: step 1815, loss -145.961, acc 0.9375\n",
      "2017-09-12T00:20:42.504791: step 1816, loss -314.373, acc 0.9375\n",
      "2017-09-12T00:20:42.626692: step 1817, loss -975.498, acc 0.9375\n",
      "2017-09-12T00:20:42.740398: step 1818, loss -642.944, acc 0.96875\n",
      "2017-09-12T00:20:42.831255: step 1819, loss -508.459, acc 0.875\n",
      "2017-09-12T00:20:42.923894: step 1820, loss -138.611, acc 0.875\n",
      "2017-09-12T00:20:43.033618: step 1821, loss -27.4013, acc 0.90625\n",
      "2017-09-12T00:20:43.132549: step 1822, loss -166.281, acc 0.90625\n",
      "2017-09-12T00:20:43.227998: step 1823, loss -853.695, acc 1\n",
      "2017-09-12T00:20:43.322685: step 1824, loss -431.608, acc 0.96875\n",
      "2017-09-12T00:20:43.554253: step 1825, loss -701.485, acc 0.96875\n",
      "2017-09-12T00:20:43.714890: step 1826, loss -336.913, acc 0.90625\n",
      "2017-09-12T00:20:43.927097: step 1827, loss -280.087, acc 0.9375\n",
      "2017-09-12T00:20:44.066174: step 1828, loss -1057.29, acc 0.96875\n",
      "2017-09-12T00:20:44.213281: step 1829, loss -674.805, acc 0.875\n",
      "2017-09-12T00:20:44.354381: step 1830, loss -131.332, acc 0.90625\n",
      "2017-09-12T00:20:44.505040: step 1831, loss 110.062, acc 0.84375\n",
      "2017-09-12T00:20:44.654162: step 1832, loss -49.9827, acc 0.90625\n",
      "2017-09-12T00:20:44.804902: step 1833, loss -139.511, acc 0.9375\n",
      "2017-09-12T00:20:44.956094: step 1834, loss -571.141, acc 0.96875\n",
      "2017-09-12T00:20:45.126010: step 1835, loss -138.854, acc 0.90625\n",
      "2017-09-12T00:20:45.267976: step 1836, loss -55.0509, acc 0.875\n",
      "2017-09-12T00:20:45.427014: step 1837, loss -113.541, acc 0.875\n",
      "2017-09-12T00:20:45.592278: step 1838, loss -498.347, acc 0.84375\n",
      "2017-09-12T00:20:45.745780: step 1839, loss -268.525, acc 0.9375\n",
      "2017-09-12T00:20:45.901096: step 1840, loss 35.0978, acc 0.84375\n",
      "2017-09-12T00:20:45.961380: step 1841, loss -1173.84, acc 0.875\n",
      "2017-09-12T00:20:46.177966: step 1842, loss -1561.71, acc 0.9375\n",
      "2017-09-12T00:20:46.362708: step 1843, loss -253.557, acc 0.90625\n",
      "2017-09-12T00:20:46.543156: step 1844, loss -768.759, acc 0.90625\n",
      "2017-09-12T00:20:46.664183: step 1845, loss -685.135, acc 1\n",
      "2017-09-12T00:20:46.811739: step 1846, loss -1332.33, acc 0.9375\n",
      "2017-09-12T00:20:46.988624: step 1847, loss -1528.25, acc 1\n",
      "2017-09-12T00:20:47.142512: step 1848, loss -1179.87, acc 0.9375\n",
      "2017-09-12T00:20:47.280641: step 1849, loss -308.226, acc 0.90625\n",
      "2017-09-12T00:20:47.428796: step 1850, loss -971.779, acc 0.96875\n",
      "2017-09-12T00:20:47.595147: step 1851, loss -648.265, acc 0.90625\n",
      "2017-09-12T00:20:47.750847: step 1852, loss -400.899, acc 0.96875\n",
      "2017-09-12T00:20:47.946340: step 1853, loss -455.84, acc 0.96875\n",
      "2017-09-12T00:20:48.071017: step 1854, loss -122.766, acc 0.96875\n",
      "2017-09-12T00:20:48.232723: step 1855, loss -1034.44, acc 1\n",
      "2017-09-12T00:20:48.379649: step 1856, loss 428.941, acc 0.8125\n",
      "2017-09-12T00:20:48.519972: step 1857, loss -205.604, acc 0.90625\n",
      "2017-09-12T00:20:48.730765: step 1858, loss -610.565, acc 0.90625\n",
      "2017-09-12T00:20:48.923773: step 1859, loss -129.31, acc 0.9375\n",
      "2017-09-12T00:20:49.087719: step 1860, loss -624.077, acc 0.875\n",
      "2017-09-12T00:20:49.250503: step 1861, loss -155.155, acc 0.90625\n",
      "2017-09-12T00:20:49.409317: step 1862, loss -878.568, acc 0.96875\n",
      "2017-09-12T00:20:49.540264: step 1863, loss -949.905, acc 0.9375\n",
      "2017-09-12T00:20:49.681535: step 1864, loss -144.429, acc 0.9375\n",
      "2017-09-12T00:20:49.842313: step 1865, loss -649.375, acc 0.9375\n",
      "2017-09-12T00:20:49.994525: step 1866, loss -1186.91, acc 0.9375\n",
      "2017-09-12T00:20:50.149976: step 1867, loss -836.447, acc 0.9375\n",
      "2017-09-12T00:20:50.297568: step 1868, loss -919.511, acc 0.9375\n",
      "2017-09-12T00:20:50.433471: step 1869, loss -832.109, acc 0.9375\n",
      "2017-09-12T00:20:50.591888: step 1870, loss -953.108, acc 1\n",
      "2017-09-12T00:20:50.746652: step 1871, loss -813.127, acc 0.9375\n",
      "2017-09-12T00:20:50.895558: step 1872, loss -1355.98, acc 1\n",
      "2017-09-12T00:20:51.047420: step 1873, loss -462.185, acc 0.90625\n",
      "2017-09-12T00:20:51.163417: step 1874, loss -192.544, acc 0.90625\n",
      "2017-09-12T00:20:51.329182: step 1875, loss -311.672, acc 0.9375\n",
      "2017-09-12T00:20:51.463415: step 1876, loss -1150.95, acc 0.9375\n",
      "2017-09-12T00:20:51.602772: step 1877, loss 99.571, acc 0.8125\n",
      "2017-09-12T00:20:51.740685: step 1878, loss -463.733, acc 1\n",
      "2017-09-12T00:20:51.899200: step 1879, loss -1713.04, acc 1\n",
      "2017-09-12T00:20:52.025226: step 1880, loss -579.044, acc 0.96875\n",
      "2017-09-12T00:20:52.172883: step 1881, loss -149.187, acc 0.96875\n",
      "2017-09-12T00:20:52.304543: step 1882, loss -639.403, acc 0.96875\n",
      "2017-09-12T00:20:52.477136: step 1883, loss -789.543, acc 1\n",
      "2017-09-12T00:20:52.631945: step 1884, loss -194.256, acc 0.90625\n",
      "2017-09-12T00:20:52.759742: step 1885, loss -335.022, acc 0.9375\n",
      "2017-09-12T00:20:52.907180: step 1886, loss -1271.64, acc 0.96875\n",
      "2017-09-12T00:20:53.071251: step 1887, loss -485.821, acc 0.9375\n",
      "2017-09-12T00:20:53.196139: step 1888, loss -496.258, acc 0.9375\n",
      "2017-09-12T00:20:53.355516: step 1889, loss -1090.46, acc 0.90625\n",
      "2017-09-12T00:20:53.535364: step 1890, loss -1432.62, acc 1\n",
      "2017-09-12T00:20:53.702785: step 1891, loss -725.132, acc 0.96875\n",
      "2017-09-12T00:20:53.838152: step 1892, loss -607.606, acc 0.90625\n",
      "2017-09-12T00:20:54.010726: step 1893, loss -1210.6, acc 0.9375\n",
      "2017-09-12T00:20:54.200238: step 1894, loss -358.303, acc 0.90625\n",
      "2017-09-12T00:20:54.388170: step 1895, loss -18.8701, acc 0.875\n",
      "2017-09-12T00:20:54.674156: step 1896, loss -945.93, acc 1\n",
      "2017-09-12T00:20:54.924330: step 1897, loss -551.375, acc 0.90625\n",
      "2017-09-12T00:20:55.206234: step 1898, loss -612.005, acc 0.90625\n",
      "2017-09-12T00:20:55.540158: step 1899, loss -570.847, acc 0.9375\n",
      "2017-09-12T00:20:55.862435: step 1900, loss -198.469, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:20:58.503532: step 1900, loss -631.539, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-1900\n",
      "\n",
      "2017-09-12T00:21:02.327161: step 1901, loss -4.72281, acc 0.90625\n",
      "2017-09-12T00:21:02.451381: step 1902, loss -150.521, acc 0.84375\n",
      "2017-09-12T00:21:02.571818: step 1903, loss -651.3, acc 0.90625\n",
      "2017-09-12T00:21:02.744252: step 1904, loss -1155.58, acc 0.9375\n",
      "2017-09-12T00:21:02.860795: step 1905, loss -14.0288, acc 0.875\n",
      "2017-09-12T00:21:02.980398: step 1906, loss -969.448, acc 0.9375\n",
      "2017-09-12T00:21:03.090513: step 1907, loss -178.28, acc 0.96875\n",
      "2017-09-12T00:21:03.211870: step 1908, loss -603.259, acc 0.9375\n",
      "2017-09-12T00:21:03.324166: step 1909, loss -855.221, acc 0.9375\n",
      "2017-09-12T00:21:03.464854: step 1910, loss -33.2773, acc 0.875\n",
      "2017-09-12T00:21:03.564104: step 1911, loss -329.598, acc 0.90625\n",
      "2017-09-12T00:21:03.658679: step 1912, loss -505.318, acc 0.90625\n",
      "2017-09-12T00:21:03.753713: step 1913, loss -471.999, acc 0.90625\n",
      "2017-09-12T00:21:03.884281: step 1914, loss 0, acc 1\n",
      "2017-09-12T00:21:03.987385: step 1915, loss -330.07, acc 0.90625\n",
      "2017-09-12T00:21:04.084553: step 1916, loss -1042.5, acc 0.90625\n",
      "2017-09-12T00:21:04.187675: step 1917, loss -814.315, acc 0.96875\n",
      "2017-09-12T00:21:04.281935: step 1918, loss -695.956, acc 0.875\n",
      "2017-09-12T00:21:04.372964: step 1919, loss -627.785, acc 0.9375\n",
      "2017-09-12T00:21:04.470169: step 1920, loss -710.258, acc 0.96875\n",
      "2017-09-12T00:21:04.748261: step 1921, loss -1457.5, acc 0.9375\n",
      "2017-09-12T00:21:04.891847: step 1922, loss 146.945, acc 0.875\n",
      "2017-09-12T00:21:05.045290: step 1923, loss 923.526, acc 0.78125\n",
      "2017-09-12T00:21:05.181365: step 1924, loss 4.86618, acc 0.875\n",
      "2017-09-12T00:21:05.330328: step 1925, loss -540.181, acc 0.875\n",
      "2017-09-12T00:21:05.481635: step 1926, loss 326.264, acc 0.90625\n",
      "2017-09-12T00:21:05.656136: step 1927, loss -722.961, acc 0.90625\n",
      "2017-09-12T00:21:05.792663: step 1928, loss -470.272, acc 0.90625\n",
      "2017-09-12T00:21:05.955015: step 1929, loss -855.068, acc 0.96875\n",
      "2017-09-12T00:21:06.104612: step 1930, loss -1014.95, acc 0.90625\n",
      "2017-09-12T00:21:06.258489: step 1931, loss -307.363, acc 0.9375\n",
      "2017-09-12T00:21:06.407582: step 1932, loss -656.931, acc 1\n",
      "2017-09-12T00:21:06.552675: step 1933, loss 37.3374, acc 0.875\n",
      "2017-09-12T00:21:06.708246: step 1934, loss -1417.62, acc 0.9375\n",
      "2017-09-12T00:21:06.852331: step 1935, loss -886.53, acc 0.96875\n",
      "2017-09-12T00:21:07.018392: step 1936, loss -964.698, acc 0.96875\n",
      "2017-09-12T00:21:07.174573: step 1937, loss 9.70732, acc 0.90625\n",
      "2017-09-12T00:21:07.341439: step 1938, loss -479.264, acc 0.84375\n",
      "2017-09-12T00:21:07.484049: step 1939, loss 155.322, acc 0.90625\n",
      "2017-09-12T00:21:07.629918: step 1940, loss 28.7742, acc 0.84375\n",
      "2017-09-12T00:21:07.791202: step 1941, loss -334.234, acc 0.9375\n",
      "2017-09-12T00:21:07.942273: step 1942, loss -126.47, acc 0.90625\n",
      "2017-09-12T00:21:08.085876: step 1943, loss -332.477, acc 0.90625\n",
      "2017-09-12T00:21:08.245690: step 1944, loss -494.892, acc 0.9375\n",
      "2017-09-12T00:21:08.391321: step 1945, loss 84.5354, acc 0.84375\n",
      "2017-09-12T00:21:08.547171: step 1946, loss -1037.5, acc 0.96875\n",
      "2017-09-12T00:21:08.703016: step 1947, loss -329.128, acc 0.875\n",
      "2017-09-12T00:21:08.854365: step 1948, loss -1043.92, acc 0.875\n",
      "2017-09-12T00:21:09.010538: step 1949, loss -777.541, acc 0.9375\n",
      "2017-09-12T00:21:09.168752: step 1950, loss -113.435, acc 0.90625\n",
      "2017-09-12T00:21:09.311485: step 1951, loss -974.388, acc 0.875\n",
      "2017-09-12T00:21:09.459955: step 1952, loss -1065.9, acc 0.9375\n",
      "2017-09-12T00:21:09.629803: step 1953, loss -320.48, acc 0.875\n",
      "2017-09-12T00:21:09.789031: step 1954, loss -994.832, acc 0.9375\n",
      "2017-09-12T00:21:09.934484: step 1955, loss 0, acc 1\n",
      "2017-09-12T00:21:10.087446: step 1956, loss -666.186, acc 1\n",
      "2017-09-12T00:21:10.249636: step 1957, loss -347.54, acc 0.90625\n",
      "2017-09-12T00:21:10.393251: step 1958, loss -538.909, acc 0.9375\n",
      "2017-09-12T00:21:10.549503: step 1959, loss -472.069, acc 0.875\n",
      "2017-09-12T00:21:10.704965: step 1960, loss -811.843, acc 0.875\n",
      "2017-09-12T00:21:10.858404: step 1961, loss -400.149, acc 0.875\n",
      "2017-09-12T00:21:10.996405: step 1962, loss -838.091, acc 1\n",
      "2017-09-12T00:21:11.152756: step 1963, loss -702.418, acc 0.9375\n",
      "2017-09-12T00:21:11.307230: step 1964, loss 366.357, acc 0.78125\n",
      "2017-09-12T00:21:11.468445: step 1965, loss -232.969, acc 0.90625\n",
      "2017-09-12T00:21:11.616919: step 1966, loss -981.095, acc 0.96875\n",
      "2017-09-12T00:21:11.754648: step 1967, loss 172.462, acc 0.90625\n",
      "2017-09-12T00:21:11.893041: step 1968, loss -28.4226, acc 0.90625\n",
      "2017-09-12T00:21:12.033464: step 1969, loss 13.9741, acc 0.90625\n",
      "2017-09-12T00:21:12.196409: step 1970, loss -1082.45, acc 0.9375\n",
      "2017-09-12T00:21:12.353374: step 1971, loss -697.023, acc 0.875\n",
      "2017-09-12T00:21:12.495748: step 1972, loss -347.613, acc 0.875\n",
      "2017-09-12T00:21:12.646950: step 1973, loss -81.6726, acc 0.84375\n",
      "2017-09-12T00:21:12.806755: step 1974, loss -1097.62, acc 0.875\n",
      "2017-09-12T00:21:12.943464: step 1975, loss -1042.06, acc 0.9375\n",
      "2017-09-12T00:21:13.096282: step 1976, loss -160.285, acc 0.9375\n",
      "2017-09-12T00:21:13.260063: step 1977, loss -726.097, acc 0.96875\n",
      "2017-09-12T00:21:13.406704: step 1978, loss 106.143, acc 0.84375\n",
      "2017-09-12T00:21:13.565242: step 1979, loss 293.497, acc 0.84375\n",
      "2017-09-12T00:21:13.696281: step 1980, loss -853.506, acc 0.96875\n",
      "2017-09-12T00:21:13.862947: step 1981, loss -279.123, acc 0.9375\n",
      "2017-09-12T00:21:14.036050: step 1982, loss 146.236, acc 0.875\n",
      "2017-09-12T00:21:14.176068: step 1983, loss -311.23, acc 0.875\n",
      "2017-09-12T00:21:14.326598: step 1984, loss -563.096, acc 0.9375\n",
      "2017-09-12T00:21:14.486627: step 1985, loss -759.766, acc 0.90625\n",
      "2017-09-12T00:21:14.634239: step 1986, loss -563.411, acc 0.90625\n",
      "2017-09-12T00:21:14.763034: step 1987, loss -608.787, acc 0.9375\n",
      "2017-09-12T00:21:14.927876: step 1988, loss -795.758, acc 0.9375\n",
      "2017-09-12T00:21:15.097063: step 1989, loss -1236.27, acc 1\n",
      "2017-09-12T00:21:15.251601: step 1990, loss -1032.44, acc 0.96875\n",
      "2017-09-12T00:21:15.384316: step 1991, loss -15.6789, acc 0.90625\n",
      "2017-09-12T00:21:15.530806: step 1992, loss -199.222, acc 0.90625\n",
      "2017-09-12T00:21:15.689357: step 1993, loss 183.434, acc 0.90625\n",
      "2017-09-12T00:21:15.832319: step 1994, loss -1076.12, acc 0.96875\n",
      "2017-09-12T00:21:15.990859: step 1995, loss -1579.17, acc 0.96875\n",
      "2017-09-12T00:21:16.161999: step 1996, loss -394.963, acc 0.875\n",
      "2017-09-12T00:21:16.305669: step 1997, loss 148.297, acc 0.9375\n",
      "2017-09-12T00:21:16.459474: step 1998, loss 137.443, acc 0.90625\n",
      "2017-09-12T00:21:16.610638: step 1999, loss -214.731, acc 0.90625\n",
      "2017-09-12T00:21:16.754063: step 2000, loss -455.482, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:21:18.154818: step 2000, loss -705.861, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2000\n",
      "\n",
      "2017-09-12T00:21:19.914197: step 2001, loss 28.8333, acc 0.875\n",
      "2017-09-12T00:21:20.007312: step 2002, loss -715.891, acc 0.96875\n",
      "2017-09-12T00:21:20.136820: step 2003, loss -180.982, acc 0.9375\n",
      "2017-09-12T00:21:20.248141: step 2004, loss -310.608, acc 0.96875\n",
      "2017-09-12T00:21:20.350138: step 2005, loss -1069.37, acc 1\n",
      "2017-09-12T00:21:20.450964: step 2006, loss -696.711, acc 0.9375\n",
      "2017-09-12T00:21:20.560247: step 2007, loss -372.74, acc 0.90625\n",
      "2017-09-12T00:21:20.675204: step 2008, loss -241.288, acc 0.9375\n",
      "2017-09-12T00:21:20.771316: step 2009, loss -968.389, acc 0.9375\n",
      "2017-09-12T00:21:20.864031: step 2010, loss -1071.87, acc 0.9375\n",
      "2017-09-12T00:21:20.957451: step 2011, loss -186.691, acc 0.9375\n",
      "2017-09-12T00:21:21.052631: step 2012, loss -413.308, acc 0.90625\n",
      "2017-09-12T00:21:21.139951: step 2013, loss -36.8566, acc 0.875\n",
      "2017-09-12T00:21:21.233625: step 2014, loss -1270.07, acc 0.96875\n",
      "2017-09-12T00:21:21.325572: step 2015, loss -1117.78, acc 0.9375\n",
      "2017-09-12T00:21:21.451196: step 2016, loss -202.882, acc 0.90625\n",
      "2017-09-12T00:21:21.533256: step 2017, loss -1135.94, acc 0.96875\n",
      "2017-09-12T00:21:21.623178: step 2018, loss -703.57, acc 0.90625\n",
      "2017-09-12T00:21:21.715152: step 2019, loss -702.926, acc 0.96875\n",
      "2017-09-12T00:21:21.815251: step 2020, loss -1339.4, acc 0.9375\n",
      "2017-09-12T00:21:21.908714: step 2021, loss -961.799, acc 0.9375\n",
      "2017-09-12T00:21:21.999630: step 2022, loss -694.315, acc 0.9375\n",
      "2017-09-12T00:21:22.253037: step 2023, loss -734.677, acc 0.90625\n",
      "2017-09-12T00:21:22.396383: step 2024, loss -6.75873, acc 0.875\n",
      "2017-09-12T00:21:22.532453: step 2025, loss -376.473, acc 0.96875\n",
      "2017-09-12T00:21:22.698754: step 2026, loss 198.306, acc 0.875\n",
      "2017-09-12T00:21:22.838973: step 2027, loss -395.628, acc 0.875\n",
      "2017-09-12T00:21:23.035381: step 2028, loss -1206.37, acc 0.96875\n",
      "2017-09-12T00:21:23.181684: step 2029, loss -1099.22, acc 1\n",
      "2017-09-12T00:21:23.318883: step 2030, loss -286.005, acc 0.90625\n",
      "2017-09-12T00:21:23.462132: step 2031, loss -1548.17, acc 1\n",
      "2017-09-12T00:21:23.612019: step 2032, loss -1132.55, acc 0.96875\n",
      "2017-09-12T00:21:23.755191: step 2033, loss -1254.01, acc 1\n",
      "2017-09-12T00:21:23.912373: step 2034, loss -1275.52, acc 0.9375\n",
      "2017-09-12T00:21:24.065694: step 2035, loss -911.692, acc 0.96875\n",
      "2017-09-12T00:21:24.211083: step 2036, loss -967.491, acc 0.9375\n",
      "2017-09-12T00:21:24.362378: step 2037, loss -577.044, acc 0.9375\n",
      "2017-09-12T00:21:24.516542: step 2038, loss -689.186, acc 0.84375\n",
      "2017-09-12T00:21:24.664838: step 2039, loss -1068.77, acc 1\n",
      "2017-09-12T00:21:24.820657: step 2040, loss -398.735, acc 0.9375\n",
      "2017-09-12T00:21:24.954505: step 2041, loss -510.142, acc 1\n",
      "2017-09-12T00:21:25.110602: step 2042, loss -951.811, acc 0.875\n",
      "2017-09-12T00:21:25.272852: step 2043, loss -1144.63, acc 0.9375\n",
      "2017-09-12T00:21:25.428096: step 2044, loss -382.102, acc 0.96875\n",
      "2017-09-12T00:21:25.592873: step 2045, loss -754.574, acc 0.9375\n",
      "2017-09-12T00:21:25.761892: step 2046, loss -763.686, acc 0.96875\n",
      "2017-09-12T00:21:25.954032: step 2047, loss -1066.78, acc 0.96875\n",
      "2017-09-12T00:21:26.113817: step 2048, loss -761.837, acc 0.9375\n",
      "2017-09-12T00:21:26.296879: step 2049, loss -190.351, acc 0.875\n",
      "2017-09-12T00:21:26.450834: step 2050, loss -627.407, acc 0.875\n",
      "2017-09-12T00:21:26.647038: step 2051, loss -1449.28, acc 0.9375\n",
      "2017-09-12T00:21:26.823507: step 2052, loss -1145.23, acc 0.9375\n",
      "2017-09-12T00:21:27.040050: step 2053, loss -584.855, acc 0.9375\n",
      "2017-09-12T00:21:27.266390: step 2054, loss -923.098, acc 0.96875\n",
      "2017-09-12T00:21:27.410318: step 2055, loss 39.4842, acc 0.90625\n",
      "2017-09-12T00:21:27.561787: step 2056, loss 299.545, acc 0.8125\n",
      "2017-09-12T00:21:27.709881: step 2057, loss -234.345, acc 0.90625\n",
      "2017-09-12T00:21:27.853592: step 2058, loss -419.771, acc 0.9375\n",
      "2017-09-12T00:21:28.003336: step 2059, loss -1007.55, acc 1\n",
      "2017-09-12T00:21:28.177083: step 2060, loss -216.554, acc 0.84375\n",
      "2017-09-12T00:21:28.314729: step 2061, loss -1564.52, acc 0.96875\n",
      "2017-09-12T00:21:28.504252: step 2062, loss -593.732, acc 0.875\n",
      "2017-09-12T00:21:28.650586: step 2063, loss -734.505, acc 0.96875\n",
      "2017-09-12T00:21:28.802426: step 2064, loss -1268.72, acc 0.96875\n",
      "2017-09-12T00:21:28.979598: step 2065, loss -195.896, acc 0.90625\n",
      "2017-09-12T00:21:29.145863: step 2066, loss -777.654, acc 0.875\n",
      "2017-09-12T00:21:29.298222: step 2067, loss -190.588, acc 0.9375\n",
      "2017-09-12T00:21:29.460783: step 2068, loss -435.142, acc 0.90625\n",
      "2017-09-12T00:21:29.629984: step 2069, loss -1351.88, acc 0.96875\n",
      "2017-09-12T00:21:29.772557: step 2070, loss -335.102, acc 0.90625\n",
      "2017-09-12T00:21:29.926688: step 2071, loss -1340.27, acc 0.96875\n",
      "2017-09-12T00:21:30.080618: step 2072, loss -49.5546, acc 0.875\n",
      "2017-09-12T00:21:30.233316: step 2073, loss 132.778, acc 0.84375\n",
      "2017-09-12T00:21:30.402344: step 2074, loss -786.396, acc 1\n",
      "2017-09-12T00:21:30.573907: step 2075, loss -1465.07, acc 0.9375\n",
      "2017-09-12T00:21:30.724574: step 2076, loss -1394.75, acc 0.96875\n",
      "2017-09-12T00:21:30.884553: step 2077, loss -450.284, acc 0.90625\n",
      "2017-09-12T00:21:31.033915: step 2078, loss 171.371, acc 0.84375\n",
      "2017-09-12T00:21:31.173489: step 2079, loss 280.569, acc 0.8125\n",
      "2017-09-12T00:21:31.329618: step 2080, loss -1192.17, acc 0.9375\n",
      "2017-09-12T00:21:31.500651: step 2081, loss -947.799, acc 0.96875\n",
      "2017-09-12T00:21:31.648218: step 2082, loss -841.825, acc 0.9375\n",
      "2017-09-12T00:21:31.806938: step 2083, loss -448.512, acc 0.9375\n",
      "2017-09-12T00:21:31.944546: step 2084, loss -29.1828, acc 0.90625\n",
      "2017-09-12T00:21:32.099405: step 2085, loss 147.434, acc 0.875\n",
      "2017-09-12T00:21:32.262026: step 2086, loss -40.5892, acc 0.90625\n",
      "2017-09-12T00:21:32.419816: step 2087, loss -1640.77, acc 0.96875\n",
      "2017-09-12T00:21:32.566792: step 2088, loss -202.981, acc 0.875\n",
      "2017-09-12T00:21:32.737422: step 2089, loss -1337.3, acc 0.96875\n",
      "2017-09-12T00:21:32.887922: step 2090, loss -1197.39, acc 0.90625\n",
      "2017-09-12T00:21:33.033937: step 2091, loss -671.571, acc 0.90625\n",
      "2017-09-12T00:21:33.192222: step 2092, loss -419.753, acc 0.84375\n",
      "2017-09-12T00:21:33.341772: step 2093, loss -873.165, acc 0.96875\n",
      "2017-09-12T00:21:33.492667: step 2094, loss -1619.01, acc 0.9375\n",
      "2017-09-12T00:21:33.651385: step 2095, loss -1038.45, acc 0.9375\n",
      "2017-09-12T00:21:33.797719: step 2096, loss -1211.81, acc 0.96875\n",
      "2017-09-12T00:21:33.953669: step 2097, loss -359.849, acc 0.90625\n",
      "2017-09-12T00:21:34.129603: step 2098, loss -1197.27, acc 0.96875\n",
      "2017-09-12T00:21:34.276240: step 2099, loss -368.2, acc 0.875\n",
      "2017-09-12T00:21:34.426872: step 2100, loss -632.593, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:21:35.871113: step 2100, loss -803.926, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2100\n",
      "\n",
      "2017-09-12T00:21:38.077728: step 2101, loss -412.423, acc 0.90625\n",
      "2017-09-12T00:21:38.178007: step 2102, loss -1642.88, acc 1\n",
      "2017-09-12T00:21:38.271758: step 2103, loss 243.814, acc 0.90625\n",
      "2017-09-12T00:21:38.313611: step 2104, loss -891.459, acc 0.875\n",
      "2017-09-12T00:21:38.427889: step 2105, loss -1773.96, acc 0.96875\n",
      "2017-09-12T00:21:38.552551: step 2106, loss -427.939, acc 0.96875\n",
      "2017-09-12T00:21:38.662294: step 2107, loss -814.51, acc 0.9375\n",
      "2017-09-12T00:21:38.754607: step 2108, loss -201.372, acc 0.9375\n",
      "2017-09-12T00:21:38.847391: step 2109, loss -2183.61, acc 0.9375\n",
      "2017-09-12T00:21:38.940835: step 2110, loss -613.19, acc 0.9375\n",
      "2017-09-12T00:21:39.050652: step 2111, loss 142.253, acc 0.875\n",
      "2017-09-12T00:21:39.149208: step 2112, loss 193.036, acc 0.90625\n",
      "2017-09-12T00:21:39.241351: step 2113, loss -1243.55, acc 0.96875\n",
      "2017-09-12T00:21:39.354046: step 2114, loss -1201.59, acc 1\n",
      "2017-09-12T00:21:39.453375: step 2115, loss -867.151, acc 0.9375\n",
      "2017-09-12T00:21:39.542251: step 2116, loss -1234.85, acc 0.9375\n",
      "2017-09-12T00:21:39.654399: step 2117, loss -602.333, acc 0.96875\n",
      "2017-09-12T00:21:39.755707: step 2118, loss 607.936, acc 0.8125\n",
      "2017-09-12T00:21:40.001398: step 2119, loss -1490.73, acc 0.90625\n",
      "2017-09-12T00:21:40.154812: step 2120, loss 128.359, acc 0.875\n",
      "2017-09-12T00:21:40.268231: step 2121, loss -602.226, acc 0.90625\n",
      "2017-09-12T00:21:40.444477: step 2122, loss -1014.31, acc 0.9375\n",
      "2017-09-12T00:21:40.602861: step 2123, loss -861.815, acc 0.9375\n",
      "2017-09-12T00:21:40.738421: step 2124, loss 138.055, acc 0.875\n",
      "2017-09-12T00:21:40.891863: step 2125, loss -826.894, acc 0.9375\n",
      "2017-09-12T00:21:41.032519: step 2126, loss -426.122, acc 0.875\n",
      "2017-09-12T00:21:41.180486: step 2127, loss -1300.14, acc 0.96875\n",
      "2017-09-12T00:21:41.328808: step 2128, loss 149.068, acc 0.875\n",
      "2017-09-12T00:21:41.492457: step 2129, loss -394.961, acc 0.90625\n",
      "2017-09-12T00:21:41.634351: step 2130, loss -919.171, acc 0.90625\n",
      "2017-09-12T00:21:41.848335: step 2131, loss -839.69, acc 0.90625\n",
      "2017-09-12T00:21:42.064451: step 2132, loss -1039.39, acc 0.90625\n",
      "2017-09-12T00:21:42.214783: step 2133, loss 38.8494, acc 0.90625\n",
      "2017-09-12T00:21:42.359667: step 2134, loss -1292.22, acc 0.9375\n",
      "2017-09-12T00:21:42.510115: step 2135, loss -460.257, acc 0.875\n",
      "2017-09-12T00:21:42.658475: step 2136, loss -250.001, acc 0.875\n",
      "2017-09-12T00:21:42.808234: step 2137, loss -1597.13, acc 0.96875\n",
      "2017-09-12T00:21:42.962137: step 2138, loss -1136.77, acc 0.96875\n",
      "2017-09-12T00:21:43.118557: step 2139, loss -481.503, acc 0.96875\n",
      "2017-09-12T00:21:43.275425: step 2140, loss -1064.7, acc 0.90625\n",
      "2017-09-12T00:21:43.421571: step 2141, loss -881.191, acc 0.875\n",
      "2017-09-12T00:21:43.565963: step 2142, loss -1424.53, acc 0.90625\n",
      "2017-09-12T00:21:43.716427: step 2143, loss -1089.99, acc 1\n",
      "2017-09-12T00:21:43.888802: step 2144, loss -1030.13, acc 0.96875\n",
      "2017-09-12T00:21:44.007232: step 2145, loss -25.9602, acc 0.84375\n",
      "2017-09-12T00:21:44.167538: step 2146, loss -1125.95, acc 0.96875\n",
      "2017-09-12T00:21:44.315564: step 2147, loss -81.584, acc 0.875\n",
      "2017-09-12T00:21:44.464101: step 2148, loss -222.675, acc 0.9375\n",
      "2017-09-12T00:21:44.601867: step 2149, loss -1541.27, acc 0.9375\n",
      "2017-09-12T00:21:44.807084: step 2150, loss 222.777, acc 0.90625\n",
      "2017-09-12T00:21:44.938007: step 2151, loss -1398.76, acc 0.90625\n",
      "2017-09-12T00:21:45.142124: step 2152, loss -631.483, acc 0.9375\n",
      "2017-09-12T00:21:45.297692: step 2153, loss 23.7176, acc 0.9375\n",
      "2017-09-12T00:21:45.438782: step 2154, loss -1277.12, acc 0.9375\n",
      "2017-09-12T00:21:45.580379: step 2155, loss -668.455, acc 0.90625\n",
      "2017-09-12T00:21:45.732643: step 2156, loss -836.227, acc 0.96875\n",
      "2017-09-12T00:21:45.909478: step 2157, loss -1557.26, acc 0.96875\n",
      "2017-09-12T00:21:46.042593: step 2158, loss -510.45, acc 0.90625\n",
      "2017-09-12T00:21:46.189958: step 2159, loss -476.729, acc 0.9375\n",
      "2017-09-12T00:21:46.326373: step 2160, loss -1390.55, acc 0.9375\n",
      "2017-09-12T00:21:46.466446: step 2161, loss -898.271, acc 0.96875\n",
      "2017-09-12T00:21:46.630028: step 2162, loss -248.531, acc 0.90625\n",
      "2017-09-12T00:21:46.769322: step 2163, loss -839.681, acc 0.84375\n",
      "2017-09-12T00:21:46.918853: step 2164, loss -909.713, acc 0.96875\n",
      "2017-09-12T00:21:47.073956: step 2165, loss -1035.7, acc 0.875\n",
      "2017-09-12T00:21:47.219955: step 2166, loss -1334.42, acc 0.9375\n",
      "2017-09-12T00:21:47.361944: step 2167, loss -221.316, acc 0.9375\n",
      "2017-09-12T00:21:47.511471: step 2168, loss -1700.34, acc 0.875\n",
      "2017-09-12T00:21:47.649717: step 2169, loss -709.136, acc 0.9375\n",
      "2017-09-12T00:21:47.809107: step 2170, loss -1320.84, acc 0.90625\n",
      "2017-09-12T00:21:47.955852: step 2171, loss -256.315, acc 0.875\n",
      "2017-09-12T00:21:48.107715: step 2172, loss -716.356, acc 0.9375\n",
      "2017-09-12T00:21:48.250147: step 2173, loss -1148.76, acc 0.9375\n",
      "2017-09-12T00:21:48.389515: step 2174, loss -1517.08, acc 1\n",
      "2017-09-12T00:21:48.533345: step 2175, loss -1329.25, acc 1\n",
      "2017-09-12T00:21:48.703782: step 2176, loss -387.147, acc 0.90625\n",
      "2017-09-12T00:21:48.856159: step 2177, loss -27.0428, acc 0.9375\n",
      "2017-09-12T00:21:49.007676: step 2178, loss -176.928, acc 0.90625\n",
      "2017-09-12T00:21:49.163406: step 2179, loss -1789.32, acc 0.96875\n",
      "2017-09-12T00:21:49.324145: step 2180, loss 141.258, acc 0.8125\n",
      "2017-09-12T00:21:49.483524: step 2181, loss -838.057, acc 0.9375\n",
      "2017-09-12T00:21:49.641114: step 2182, loss -29.5048, acc 0.9375\n",
      "2017-09-12T00:21:49.831651: step 2183, loss -388.239, acc 0.9375\n",
      "2017-09-12T00:21:49.975523: step 2184, loss -1797.44, acc 1\n",
      "2017-09-12T00:21:50.128623: step 2185, loss -414.965, acc 0.90625\n",
      "2017-09-12T00:21:50.333243: step 2186, loss -264.875, acc 0.90625\n",
      "2017-09-12T00:21:50.490323: step 2187, loss -673.563, acc 0.875\n",
      "2017-09-12T00:21:50.646698: step 2188, loss -631.151, acc 0.90625\n",
      "2017-09-12T00:21:50.793211: step 2189, loss -471.944, acc 0.9375\n",
      "2017-09-12T00:21:50.936738: step 2190, loss -738.151, acc 0.875\n",
      "2017-09-12T00:21:51.093376: step 2191, loss -899.976, acc 0.9375\n",
      "2017-09-12T00:21:51.238228: step 2192, loss -1690.43, acc 0.90625\n",
      "2017-09-12T00:21:51.404865: step 2193, loss -689.839, acc 0.875\n",
      "2017-09-12T00:21:51.557092: step 2194, loss -540.026, acc 0.90625\n",
      "2017-09-12T00:21:51.710282: step 2195, loss -1166.06, acc 1\n",
      "2017-09-12T00:21:51.872446: step 2196, loss -1259.33, acc 0.96875\n",
      "2017-09-12T00:21:52.019745: step 2197, loss -688.162, acc 0.9375\n",
      "2017-09-12T00:21:52.170363: step 2198, loss -282.007, acc 0.875\n",
      "2017-09-12T00:21:52.314736: step 2199, loss -1643.34, acc 0.96875\n",
      "2017-09-12T00:21:52.477861: step 2200, loss -221.003, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:21:53.904249: step 2200, loss -910.652, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2200\n",
      "\n",
      "2017-09-12T00:21:55.636020: step 2201, loss -1241.33, acc 0.9375\n",
      "2017-09-12T00:21:55.733911: step 2202, loss -973.267, acc 0.9375\n",
      "2017-09-12T00:21:55.829922: step 2203, loss 56.5551, acc 0.875\n",
      "2017-09-12T00:21:55.927251: step 2204, loss -605.163, acc 0.875\n",
      "2017-09-12T00:21:56.055936: step 2205, loss -696.331, acc 1\n",
      "2017-09-12T00:21:56.229147: step 2206, loss -1410.22, acc 1\n",
      "2017-09-12T00:21:56.327116: step 2207, loss 672.874, acc 0.84375\n",
      "2017-09-12T00:21:56.423851: step 2208, loss 26.3022, acc 0.84375\n",
      "2017-09-12T00:21:56.535132: step 2209, loss -1300.58, acc 0.90625\n",
      "2017-09-12T00:21:56.645565: step 2210, loss -412.288, acc 0.9375\n",
      "2017-09-12T00:21:56.754415: step 2211, loss -939.456, acc 0.96875\n",
      "2017-09-12T00:21:56.900454: step 2212, loss 484.937, acc 0.84375\n",
      "2017-09-12T00:21:57.011861: step 2213, loss -1674.35, acc 0.90625\n",
      "2017-09-12T00:21:57.109272: step 2214, loss 1024.1, acc 0.78125\n",
      "2017-09-12T00:21:57.209553: step 2215, loss -7.14719, acc 0.90625\n",
      "2017-09-12T00:21:57.321306: step 2216, loss -1427.71, acc 0.96875\n",
      "2017-09-12T00:21:57.419921: step 2217, loss -479.575, acc 0.9375\n",
      "2017-09-12T00:21:57.513496: step 2218, loss -1171.65, acc 0.96875\n",
      "2017-09-12T00:21:57.607775: step 2219, loss -908.875, acc 0.90625\n",
      "2017-09-12T00:21:57.696657: step 2220, loss -967.569, acc 0.9375\n",
      "2017-09-12T00:21:57.809173: step 2221, loss -1392.73, acc 0.96875\n",
      "2017-09-12T00:21:58.071851: step 2222, loss -1195.11, acc 0.96875\n",
      "2017-09-12T00:21:58.234723: step 2223, loss -1679.41, acc 0.96875\n",
      "2017-09-12T00:21:58.371889: step 2224, loss 221.752, acc 0.9375\n",
      "2017-09-12T00:21:58.532236: step 2225, loss 395.893, acc 0.84375\n",
      "2017-09-12T00:21:58.664437: step 2226, loss -1581.66, acc 0.9375\n",
      "2017-09-12T00:21:58.821093: step 2227, loss -581.18, acc 0.875\n",
      "2017-09-12T00:21:58.957479: step 2228, loss -994.465, acc 0.875\n",
      "2017-09-12T00:21:59.096705: step 2229, loss -848.816, acc 0.9375\n",
      "2017-09-12T00:21:59.253595: step 2230, loss -1338.6, acc 1\n",
      "2017-09-12T00:21:59.399369: step 2231, loss -1014.84, acc 0.96875\n",
      "2017-09-12T00:21:59.553160: step 2232, loss -1452.19, acc 0.9375\n",
      "2017-09-12T00:21:59.705348: step 2233, loss -1395.9, acc 0.9375\n",
      "2017-09-12T00:21:59.991283: step 2234, loss -1733.46, acc 0.9375\n",
      "2017-09-12T00:22:00.183491: step 2235, loss -454.371, acc 1\n",
      "2017-09-12T00:22:00.346138: step 2236, loss -1734.28, acc 0.9375\n",
      "2017-09-12T00:22:00.497761: step 2237, loss -235.591, acc 0.9375\n",
      "2017-09-12T00:22:00.650611: step 2238, loss 565.607, acc 0.8125\n",
      "2017-09-12T00:22:00.793121: step 2239, loss -287.549, acc 0.875\n",
      "2017-09-12T00:22:00.947425: step 2240, loss -2541.15, acc 0.9375\n",
      "2017-09-12T00:22:01.084081: step 2241, loss 33.4813, acc 0.875\n",
      "2017-09-12T00:22:01.247924: step 2242, loss -258.819, acc 0.90625\n",
      "2017-09-12T00:22:01.405365: step 2243, loss -461.875, acc 0.90625\n",
      "2017-09-12T00:22:01.603860: step 2244, loss 191.127, acc 0.84375\n",
      "2017-09-12T00:22:01.783472: step 2245, loss -471.315, acc 0.9375\n",
      "2017-09-12T00:22:01.921330: step 2246, loss -784.144, acc 0.9375\n",
      "2017-09-12T00:22:02.071103: step 2247, loss -1273.77, acc 0.90625\n",
      "2017-09-12T00:22:02.218976: step 2248, loss -488.769, acc 0.96875\n",
      "2017-09-12T00:22:02.384768: step 2249, loss -1735.24, acc 0.96875\n",
      "2017-09-12T00:22:02.547411: step 2250, loss -1395.47, acc 1\n",
      "2017-09-12T00:22:02.685992: step 2251, loss -1251.07, acc 0.96875\n",
      "2017-09-12T00:22:02.840474: step 2252, loss -1685.02, acc 0.96875\n",
      "2017-09-12T00:22:02.994404: step 2253, loss -694.588, acc 0.96875\n",
      "2017-09-12T00:22:03.163595: step 2254, loss -1598.04, acc 0.9375\n",
      "2017-09-12T00:22:03.326293: step 2255, loss 217.238, acc 0.84375\n",
      "2017-09-12T00:22:03.472837: step 2256, loss -745.147, acc 0.9375\n",
      "2017-09-12T00:22:03.627377: step 2257, loss -1051.74, acc 0.90625\n",
      "2017-09-12T00:22:03.768104: step 2258, loss -976.284, acc 0.96875\n",
      "2017-09-12T00:22:03.895779: step 2259, loss -217.759, acc 0.9375\n",
      "2017-09-12T00:22:04.051002: step 2260, loss -483.762, acc 0.90625\n",
      "2017-09-12T00:22:04.196342: step 2261, loss -185.039, acc 0.84375\n",
      "2017-09-12T00:22:04.348447: step 2262, loss -804.855, acc 0.90625\n",
      "2017-09-12T00:22:04.482352: step 2263, loss -53.3052, acc 0.84375\n",
      "2017-09-12T00:22:04.638535: step 2264, loss -1490.37, acc 0.96875\n",
      "2017-09-12T00:22:04.791079: step 2265, loss -970.719, acc 0.96875\n",
      "2017-09-12T00:22:04.935214: step 2266, loss -1809.49, acc 0.90625\n",
      "2017-09-12T00:22:05.089442: step 2267, loss -1137.86, acc 0.96875\n",
      "2017-09-12T00:22:05.236503: step 2268, loss -1054.73, acc 0.90625\n",
      "2017-09-12T00:22:05.386782: step 2269, loss -1201.82, acc 0.96875\n",
      "2017-09-12T00:22:05.534393: step 2270, loss -665.263, acc 0.96875\n",
      "2017-09-12T00:22:05.691171: step 2271, loss -1250.94, acc 0.96875\n",
      "2017-09-12T00:22:05.840860: step 2272, loss -1314.9, acc 0.90625\n",
      "2017-09-12T00:22:05.998594: step 2273, loss -1184.78, acc 0.96875\n",
      "2017-09-12T00:22:06.150275: step 2274, loss -1040.5, acc 0.96875\n",
      "2017-09-12T00:22:06.282449: step 2275, loss 240.823, acc 0.875\n",
      "2017-09-12T00:22:06.432835: step 2276, loss -1235.52, acc 0.9375\n",
      "2017-09-12T00:22:06.563425: step 2277, loss -847.495, acc 0.90625\n",
      "2017-09-12T00:22:06.729835: step 2278, loss -238.453, acc 0.9375\n",
      "2017-09-12T00:22:06.884660: step 2279, loss 751.951, acc 0.84375\n",
      "2017-09-12T00:22:07.022277: step 2280, loss -1023.37, acc 0.9375\n",
      "2017-09-12T00:22:07.180505: step 2281, loss 306.931, acc 0.90625\n",
      "2017-09-12T00:22:07.320533: step 2282, loss -1053.11, acc 0.9375\n",
      "2017-09-12T00:22:07.484827: step 2283, loss -1123.07, acc 0.875\n",
      "2017-09-12T00:22:07.633478: step 2284, loss -809.541, acc 0.875\n",
      "2017-09-12T00:22:07.775051: step 2285, loss -1415.06, acc 0.9375\n",
      "2017-09-12T00:22:07.917496: step 2286, loss -1873.43, acc 0.96875\n",
      "2017-09-12T00:22:08.076590: step 2287, loss -591.292, acc 0.96875\n",
      "2017-09-12T00:22:08.235334: step 2288, loss -1557.8, acc 1\n",
      "2017-09-12T00:22:08.390519: step 2289, loss -293.837, acc 0.90625\n",
      "2017-09-12T00:22:08.531755: step 2290, loss -1448.42, acc 0.90625\n",
      "2017-09-12T00:22:08.682181: step 2291, loss -240.886, acc 0.96875\n",
      "2017-09-12T00:22:08.825787: step 2292, loss -848.042, acc 0.9375\n",
      "2017-09-12T00:22:08.971649: step 2293, loss -1510.07, acc 0.96875\n",
      "2017-09-12T00:22:09.131478: step 2294, loss -1018.92, acc 0.96875\n",
      "2017-09-12T00:22:09.286874: step 2295, loss -2046.88, acc 0.9375\n",
      "2017-09-12T00:22:09.414568: step 2296, loss -1359.28, acc 0.9375\n",
      "2017-09-12T00:22:09.568676: step 2297, loss -2227.02, acc 0.90625\n",
      "2017-09-12T00:22:09.714106: step 2298, loss -1532.44, acc 0.96875\n",
      "2017-09-12T00:22:09.867741: step 2299, loss -458.942, acc 0.90625\n",
      "2017-09-12T00:22:10.018014: step 2300, loss -1023.85, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:22:11.352504: step 2300, loss -1020.42, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2300\n",
      "\n",
      "2017-09-12T00:22:13.366711: step 2301, loss -516.3, acc 0.90625\n",
      "2017-09-12T00:22:13.461266: step 2302, loss -974.688, acc 0.90625\n",
      "2017-09-12T00:22:13.552962: step 2303, loss -278.805, acc 0.9375\n",
      "2017-09-12T00:22:13.654760: step 2304, loss -1809.81, acc 0.9375\n",
      "2017-09-12T00:22:13.765635: step 2305, loss -288.112, acc 0.96875\n",
      "2017-09-12T00:22:13.868399: step 2306, loss -1049.03, acc 0.96875\n",
      "2017-09-12T00:22:13.977960: step 2307, loss -548.155, acc 0.96875\n",
      "2017-09-12T00:22:14.140052: step 2308, loss -308.82, acc 0.875\n",
      "2017-09-12T00:22:14.271500: step 2309, loss -1854.74, acc 0.96875\n",
      "2017-09-12T00:22:14.412828: step 2310, loss -508.091, acc 0.9375\n",
      "2017-09-12T00:22:14.539512: step 2311, loss 754.019, acc 0.78125\n",
      "2017-09-12T00:22:14.638121: step 2312, loss -1234.51, acc 0.96875\n",
      "2017-09-12T00:22:14.731608: step 2313, loss -1047.45, acc 0.96875\n",
      "2017-09-12T00:22:14.824799: step 2314, loss -2455.24, acc 0.96875\n",
      "2017-09-12T00:22:14.917521: step 2315, loss -1341.68, acc 0.90625\n",
      "2017-09-12T00:22:15.055917: step 2316, loss -436.501, acc 0.84375\n",
      "2017-09-12T00:22:15.153491: step 2317, loss -630.869, acc 0.90625\n",
      "2017-09-12T00:22:15.246042: step 2318, loss -1595.68, acc 0.9375\n",
      "2017-09-12T00:22:15.340674: step 2319, loss -856.879, acc 0.9375\n",
      "2017-09-12T00:22:15.431263: step 2320, loss -390.482, acc 0.8125\n",
      "2017-09-12T00:22:15.529915: step 2321, loss -3193.89, acc 1\n",
      "2017-09-12T00:22:15.841035: step 2322, loss -807.938, acc 1\n",
      "2017-09-12T00:22:16.039207: step 2323, loss -1050.27, acc 0.96875\n",
      "2017-09-12T00:22:16.163072: step 2324, loss -766.811, acc 0.875\n",
      "2017-09-12T00:22:16.315593: step 2325, loss -1368.62, acc 0.96875\n",
      "2017-09-12T00:22:16.484181: step 2326, loss -728.842, acc 0.9375\n",
      "2017-09-12T00:22:16.621128: step 2327, loss -613.545, acc 0.9375\n",
      "2017-09-12T00:22:16.764046: step 2328, loss -1653.25, acc 0.90625\n",
      "2017-09-12T00:22:16.904126: step 2329, loss -942.053, acc 0.875\n",
      "2017-09-12T00:22:17.051397: step 2330, loss -854.771, acc 0.9375\n",
      "2017-09-12T00:22:17.202321: step 2331, loss -850.614, acc 0.9375\n",
      "2017-09-12T00:22:17.397065: step 2332, loss -1376.3, acc 0.96875\n",
      "2017-09-12T00:22:17.524035: step 2333, loss -810.059, acc 1\n",
      "2017-09-12T00:22:17.673012: step 2334, loss -401.833, acc 0.8125\n",
      "2017-09-12T00:22:17.823422: step 2335, loss -1632.57, acc 0.9375\n",
      "2017-09-12T00:22:17.967732: step 2336, loss -979.309, acc 0.875\n",
      "2017-09-12T00:22:18.115950: step 2337, loss -1135.22, acc 0.9375\n",
      "2017-09-12T00:22:18.269947: step 2338, loss -1962.15, acc 0.96875\n",
      "2017-09-12T00:22:18.474565: step 2339, loss -932.39, acc 0.90625\n",
      "2017-09-12T00:22:18.628905: step 2340, loss -1774.28, acc 0.90625\n",
      "2017-09-12T00:22:18.761879: step 2341, loss -356.1, acc 0.90625\n",
      "2017-09-12T00:22:18.915165: step 2342, loss -893.133, acc 0.90625\n",
      "2017-09-12T00:22:19.088399: step 2343, loss 201.549, acc 0.9375\n",
      "2017-09-12T00:22:19.235014: step 2344, loss -918.835, acc 0.9375\n",
      "2017-09-12T00:22:19.369975: step 2345, loss 46.9221, acc 0.9375\n",
      "2017-09-12T00:22:19.516026: step 2346, loss 710.767, acc 0.84375\n",
      "2017-09-12T00:22:19.694436: step 2347, loss -1047.8, acc 0.875\n",
      "2017-09-12T00:22:19.873256: step 2348, loss -510.782, acc 0.84375\n",
      "2017-09-12T00:22:20.060283: step 2349, loss -540.315, acc 0.96875\n",
      "2017-09-12T00:22:20.202019: step 2350, loss -1900.31, acc 0.96875\n",
      "2017-09-12T00:22:20.353208: step 2351, loss -1118.28, acc 0.90625\n",
      "2017-09-12T00:22:20.501834: step 2352, loss -2197.95, acc 1\n",
      "2017-09-12T00:22:20.664680: step 2353, loss -183.325, acc 0.9375\n",
      "2017-09-12T00:22:20.810702: step 2354, loss -1910.8, acc 0.96875\n",
      "2017-09-12T00:22:20.953954: step 2355, loss -110.814, acc 0.875\n",
      "2017-09-12T00:22:21.102759: step 2356, loss -1163.01, acc 0.9375\n",
      "2017-09-12T00:22:21.253914: step 2357, loss -823.758, acc 1\n",
      "2017-09-12T00:22:21.420030: step 2358, loss -895.622, acc 0.90625\n",
      "2017-09-12T00:22:21.573440: step 2359, loss -480.762, acc 0.90625\n",
      "2017-09-12T00:22:21.704527: step 2360, loss -942.998, acc 0.90625\n",
      "2017-09-12T00:22:21.869620: step 2361, loss -1642.74, acc 0.90625\n",
      "2017-09-12T00:22:22.008406: step 2362, loss 208.918, acc 0.875\n",
      "2017-09-12T00:22:22.189954: step 2363, loss -658.052, acc 0.875\n",
      "2017-09-12T00:22:22.332243: step 2364, loss -1037.95, acc 0.90625\n",
      "2017-09-12T00:22:22.483322: step 2365, loss -1679.68, acc 0.9375\n",
      "2017-09-12T00:22:22.630865: step 2366, loss -801.456, acc 0.9375\n",
      "2017-09-12T00:22:22.678337: step 2367, loss 1162.76, acc 0.875\n",
      "2017-09-12T00:22:22.834215: step 2368, loss 814.036, acc 0.875\n",
      "2017-09-12T00:22:22.993455: step 2369, loss -1449.31, acc 0.9375\n",
      "2017-09-12T00:22:23.147274: step 2370, loss -296.304, acc 0.9375\n",
      "2017-09-12T00:22:23.292587: step 2371, loss -531.521, acc 0.90625\n",
      "2017-09-12T00:22:23.450628: step 2372, loss -637.255, acc 0.9375\n",
      "2017-09-12T00:22:23.611469: step 2373, loss -1765.73, acc 0.875\n",
      "2017-09-12T00:22:23.757247: step 2374, loss -2525.01, acc 1\n",
      "2017-09-12T00:22:23.914151: step 2375, loss -1657.8, acc 1\n",
      "2017-09-12T00:22:24.060150: step 2376, loss -848.7, acc 0.875\n",
      "2017-09-12T00:22:24.213122: step 2377, loss -1081.61, acc 0.9375\n",
      "2017-09-12T00:22:24.364316: step 2378, loss -218.414, acc 0.90625\n",
      "2017-09-12T00:22:24.514890: step 2379, loss -1692.83, acc 0.875\n",
      "2017-09-12T00:22:24.664752: step 2380, loss -77.3553, acc 0.84375\n",
      "2017-09-12T00:22:24.833762: step 2381, loss -1157.27, acc 0.9375\n",
      "2017-09-12T00:22:24.969995: step 2382, loss -1515.82, acc 1\n",
      "2017-09-12T00:22:25.112032: step 2383, loss -1530.6, acc 0.9375\n",
      "2017-09-12T00:22:25.259634: step 2384, loss -61.5375, acc 0.90625\n",
      "2017-09-12T00:22:25.417490: step 2385, loss -2702.6, acc 1\n",
      "2017-09-12T00:22:25.564154: step 2386, loss -1465.85, acc 0.9375\n",
      "2017-09-12T00:22:25.710047: step 2387, loss -1089.86, acc 0.9375\n",
      "2017-09-12T00:22:25.873384: step 2388, loss 542.288, acc 0.875\n",
      "2017-09-12T00:22:26.024567: step 2389, loss -393.912, acc 0.90625\n",
      "2017-09-12T00:22:26.167399: step 2390, loss -862.67, acc 0.96875\n",
      "2017-09-12T00:22:26.328638: step 2391, loss -1074.97, acc 0.90625\n",
      "2017-09-12T00:22:26.474366: step 2392, loss -1151.05, acc 0.96875\n",
      "2017-09-12T00:22:26.628520: step 2393, loss -24.4147, acc 0.875\n",
      "2017-09-12T00:22:26.779156: step 2394, loss -1247.14, acc 0.96875\n",
      "2017-09-12T00:22:26.932572: step 2395, loss -734.493, acc 0.9375\n",
      "2017-09-12T00:22:27.092409: step 2396, loss -1728.62, acc 1\n",
      "2017-09-12T00:22:27.252355: step 2397, loss -322.682, acc 0.9375\n",
      "2017-09-12T00:22:27.392767: step 2398, loss -267.391, acc 0.9375\n",
      "2017-09-12T00:22:27.537688: step 2399, loss 196.721, acc 0.9375\n",
      "2017-09-12T00:22:27.693781: step 2400, loss -1383.99, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:22:29.108432: step 2400, loss -1139.94, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2400\n",
      "\n",
      "2017-09-12T00:22:31.149387: step 2401, loss -1818.2, acc 0.96875\n",
      "2017-09-12T00:22:31.245927: step 2402, loss -298.697, acc 0.9375\n",
      "2017-09-12T00:22:31.344142: step 2403, loss -1569.91, acc 0.9375\n",
      "2017-09-12T00:22:31.459141: step 2404, loss -599.134, acc 0.875\n",
      "2017-09-12T00:22:31.557549: step 2405, loss -2381.28, acc 0.96875\n",
      "2017-09-12T00:22:31.652459: step 2406, loss 192.844, acc 0.84375\n",
      "2017-09-12T00:22:31.745217: step 2407, loss -774.142, acc 0.90625\n",
      "2017-09-12T00:22:31.839557: step 2408, loss -1489.92, acc 0.9375\n",
      "2017-09-12T00:22:31.931053: step 2409, loss -1136.03, acc 0.9375\n",
      "2017-09-12T00:22:32.039231: step 2410, loss -2717.55, acc 0.96875\n",
      "2017-09-12T00:22:32.144252: step 2411, loss -1822.76, acc 0.96875\n",
      "2017-09-12T00:22:32.240510: step 2412, loss -2226.18, acc 0.90625\n",
      "2017-09-12T00:22:32.346034: step 2413, loss 14.5401, acc 0.90625\n",
      "2017-09-12T00:22:32.436301: step 2414, loss -2597.78, acc 0.9375\n",
      "2017-09-12T00:22:32.541547: step 2415, loss -260.151, acc 0.9375\n",
      "2017-09-12T00:22:32.643562: step 2416, loss 1102.64, acc 0.78125\n",
      "2017-09-12T00:22:32.731528: step 2417, loss -2668.02, acc 0.9375\n",
      "2017-09-12T00:22:32.825322: step 2418, loss -1359.72, acc 0.96875\n",
      "2017-09-12T00:22:32.919742: step 2419, loss -21.4694, acc 0.78125\n",
      "2017-09-12T00:22:33.209023: step 2420, loss -1776.72, acc 0.96875\n",
      "2017-09-12T00:22:33.350909: step 2421, loss -262.425, acc 0.9375\n",
      "2017-09-12T00:22:33.497052: step 2422, loss 35.4623, acc 0.90625\n",
      "2017-09-12T00:22:33.643280: step 2423, loss -2374.64, acc 0.96875\n",
      "2017-09-12T00:22:33.794328: step 2424, loss -318.618, acc 0.90625\n",
      "2017-09-12T00:22:33.940602: step 2425, loss -291.517, acc 0.90625\n",
      "2017-09-12T00:22:34.092672: step 2426, loss -1198.68, acc 0.96875\n",
      "2017-09-12T00:22:34.239661: step 2427, loss -2020.33, acc 0.96875\n",
      "2017-09-12T00:22:34.385557: step 2428, loss -1813.3, acc 0.9375\n",
      "2017-09-12T00:22:34.535421: step 2429, loss -281.468, acc 0.90625\n",
      "2017-09-12T00:22:34.689973: step 2430, loss -585.718, acc 0.90625\n",
      "2017-09-12T00:22:34.846954: step 2431, loss -588.535, acc 0.84375\n",
      "2017-09-12T00:22:34.992752: step 2432, loss -2038.64, acc 0.96875\n",
      "2017-09-12T00:22:35.141578: step 2433, loss -946.918, acc 0.90625\n",
      "2017-09-12T00:22:35.282161: step 2434, loss -1884.36, acc 0.96875\n",
      "2017-09-12T00:22:35.436249: step 2435, loss -1159.69, acc 0.96875\n",
      "2017-09-12T00:22:35.584776: step 2436, loss -620.488, acc 0.875\n",
      "2017-09-12T00:22:35.721940: step 2437, loss -915.093, acc 0.9375\n",
      "2017-09-12T00:22:35.883412: step 2438, loss -1492.59, acc 1\n",
      "2017-09-12T00:22:36.025540: step 2439, loss -1429.7, acc 0.9375\n",
      "2017-09-12T00:22:36.171298: step 2440, loss -408.889, acc 0.90625\n",
      "2017-09-12T00:22:36.321631: step 2441, loss -2374.85, acc 1\n",
      "2017-09-12T00:22:36.464706: step 2442, loss -1147.82, acc 0.90625\n",
      "2017-09-12T00:22:36.606172: step 2443, loss -994.327, acc 0.9375\n",
      "2017-09-12T00:22:36.762984: step 2444, loss -1851.28, acc 0.875\n",
      "2017-09-12T00:22:36.899911: step 2445, loss -1068, acc 0.90625\n",
      "2017-09-12T00:22:37.033061: step 2446, loss -630.281, acc 0.96875\n",
      "2017-09-12T00:22:37.195168: step 2447, loss -948.19, acc 0.90625\n",
      "2017-09-12T00:22:37.338925: step 2448, loss 824.158, acc 0.78125\n",
      "2017-09-12T00:22:37.486378: step 2449, loss -620.097, acc 0.96875\n",
      "2017-09-12T00:22:37.641418: step 2450, loss -933.974, acc 0.90625\n",
      "2017-09-12T00:22:37.792109: step 2451, loss -561.401, acc 0.875\n",
      "2017-09-12T00:22:37.945675: step 2452, loss -2196.72, acc 0.96875\n",
      "2017-09-12T00:22:38.103961: step 2453, loss -1816.19, acc 0.9375\n",
      "2017-09-12T00:22:38.244319: step 2454, loss -1191.06, acc 0.90625\n",
      "2017-09-12T00:22:38.395162: step 2455, loss -1595.25, acc 1\n",
      "2017-09-12T00:22:38.533947: step 2456, loss -596.613, acc 0.9375\n",
      "2017-09-12T00:22:38.681809: step 2457, loss -1504.37, acc 0.96875\n",
      "2017-09-12T00:22:38.827502: step 2458, loss 1029.99, acc 0.8125\n",
      "2017-09-12T00:22:38.979335: step 2459, loss -632.418, acc 0.875\n",
      "2017-09-12T00:22:39.125943: step 2460, loss -894.633, acc 0.9375\n",
      "2017-09-12T00:22:39.281889: step 2461, loss -326.939, acc 0.90625\n",
      "2017-09-12T00:22:39.426991: step 2462, loss -386.272, acc 0.9375\n",
      "2017-09-12T00:22:39.584332: step 2463, loss -368.896, acc 0.875\n",
      "2017-09-12T00:22:39.732298: step 2464, loss -1067.34, acc 0.90625\n",
      "2017-09-12T00:22:39.885376: step 2465, loss -2028.67, acc 0.90625\n",
      "2017-09-12T00:22:40.031729: step 2466, loss 478.49, acc 0.875\n",
      "2017-09-12T00:22:40.177198: step 2467, loss -1311.8, acc 0.9375\n",
      "2017-09-12T00:22:40.333268: step 2468, loss -3174.76, acc 1\n",
      "2017-09-12T00:22:40.474203: step 2469, loss -833.196, acc 0.90625\n",
      "2017-09-12T00:22:40.634101: step 2470, loss -1708.71, acc 0.96875\n",
      "2017-09-12T00:22:40.772410: step 2471, loss -1234.03, acc 0.9375\n",
      "2017-09-12T00:22:40.928583: step 2472, loss -1113.5, acc 0.84375\n",
      "2017-09-12T00:22:41.063816: step 2473, loss -2558.72, acc 0.9375\n",
      "2017-09-12T00:22:41.205728: step 2474, loss -2238.81, acc 0.9375\n",
      "2017-09-12T00:22:41.365027: step 2475, loss -374.701, acc 0.875\n",
      "2017-09-12T00:22:41.506228: step 2476, loss -1193.27, acc 0.9375\n",
      "2017-09-12T00:22:41.657095: step 2477, loss -874.277, acc 0.9375\n",
      "2017-09-12T00:22:41.810368: step 2478, loss -650.588, acc 0.96875\n",
      "2017-09-12T00:22:41.956466: step 2479, loss -1852.17, acc 0.9375\n",
      "2017-09-12T00:22:42.107497: step 2480, loss -984.119, acc 0.875\n",
      "2017-09-12T00:22:42.246027: step 2481, loss 86.3575, acc 0.90625\n",
      "2017-09-12T00:22:42.403367: step 2482, loss -766.762, acc 0.84375\n",
      "2017-09-12T00:22:42.549038: step 2483, loss -3132.22, acc 1\n",
      "2017-09-12T00:22:42.692520: step 2484, loss 48.2747, acc 0.90625\n",
      "2017-09-12T00:22:42.840943: step 2485, loss -626.131, acc 0.90625\n",
      "2017-09-12T00:22:42.977360: step 2486, loss -338.403, acc 0.9375\n",
      "2017-09-12T00:22:43.126891: step 2487, loss -1571.98, acc 0.96875\n",
      "2017-09-12T00:22:43.275092: step 2488, loss 202.02, acc 0.84375\n",
      "2017-09-12T00:22:43.423307: step 2489, loss -2050.32, acc 0.9375\n",
      "2017-09-12T00:22:43.574422: step 2490, loss -418.303, acc 0.90625\n",
      "2017-09-12T00:22:43.728932: step 2491, loss -15.6192, acc 0.9375\n",
      "2017-09-12T00:22:43.873545: step 2492, loss -206.882, acc 0.875\n",
      "2017-09-12T00:22:44.014637: step 2493, loss -818.704, acc 0.875\n",
      "2017-09-12T00:22:44.161555: step 2494, loss -1156.79, acc 0.90625\n",
      "2017-09-12T00:22:44.306839: step 2495, loss 264.343, acc 0.84375\n",
      "2017-09-12T00:22:44.444725: step 2496, loss 503.501, acc 0.90625\n",
      "2017-09-12T00:22:44.598570: step 2497, loss -982.307, acc 0.9375\n",
      "2017-09-12T00:22:44.751701: step 2498, loss -2147.01, acc 0.96875\n",
      "2017-09-12T00:22:44.886675: step 2499, loss -994.493, acc 0.90625\n",
      "2017-09-12T00:22:45.043803: step 2500, loss -654.151, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:22:46.335241: step 2500, loss -1264.81, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2500\n",
      "\n",
      "2017-09-12T00:22:48.001526: step 2501, loss -2955.15, acc 0.9375\n",
      "2017-09-12T00:22:48.085829: step 2502, loss -2007.49, acc 0.90625\n",
      "2017-09-12T00:22:48.215228: step 2503, loss -692.653, acc 0.96875\n",
      "2017-09-12T00:22:48.328840: step 2504, loss -1522.68, acc 0.96875\n",
      "2017-09-12T00:22:48.432684: step 2505, loss -591.942, acc 0.875\n",
      "2017-09-12T00:22:48.524223: step 2506, loss -2547.4, acc 0.90625\n",
      "2017-09-12T00:22:48.627426: step 2507, loss -360.811, acc 0.96875\n",
      "2017-09-12T00:22:48.729789: step 2508, loss -1040.01, acc 0.90625\n",
      "2017-09-12T00:22:48.823226: step 2509, loss -77.1123, acc 0.90625\n",
      "2017-09-12T00:22:48.916694: step 2510, loss -442.837, acc 0.9375\n",
      "2017-09-12T00:22:49.006029: step 2511, loss -913.701, acc 0.9375\n",
      "2017-09-12T00:22:49.097871: step 2512, loss -303.881, acc 0.90625\n",
      "2017-09-12T00:22:49.193489: step 2513, loss 397.228, acc 0.875\n",
      "2017-09-12T00:22:49.296800: step 2514, loss 936.796, acc 0.8125\n",
      "2017-09-12T00:22:49.386772: step 2515, loss -1190.51, acc 1\n",
      "2017-09-12T00:22:49.490974: step 2516, loss -1334.94, acc 0.96875\n",
      "2017-09-12T00:22:49.600999: step 2517, loss -1004.33, acc 0.9375\n",
      "2017-09-12T00:22:49.689571: step 2518, loss -873.525, acc 0.9375\n",
      "2017-09-12T00:22:49.801185: step 2519, loss -275.013, acc 0.90625\n",
      "2017-09-12T00:22:50.026893: step 2520, loss -2497.98, acc 1\n",
      "2017-09-12T00:22:50.194796: step 2521, loss -2413.18, acc 0.9375\n",
      "2017-09-12T00:22:50.328898: step 2522, loss -3512.24, acc 1\n",
      "2017-09-12T00:22:50.472291: step 2523, loss 328.673, acc 0.8125\n",
      "2017-09-12T00:22:50.636226: step 2524, loss -1123.15, acc 0.90625\n",
      "2017-09-12T00:22:50.786324: step 2525, loss -1035.98, acc 0.90625\n",
      "2017-09-12T00:22:50.922923: step 2526, loss -2649.54, acc 1\n",
      "2017-09-12T00:22:51.073502: step 2527, loss 220.584, acc 0.84375\n",
      "2017-09-12T00:22:51.219649: step 2528, loss -1021.29, acc 0.875\n",
      "2017-09-12T00:22:51.380772: step 2529, loss -598.952, acc 0.9375\n",
      "2017-09-12T00:22:51.519314: step 2530, loss -912.612, acc 0.875\n",
      "2017-09-12T00:22:51.668114: step 2531, loss -42.6879, acc 0.9375\n",
      "2017-09-12T00:22:51.822322: step 2532, loss -555.808, acc 0.9375\n",
      "2017-09-12T00:22:51.974836: step 2533, loss -1234.04, acc 0.9375\n",
      "2017-09-12T00:22:52.130116: step 2534, loss -1340.32, acc 0.9375\n",
      "2017-09-12T00:22:52.284121: step 2535, loss -2401.7, acc 0.9375\n",
      "2017-09-12T00:22:52.421115: step 2536, loss -1263.37, acc 0.96875\n",
      "2017-09-12T00:22:52.565664: step 2537, loss -360.073, acc 0.96875\n",
      "2017-09-12T00:22:52.729374: step 2538, loss -1320, acc 0.96875\n",
      "2017-09-12T00:22:52.869069: step 2539, loss -1741.61, acc 0.9375\n",
      "2017-09-12T00:22:53.009163: step 2540, loss -343.431, acc 1\n",
      "2017-09-12T00:22:53.158590: step 2541, loss -909.217, acc 0.9375\n",
      "2017-09-12T00:22:53.305746: step 2542, loss -3341.78, acc 0.96875\n",
      "2017-09-12T00:22:53.461356: step 2543, loss -393.447, acc 0.90625\n",
      "2017-09-12T00:22:53.614141: step 2544, loss -573.168, acc 0.90625\n",
      "2017-09-12T00:22:53.750508: step 2545, loss 304.917, acc 0.90625\n",
      "2017-09-12T00:22:53.902798: step 2546, loss -973.091, acc 0.90625\n",
      "2017-09-12T00:22:54.041192: step 2547, loss -2655.66, acc 0.9375\n",
      "2017-09-12T00:22:54.184525: step 2548, loss -605.149, acc 0.9375\n",
      "2017-09-12T00:22:54.352592: step 2549, loss -1604.99, acc 0.90625\n",
      "2017-09-12T00:22:54.493262: step 2550, loss -2351.17, acc 0.96875\n",
      "2017-09-12T00:22:54.646922: step 2551, loss -1658.03, acc 0.96875\n",
      "2017-09-12T00:22:54.801028: step 2552, loss -1349.19, acc 0.9375\n",
      "2017-09-12T00:22:54.943457: step 2553, loss -1482.68, acc 0.90625\n",
      "2017-09-12T00:22:55.102352: step 2554, loss -404.518, acc 0.96875\n",
      "2017-09-12T00:22:55.245408: step 2555, loss -3576.85, acc 1\n",
      "2017-09-12T00:22:55.385572: step 2556, loss -2371.11, acc 0.96875\n",
      "2017-09-12T00:22:55.526796: step 2557, loss -1743.52, acc 0.96875\n",
      "2017-09-12T00:22:55.685388: step 2558, loss -1268.84, acc 0.9375\n",
      "2017-09-12T00:22:55.822956: step 2559, loss -813.471, acc 0.875\n",
      "2017-09-12T00:22:55.975947: step 2560, loss -1090.13, acc 0.9375\n",
      "2017-09-12T00:22:56.122579: step 2561, loss -744.864, acc 0.9375\n",
      "2017-09-12T00:22:56.274480: step 2562, loss -2237.7, acc 0.96875\n",
      "2017-09-12T00:22:56.422474: step 2563, loss -115.24, acc 0.875\n",
      "2017-09-12T00:22:56.565518: step 2564, loss 1948.6, acc 0.75\n",
      "2017-09-12T00:22:56.722923: step 2565, loss -2127.24, acc 0.96875\n",
      "2017-09-12T00:22:56.868698: step 2566, loss -934.166, acc 1\n",
      "2017-09-12T00:22:57.009678: step 2567, loss -1392.98, acc 0.96875\n",
      "2017-09-12T00:22:57.155761: step 2568, loss -976.337, acc 0.96875\n",
      "2017-09-12T00:22:57.310210: step 2569, loss -2233.2, acc 0.9375\n",
      "2017-09-12T00:22:57.450584: step 2570, loss -575.013, acc 0.84375\n",
      "2017-09-12T00:22:57.589943: step 2571, loss -1999.78, acc 0.96875\n",
      "2017-09-12T00:22:57.744716: step 2572, loss -1990.22, acc 0.96875\n",
      "2017-09-12T00:22:57.895075: step 2573, loss -1668.5, acc 0.9375\n",
      "2017-09-12T00:22:58.039583: step 2574, loss -2454.11, acc 0.96875\n",
      "2017-09-12T00:22:58.189977: step 2575, loss -1260.37, acc 0.96875\n",
      "2017-09-12T00:22:58.335317: step 2576, loss -441.815, acc 0.9375\n",
      "2017-09-12T00:22:58.493089: step 2577, loss -990.706, acc 0.90625\n",
      "2017-09-12T00:22:58.629723: step 2578, loss -472.341, acc 0.875\n",
      "2017-09-12T00:22:58.785620: step 2579, loss -1990.35, acc 0.96875\n",
      "2017-09-12T00:22:58.925960: step 2580, loss -1391.43, acc 0.9375\n",
      "2017-09-12T00:22:59.091220: step 2581, loss -768.143, acc 0.9375\n",
      "2017-09-12T00:22:59.240500: step 2582, loss -2155.42, acc 0.90625\n",
      "2017-09-12T00:22:59.386131: step 2583, loss -1047.9, acc 0.9375\n",
      "2017-09-12T00:22:59.538244: step 2584, loss -784.765, acc 0.9375\n",
      "2017-09-12T00:22:59.680725: step 2585, loss -874.417, acc 0.84375\n",
      "2017-09-12T00:22:59.845861: step 2586, loss -2043.21, acc 0.96875\n",
      "2017-09-12T00:22:59.997747: step 2587, loss 35.6547, acc 0.90625\n",
      "2017-09-12T00:23:00.145740: step 2588, loss -1346.94, acc 0.9375\n",
      "2017-09-12T00:23:00.294391: step 2589, loss -2074.49, acc 0.9375\n",
      "2017-09-12T00:23:00.437602: step 2590, loss -2126.56, acc 1\n",
      "2017-09-12T00:23:00.581888: step 2591, loss -2824.15, acc 0.9375\n",
      "2017-09-12T00:23:00.727008: step 2592, loss -1767.64, acc 0.9375\n",
      "2017-09-12T00:23:00.880041: step 2593, loss 1.46951, acc 0.875\n",
      "2017-09-12T00:23:01.026475: step 2594, loss -1076.15, acc 1\n",
      "2017-09-12T00:23:01.175845: step 2595, loss -718.13, acc 0.875\n",
      "2017-09-12T00:23:01.321393: step 2596, loss -2412.31, acc 0.96875\n",
      "2017-09-12T00:23:01.468037: step 2597, loss -1183.37, acc 0.90625\n",
      "2017-09-12T00:23:01.613962: step 2598, loss -2499.25, acc 1\n",
      "2017-09-12T00:23:01.757493: step 2599, loss -2145.71, acc 1\n",
      "2017-09-12T00:23:01.910243: step 2600, loss -4.94788, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:23:03.205424: step 2600, loss -1401.39, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2600\n",
      "\n",
      "2017-09-12T00:23:05.072702: step 2601, loss 597.915, acc 0.8125\n",
      "2017-09-12T00:23:05.166858: step 2602, loss -1885.73, acc 0.96875\n",
      "2017-09-12T00:23:05.270327: step 2603, loss -104.198, acc 0.875\n",
      "2017-09-12T00:23:05.369037: step 2604, loss -407.597, acc 0.875\n",
      "2017-09-12T00:23:05.470776: step 2605, loss -1041.74, acc 0.90625\n",
      "2017-09-12T00:23:05.567690: step 2606, loss -2256.57, acc 0.875\n",
      "2017-09-12T00:23:05.665889: step 2607, loss 1082.81, acc 0.84375\n",
      "2017-09-12T00:23:05.756393: step 2608, loss -1366.18, acc 0.96875\n",
      "2017-09-12T00:23:05.848792: step 2609, loss -45.7371, acc 0.8125\n",
      "2017-09-12T00:23:05.936463: step 2610, loss -1145.66, acc 0.96875\n",
      "2017-09-12T00:23:06.025418: step 2611, loss -1419.18, acc 0.96875\n",
      "2017-09-12T00:23:06.120482: step 2612, loss -1511.32, acc 0.90625\n",
      "2017-09-12T00:23:06.212878: step 2613, loss -746.001, acc 0.875\n",
      "2017-09-12T00:23:06.306098: step 2614, loss 344.869, acc 0.90625\n",
      "2017-09-12T00:23:06.395771: step 2615, loss -2241.44, acc 0.9375\n",
      "2017-09-12T00:23:06.509801: step 2616, loss -1764.96, acc 0.96875\n",
      "2017-09-12T00:23:06.605229: step 2617, loss -3561.41, acc 1\n",
      "2017-09-12T00:23:06.695671: step 2618, loss -1853.65, acc 0.9375\n",
      "2017-09-12T00:23:06.787863: step 2619, loss 261.277, acc 0.875\n",
      "2017-09-12T00:23:07.065922: step 2620, loss -1007.11, acc 0.9375\n",
      "2017-09-12T00:23:07.214995: step 2621, loss -475.892, acc 0.84375\n",
      "2017-09-12T00:23:07.363697: step 2622, loss -1386.61, acc 0.875\n",
      "2017-09-12T00:23:07.501208: step 2623, loss -1723.77, acc 0.9375\n",
      "2017-09-12T00:23:07.652363: step 2624, loss -1410.39, acc 0.90625\n",
      "2017-09-12T00:23:07.806500: step 2625, loss -2558.08, acc 0.9375\n",
      "2017-09-12T00:23:07.943019: step 2626, loss 1368.76, acc 0.84375\n",
      "2017-09-12T00:23:08.100293: step 2627, loss -3029.52, acc 0.96875\n",
      "2017-09-12T00:23:08.228221: step 2628, loss -839.346, acc 0.96875\n",
      "2017-09-12T00:23:08.402231: step 2629, loss -3252.14, acc 0.9375\n",
      "2017-09-12T00:23:08.449489: step 2630, loss -1549.69, acc 0.875\n",
      "2017-09-12T00:23:08.594675: step 2631, loss -1779.99, acc 0.96875\n",
      "2017-09-12T00:23:08.753614: step 2632, loss -366.42, acc 0.90625\n",
      "2017-09-12T00:23:08.893245: step 2633, loss -1870.53, acc 0.9375\n",
      "2017-09-12T00:23:09.029241: step 2634, loss -1796.05, acc 0.96875\n",
      "2017-09-12T00:23:09.191395: step 2635, loss -1484.2, acc 0.9375\n",
      "2017-09-12T00:23:09.324365: step 2636, loss -1083.99, acc 0.9375\n",
      "2017-09-12T00:23:09.486043: step 2637, loss -793.157, acc 0.875\n",
      "2017-09-12T00:23:09.650222: step 2638, loss -20.2014, acc 0.90625\n",
      "2017-09-12T00:23:09.787490: step 2639, loss -2511.66, acc 1\n",
      "2017-09-12T00:23:09.956375: step 2640, loss -632.702, acc 0.90625\n",
      "2017-09-12T00:23:10.108924: step 2641, loss -50.1623, acc 0.90625\n",
      "2017-09-12T00:23:10.254378: step 2642, loss 369.499, acc 0.9375\n",
      "2017-09-12T00:23:10.398937: step 2643, loss -776.867, acc 0.90625\n",
      "2017-09-12T00:23:10.548108: step 2644, loss -360.63, acc 0.90625\n",
      "2017-09-12T00:23:10.706069: step 2645, loss -1507.5, acc 0.9375\n",
      "2017-09-12T00:23:10.860064: step 2646, loss -1216.52, acc 0.90625\n",
      "2017-09-12T00:23:10.998775: step 2647, loss -1383.38, acc 0.96875\n",
      "2017-09-12T00:23:11.146918: step 2648, loss -1154.07, acc 0.90625\n",
      "2017-09-12T00:23:11.297083: step 2649, loss -808.787, acc 0.875\n",
      "2017-09-12T00:23:11.436943: step 2650, loss -1943.48, acc 0.9375\n",
      "2017-09-12T00:23:11.580959: step 2651, loss -381.857, acc 0.9375\n",
      "2017-09-12T00:23:11.730673: step 2652, loss -1507.61, acc 0.9375\n",
      "2017-09-12T00:23:11.876157: step 2653, loss 52.3812, acc 0.90625\n",
      "2017-09-12T00:23:12.033210: step 2654, loss -1833.11, acc 0.9375\n",
      "2017-09-12T00:23:12.178079: step 2655, loss 734.255, acc 0.875\n",
      "2017-09-12T00:23:12.319961: step 2656, loss -3380.71, acc 1\n",
      "2017-09-12T00:23:12.471363: step 2657, loss -751.82, acc 0.9375\n",
      "2017-09-12T00:23:12.607186: step 2658, loss -1496.81, acc 0.9375\n",
      "2017-09-12T00:23:12.757849: step 2659, loss -4127.73, acc 1\n",
      "2017-09-12T00:23:12.902429: step 2660, loss -2164.64, acc 0.96875\n",
      "2017-09-12T00:23:13.045600: step 2661, loss -1161.89, acc 0.96875\n",
      "2017-09-12T00:23:13.198446: step 2662, loss -241.086, acc 0.875\n",
      "2017-09-12T00:23:13.344876: step 2663, loss 408.876, acc 0.84375\n",
      "2017-09-12T00:23:13.489228: step 2664, loss -1398.58, acc 0.875\n",
      "2017-09-12T00:23:13.639049: step 2665, loss -1792.19, acc 0.9375\n",
      "2017-09-12T00:23:13.786632: step 2666, loss -2670.86, acc 0.96875\n",
      "2017-09-12T00:23:13.926451: step 2667, loss 286.312, acc 0.90625\n",
      "2017-09-12T00:23:14.065023: step 2668, loss -65.4604, acc 0.875\n",
      "2017-09-12T00:23:14.218739: step 2669, loss 18.7849, acc 0.96875\n",
      "2017-09-12T00:23:14.364142: step 2670, loss -15.9354, acc 0.84375\n",
      "2017-09-12T00:23:14.504900: step 2671, loss -1564.6, acc 0.96875\n",
      "2017-09-12T00:23:14.660283: step 2672, loss -956.039, acc 0.875\n",
      "2017-09-12T00:23:14.798350: step 2673, loss -453.29, acc 0.9375\n",
      "2017-09-12T00:23:14.942015: step 2674, loss 799.225, acc 0.84375\n",
      "2017-09-12T00:23:15.096199: step 2675, loss -1097.87, acc 0.90625\n",
      "2017-09-12T00:23:15.226856: step 2676, loss -1880.23, acc 0.96875\n",
      "2017-09-12T00:23:15.379071: step 2677, loss -95.4315, acc 0.90625\n",
      "2017-09-12T00:23:15.521666: step 2678, loss -1891.11, acc 0.9375\n",
      "2017-09-12T00:23:15.667568: step 2679, loss -1143.3, acc 0.96875\n",
      "2017-09-12T00:23:15.812366: step 2680, loss -1419.78, acc 0.90625\n",
      "2017-09-12T00:23:15.946114: step 2681, loss -801.589, acc 0.9375\n",
      "2017-09-12T00:23:16.112146: step 2682, loss -2512.63, acc 0.96875\n",
      "2017-09-12T00:23:16.248212: step 2683, loss -1737.79, acc 0.90625\n",
      "2017-09-12T00:23:16.395091: step 2684, loss -1185.67, acc 0.96875\n",
      "2017-09-12T00:23:16.530468: step 2685, loss -807.616, acc 0.90625\n",
      "2017-09-12T00:23:16.693377: step 2686, loss -345.807, acc 0.90625\n",
      "2017-09-12T00:23:16.831445: step 2687, loss -1948.38, acc 0.96875\n",
      "2017-09-12T00:23:16.972456: step 2688, loss -485.535, acc 0.9375\n",
      "2017-09-12T00:23:17.123673: step 2689, loss -1074.04, acc 0.875\n",
      "2017-09-12T00:23:17.278743: step 2690, loss -394.386, acc 0.96875\n",
      "2017-09-12T00:23:17.432397: step 2691, loss -1009.8, acc 0.90625\n",
      "2017-09-12T00:23:17.555849: step 2692, loss -1572.51, acc 0.96875\n",
      "2017-09-12T00:23:17.723362: step 2693, loss -1898.96, acc 0.9375\n",
      "2017-09-12T00:23:17.875074: step 2694, loss -521.827, acc 0.84375\n",
      "2017-09-12T00:23:18.023605: step 2695, loss -1710.91, acc 0.90625\n",
      "2017-09-12T00:23:18.155813: step 2696, loss -142.996, acc 0.90625\n",
      "2017-09-12T00:23:18.301409: step 2697, loss -1603.7, acc 0.90625\n",
      "2017-09-12T00:23:18.450175: step 2698, loss -823.384, acc 0.9375\n",
      "2017-09-12T00:23:18.603866: step 2699, loss 71.3541, acc 0.84375\n",
      "2017-09-12T00:23:18.756658: step 2700, loss 1477.06, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:23:20.070726: step 2700, loss -1526.13, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2700\n",
      "\n",
      "2017-09-12T00:23:22.052518: step 2701, loss -956.761, acc 0.90625\n",
      "2017-09-12T00:23:22.146007: step 2702, loss -2835.87, acc 0.9375\n",
      "2017-09-12T00:23:22.247240: step 2703, loss -883.647, acc 0.90625\n",
      "2017-09-12T00:23:22.342113: step 2704, loss -767.209, acc 0.90625\n",
      "2017-09-12T00:23:22.435940: step 2705, loss -2348.35, acc 0.875\n",
      "2017-09-12T00:23:22.532062: step 2706, loss -1575.98, acc 1\n",
      "2017-09-12T00:23:22.628106: step 2707, loss 455.681, acc 0.84375\n",
      "2017-09-12T00:23:22.726547: step 2708, loss -241.19, acc 0.875\n",
      "2017-09-12T00:23:22.821026: step 2709, loss -336.214, acc 0.875\n",
      "2017-09-12T00:23:22.911624: step 2710, loss -1739.41, acc 0.875\n",
      "2017-09-12T00:23:23.004931: step 2711, loss -1089.75, acc 0.875\n",
      "2017-09-12T00:23:23.094906: step 2712, loss -1532.7, acc 0.96875\n",
      "2017-09-12T00:23:23.201418: step 2713, loss -2494.62, acc 0.90625\n",
      "2017-09-12T00:23:23.301564: step 2714, loss -1627.09, acc 0.90625\n",
      "2017-09-12T00:23:23.385081: step 2715, loss -1861.5, acc 0.875\n",
      "2017-09-12T00:23:23.473713: step 2716, loss -1197.88, acc 0.9375\n",
      "2017-09-12T00:23:23.565569: step 2717, loss -2257, acc 0.96875\n",
      "2017-09-12T00:23:23.667582: step 2718, loss -1111.83, acc 0.9375\n",
      "2017-09-12T00:23:23.936972: step 2719, loss -1558.8, acc 0.90625\n",
      "2017-09-12T00:23:24.069595: step 2720, loss -1416.21, acc 0.875\n",
      "2017-09-12T00:23:24.219284: step 2721, loss -3151.4, acc 0.90625\n",
      "2017-09-12T00:23:24.374437: step 2722, loss -106.68, acc 0.875\n",
      "2017-09-12T00:23:24.517701: step 2723, loss -932.076, acc 0.90625\n",
      "2017-09-12T00:23:24.666422: step 2724, loss -1946.19, acc 0.96875\n",
      "2017-09-12T00:23:24.785844: step 2725, loss -1574.71, acc 0.96875\n",
      "2017-09-12T00:23:24.942428: step 2726, loss -1996.81, acc 0.9375\n",
      "2017-09-12T00:23:25.096733: step 2727, loss -445.804, acc 0.96875\n",
      "2017-09-12T00:23:25.242866: step 2728, loss -1863.3, acc 0.9375\n",
      "2017-09-12T00:23:25.392247: step 2729, loss -828.701, acc 0.90625\n",
      "2017-09-12T00:23:25.534983: step 2730, loss -1191.85, acc 0.96875\n",
      "2017-09-12T00:23:25.688554: step 2731, loss -361.287, acc 0.90625\n",
      "2017-09-12T00:23:25.817981: step 2732, loss -2356.61, acc 0.875\n",
      "2017-09-12T00:23:25.966773: step 2733, loss -1166.65, acc 1\n",
      "2017-09-12T00:23:26.116409: step 2734, loss 335.342, acc 0.9375\n",
      "2017-09-12T00:23:26.272699: step 2735, loss -2034.4, acc 0.96875\n",
      "2017-09-12T00:23:26.420410: step 2736, loss -85.5412, acc 0.875\n",
      "2017-09-12T00:23:26.561815: step 2737, loss -1173.85, acc 0.9375\n",
      "2017-09-12T00:23:26.702799: step 2738, loss -3539.77, acc 0.96875\n",
      "2017-09-12T00:23:26.855757: step 2739, loss -2146.3, acc 0.9375\n",
      "2017-09-12T00:23:27.011540: step 2740, loss -676.685, acc 0.9375\n",
      "2017-09-12T00:23:27.155987: step 2741, loss -3811.89, acc 0.96875\n",
      "2017-09-12T00:23:27.296390: step 2742, loss -748.485, acc 0.90625\n",
      "2017-09-12T00:23:27.431721: step 2743, loss -2812.07, acc 1\n",
      "2017-09-12T00:23:27.576922: step 2744, loss -1503.82, acc 0.84375\n",
      "2017-09-12T00:23:27.729917: step 2745, loss -3678.8, acc 1\n",
      "2017-09-12T00:23:27.865041: step 2746, loss -374.634, acc 0.90625\n",
      "2017-09-12T00:23:28.018610: step 2747, loss -3418.92, acc 1\n",
      "2017-09-12T00:23:28.159150: step 2748, loss -623.994, acc 0.875\n",
      "2017-09-12T00:23:28.305333: step 2749, loss -2420.66, acc 0.96875\n",
      "2017-09-12T00:23:28.448762: step 2750, loss -2046.87, acc 1\n",
      "2017-09-12T00:23:28.609674: step 2751, loss -1664.79, acc 1\n",
      "2017-09-12T00:23:28.757451: step 2752, loss 39.0897, acc 0.875\n",
      "2017-09-12T00:23:28.903892: step 2753, loss -1183.26, acc 0.90625\n",
      "2017-09-12T00:23:29.046890: step 2754, loss -1263.59, acc 0.96875\n",
      "2017-09-12T00:23:29.190468: step 2755, loss -869.657, acc 0.84375\n",
      "2017-09-12T00:23:29.353092: step 2756, loss -438.391, acc 0.9375\n",
      "2017-09-12T00:23:29.494416: step 2757, loss -740.199, acc 0.9375\n",
      "2017-09-12T00:23:29.645976: step 2758, loss -2037.53, acc 0.9375\n",
      "2017-09-12T00:23:29.803023: step 2759, loss -1552.42, acc 0.96875\n",
      "2017-09-12T00:23:29.929325: step 2760, loss -441.809, acc 0.90625\n",
      "2017-09-12T00:23:30.096700: step 2761, loss -1354.16, acc 0.90625\n",
      "2017-09-12T00:23:30.229835: step 2762, loss -2579.96, acc 0.90625\n",
      "2017-09-12T00:23:30.373135: step 2763, loss -2870.3, acc 0.96875\n",
      "2017-09-12T00:23:30.523567: step 2764, loss -1297.58, acc 0.90625\n",
      "2017-09-12T00:23:30.667761: step 2765, loss -1748.25, acc 0.875\n",
      "2017-09-12T00:23:30.823772: step 2766, loss -1595.12, acc 0.90625\n",
      "2017-09-12T00:23:30.982081: step 2767, loss -4178.57, acc 0.90625\n",
      "2017-09-12T00:23:31.125973: step 2768, loss -1824.61, acc 0.90625\n",
      "2017-09-12T00:23:31.288126: step 2769, loss -407.534, acc 0.96875\n",
      "2017-09-12T00:23:31.426227: step 2770, loss -3275.85, acc 0.96875\n",
      "2017-09-12T00:23:31.591215: step 2771, loss -987.375, acc 0.9375\n",
      "2017-09-12T00:23:31.723389: step 2772, loss -3052.32, acc 0.96875\n",
      "2017-09-12T00:23:31.884907: step 2773, loss -886.902, acc 0.875\n",
      "2017-09-12T00:23:32.026478: step 2774, loss -454.535, acc 0.90625\n",
      "2017-09-12T00:23:32.174528: step 2775, loss -4282.33, acc 1\n",
      "2017-09-12T00:23:32.320025: step 2776, loss -383.402, acc 0.84375\n",
      "2017-09-12T00:23:32.475369: step 2777, loss 6.29538, acc 0.875\n",
      "2017-09-12T00:23:32.617024: step 2778, loss -1228.16, acc 0.9375\n",
      "2017-09-12T00:23:32.769362: step 2779, loss -111.497, acc 0.875\n",
      "2017-09-12T00:23:32.913453: step 2780, loss -2776.37, acc 0.9375\n",
      "2017-09-12T00:23:33.065984: step 2781, loss -2929.2, acc 0.9375\n",
      "2017-09-12T00:23:33.215229: step 2782, loss -2608.5, acc 0.96875\n",
      "2017-09-12T00:23:33.350904: step 2783, loss -3030.96, acc 0.90625\n",
      "2017-09-12T00:23:33.511080: step 2784, loss -1739.59, acc 0.96875\n",
      "2017-09-12T00:23:33.646675: step 2785, loss -2562.1, acc 0.875\n",
      "2017-09-12T00:23:33.784959: step 2786, loss -1677.21, acc 0.96875\n",
      "2017-09-12T00:23:33.939794: step 2787, loss -3074.1, acc 0.96875\n",
      "2017-09-12T00:23:34.095765: step 2788, loss 13.6503, acc 0.90625\n",
      "2017-09-12T00:23:34.242819: step 2789, loss 390.015, acc 0.875\n",
      "2017-09-12T00:23:34.392113: step 2790, loss -2951.46, acc 0.96875\n",
      "2017-09-12T00:23:34.547261: step 2791, loss 795.402, acc 0.875\n",
      "2017-09-12T00:23:34.694730: step 2792, loss 426.871, acc 0.90625\n",
      "2017-09-12T00:23:34.846567: step 2793, loss -2547.22, acc 0.9375\n",
      "2017-09-12T00:23:34.989104: step 2794, loss -2640.93, acc 0.9375\n",
      "2017-09-12T00:23:35.144640: step 2795, loss -4550.03, acc 0.90625\n",
      "2017-09-12T00:23:35.294445: step 2796, loss -3001.44, acc 0.9375\n",
      "2017-09-12T00:23:35.445319: step 2797, loss -3463.27, acc 0.96875\n",
      "2017-09-12T00:23:35.586936: step 2798, loss -107.271, acc 0.875\n",
      "2017-09-12T00:23:35.773681: step 2799, loss -903.539, acc 0.90625\n",
      "2017-09-12T00:23:35.964481: step 2800, loss -3086.95, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:23:37.388856: step 2800, loss -1686.03, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2800\n",
      "\n",
      "2017-09-12T00:23:39.416238: step 2801, loss -2977.75, acc 1\n",
      "2017-09-12T00:23:39.503027: step 2802, loss 358.99, acc 0.84375\n",
      "2017-09-12T00:23:39.602950: step 2803, loss -2254.35, acc 0.9375\n",
      "2017-09-12T00:23:39.702641: step 2804, loss 386.444, acc 0.90625\n",
      "2017-09-12T00:23:39.799304: step 2805, loss -251.662, acc 0.875\n",
      "2017-09-12T00:23:39.890845: step 2806, loss -951.748, acc 0.90625\n",
      "2017-09-12T00:23:40.018388: step 2807, loss -818.42, acc 0.90625\n",
      "2017-09-12T00:23:40.143954: step 2808, loss -208.591, acc 0.875\n",
      "2017-09-12T00:23:40.274834: step 2809, loss -960.173, acc 0.9375\n",
      "2017-09-12T00:23:40.398413: step 2810, loss -3052.2, acc 0.9375\n",
      "2017-09-12T00:23:40.509041: step 2811, loss -2934.85, acc 0.96875\n",
      "2017-09-12T00:23:40.606956: step 2812, loss -31.9131, acc 0.90625\n",
      "2017-09-12T00:23:40.697821: step 2813, loss -2602.8, acc 0.90625\n",
      "2017-09-12T00:23:40.795845: step 2814, loss -2235.59, acc 0.90625\n",
      "2017-09-12T00:23:40.910731: step 2815, loss -542.539, acc 0.90625\n",
      "2017-09-12T00:23:41.008588: step 2816, loss -3012.21, acc 1\n",
      "2017-09-12T00:23:41.111169: step 2817, loss -2905.59, acc 0.96875\n",
      "2017-09-12T00:23:41.203142: step 2818, loss -2494.2, acc 1\n",
      "2017-09-12T00:23:41.298234: step 2819, loss -3486.65, acc 1\n",
      "2017-09-12T00:23:41.391648: step 2820, loss -824.394, acc 0.875\n",
      "2017-09-12T00:23:41.652567: step 2821, loss -490.986, acc 0.84375\n",
      "2017-09-12T00:23:41.801447: step 2822, loss -3338.11, acc 1\n",
      "2017-09-12T00:23:41.944418: step 2823, loss -3659.85, acc 0.96875\n",
      "2017-09-12T00:23:42.088327: step 2824, loss -1795.54, acc 0.9375\n",
      "2017-09-12T00:23:42.251378: step 2825, loss 376.283, acc 0.84375\n",
      "2017-09-12T00:23:42.386154: step 2826, loss 497.381, acc 0.9375\n",
      "2017-09-12T00:23:42.548656: step 2827, loss -962.197, acc 0.96875\n",
      "2017-09-12T00:23:42.755026: step 2828, loss -392.407, acc 0.90625\n",
      "2017-09-12T00:23:42.887650: step 2829, loss -1700.76, acc 1\n",
      "2017-09-12T00:23:43.034509: step 2830, loss -1826.43, acc 0.9375\n",
      "2017-09-12T00:23:43.192966: step 2831, loss -1402.82, acc 0.9375\n",
      "2017-09-12T00:23:43.335548: step 2832, loss -2645.46, acc 0.9375\n",
      "2017-09-12T00:23:43.488763: step 2833, loss -827.956, acc 0.90625\n",
      "2017-09-12T00:23:43.624803: step 2834, loss -1388.44, acc 0.9375\n",
      "2017-09-12T00:23:43.791377: step 2835, loss -3317.19, acc 0.90625\n",
      "2017-09-12T00:23:43.933292: step 2836, loss -503.632, acc 0.875\n",
      "2017-09-12T00:23:44.082639: step 2837, loss -1451.44, acc 0.90625\n",
      "2017-09-12T00:23:44.233805: step 2838, loss -911.478, acc 0.90625\n",
      "2017-09-12T00:23:44.397148: step 2839, loss -1362.03, acc 0.90625\n",
      "2017-09-12T00:23:44.536265: step 2840, loss -1797.84, acc 0.90625\n",
      "2017-09-12T00:23:44.682328: step 2841, loss -2265.82, acc 0.96875\n",
      "2017-09-12T00:23:44.835061: step 2842, loss -2619.48, acc 0.9375\n",
      "2017-09-12T00:23:45.008395: step 2843, loss -829.08, acc 0.96875\n",
      "2017-09-12T00:23:45.142343: step 2844, loss -2717.33, acc 0.96875\n",
      "2017-09-12T00:23:45.279427: step 2845, loss -1658.67, acc 0.90625\n",
      "2017-09-12T00:23:45.434577: step 2846, loss -1779.11, acc 0.90625\n",
      "2017-09-12T00:23:45.578374: step 2847, loss -4328.22, acc 1\n",
      "2017-09-12T00:23:45.746618: step 2848, loss -1326.68, acc 0.9375\n",
      "2017-09-12T00:23:45.891569: step 2849, loss 84.4932, acc 0.875\n",
      "2017-09-12T00:23:46.034119: step 2850, loss -3473.5, acc 0.96875\n",
      "2017-09-12T00:23:46.182167: step 2851, loss -2329.28, acc 0.9375\n",
      "2017-09-12T00:23:46.327982: step 2852, loss 381.211, acc 0.84375\n",
      "2017-09-12T00:23:46.461096: step 2853, loss -2080.61, acc 0.90625\n",
      "2017-09-12T00:23:46.604787: step 2854, loss -774.384, acc 0.90625\n",
      "2017-09-12T00:23:46.764965: step 2855, loss -510.411, acc 0.96875\n",
      "2017-09-12T00:23:46.917762: step 2856, loss -2827.09, acc 0.9375\n",
      "2017-09-12T00:23:47.060138: step 2857, loss -918.096, acc 0.84375\n",
      "2017-09-12T00:23:47.217431: step 2858, loss -312.634, acc 0.90625\n",
      "2017-09-12T00:23:47.361002: step 2859, loss -811.359, acc 0.90625\n",
      "2017-09-12T00:23:47.516687: step 2860, loss -803.039, acc 0.90625\n",
      "2017-09-12T00:23:47.663808: step 2861, loss 906.528, acc 0.875\n",
      "2017-09-12T00:23:47.849875: step 2862, loss -3597.86, acc 0.9375\n",
      "2017-09-12T00:23:48.005674: step 2863, loss 428.788, acc 0.84375\n",
      "2017-09-12T00:23:48.159245: step 2864, loss -2200.83, acc 0.96875\n",
      "2017-09-12T00:23:48.329118: step 2865, loss 1339.5, acc 0.84375\n",
      "2017-09-12T00:23:48.493835: step 2866, loss -2283.64, acc 1\n",
      "2017-09-12T00:23:48.638271: step 2867, loss -1347.88, acc 0.96875\n",
      "2017-09-12T00:23:48.786708: step 2868, loss -7.60657, acc 0.9375\n",
      "2017-09-12T00:23:48.944120: step 2869, loss -3281.74, acc 1\n",
      "2017-09-12T00:23:49.103361: step 2870, loss -1765.69, acc 0.96875\n",
      "2017-09-12T00:23:49.259208: step 2871, loss -608.17, acc 0.90625\n",
      "2017-09-12T00:23:49.412661: step 2872, loss -453.818, acc 0.875\n",
      "2017-09-12T00:23:49.564978: step 2873, loss -39.8767, acc 0.875\n",
      "2017-09-12T00:23:49.711124: step 2874, loss -1869.98, acc 0.96875\n",
      "2017-09-12T00:23:49.858539: step 2875, loss -973.472, acc 0.96875\n",
      "2017-09-12T00:23:50.012894: step 2876, loss -1964.75, acc 0.9375\n",
      "2017-09-12T00:23:50.165176: step 2877, loss -1221.78, acc 0.90625\n",
      "2017-09-12T00:23:50.329090: step 2878, loss -3746.41, acc 0.90625\n",
      "2017-09-12T00:23:50.462832: step 2879, loss -1345.87, acc 0.9375\n",
      "2017-09-12T00:23:50.609872: step 2880, loss -2852.5, acc 0.96875\n",
      "2017-09-12T00:23:50.768589: step 2881, loss -567.945, acc 0.84375\n",
      "2017-09-12T00:23:50.962069: step 2882, loss -2141.01, acc 0.9375\n",
      "2017-09-12T00:23:51.114635: step 2883, loss -2350.23, acc 0.9375\n",
      "2017-09-12T00:23:51.308959: step 2884, loss -1468.55, acc 0.875\n",
      "2017-09-12T00:23:51.480249: step 2885, loss 301.303, acc 0.90625\n",
      "2017-09-12T00:23:51.646510: step 2886, loss -944.619, acc 0.9375\n",
      "2017-09-12T00:23:51.803192: step 2887, loss -2239.04, acc 0.96875\n",
      "2017-09-12T00:23:51.952235: step 2888, loss -362.383, acc 0.96875\n",
      "2017-09-12T00:23:52.103334: step 2889, loss -2745.09, acc 0.96875\n",
      "2017-09-12T00:23:52.255821: step 2890, loss -2726.45, acc 1\n",
      "2017-09-12T00:23:52.404677: step 2891, loss -2872.4, acc 1\n",
      "2017-09-12T00:23:52.555878: step 2892, loss -3131.25, acc 0.9375\n",
      "2017-09-12T00:23:52.602755: step 2893, loss -164.518, acc 0.875\n",
      "2017-09-12T00:23:52.758164: step 2894, loss -113.091, acc 0.875\n",
      "2017-09-12T00:23:52.916141: step 2895, loss -2016.53, acc 0.9375\n",
      "2017-09-12T00:23:53.067099: step 2896, loss -1882.78, acc 0.96875\n",
      "2017-09-12T00:23:53.219075: step 2897, loss -71.9078, acc 0.84375\n",
      "2017-09-12T00:23:53.366870: step 2898, loss -1394.89, acc 0.90625\n",
      "2017-09-12T00:23:53.566232: step 2899, loss -4055.98, acc 1\n",
      "2017-09-12T00:23:53.740557: step 2900, loss 344.006, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:23:55.951102: step 2900, loss -1842.62, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-2900\n",
      "\n",
      "2017-09-12T00:23:59.612972: step 2901, loss -1884.02, acc 0.9375\n",
      "2017-09-12T00:23:59.718183: step 2902, loss -2378.89, acc 0.84375\n",
      "2017-09-12T00:23:59.834952: step 2903, loss -366.284, acc 0.9375\n",
      "2017-09-12T00:23:59.962672: step 2904, loss -1501.67, acc 0.9375\n",
      "2017-09-12T00:24:00.069166: step 2905, loss -3188.73, acc 0.9375\n",
      "2017-09-12T00:24:00.168495: step 2906, loss -1011.07, acc 0.96875\n",
      "2017-09-12T00:24:00.275201: step 2907, loss -1982.73, acc 0.90625\n",
      "2017-09-12T00:24:00.388161: step 2908, loss -3129.7, acc 0.96875\n",
      "2017-09-12T00:24:00.495878: step 2909, loss -989.563, acc 0.9375\n",
      "2017-09-12T00:24:00.638550: step 2910, loss -846.472, acc 0.90625\n",
      "2017-09-12T00:24:00.790096: step 2911, loss -1515.09, acc 0.875\n",
      "2017-09-12T00:24:00.968607: step 2912, loss -2377.85, acc 0.9375\n",
      "2017-09-12T00:24:01.123060: step 2913, loss 1459.74, acc 0.875\n",
      "2017-09-12T00:24:01.223575: step 2914, loss -3744.66, acc 0.96875\n",
      "2017-09-12T00:24:01.345604: step 2915, loss 1.98703, acc 0.90625\n",
      "2017-09-12T00:24:01.566211: step 2916, loss -44.9684, acc 0.875\n",
      "2017-09-12T00:24:01.795356: step 2917, loss -3803.24, acc 0.9375\n",
      "2017-09-12T00:24:01.972841: step 2918, loss -1173.63, acc 0.84375\n",
      "2017-09-12T00:24:02.149120: step 2919, loss 1336.46, acc 0.84375\n",
      "2017-09-12T00:24:02.319115: step 2920, loss -2751.41, acc 0.96875\n",
      "2017-09-12T00:24:02.515031: step 2921, loss -3739.86, acc 0.96875\n",
      "2017-09-12T00:24:02.662441: step 2922, loss -384.042, acc 0.84375\n",
      "2017-09-12T00:24:02.831774: step 2923, loss -3832.07, acc 1\n",
      "2017-09-12T00:24:02.995740: step 2924, loss -3686.65, acc 1\n",
      "2017-09-12T00:24:03.152122: step 2925, loss -2010.34, acc 0.90625\n",
      "2017-09-12T00:24:03.294646: step 2926, loss -1995.49, acc 1\n",
      "2017-09-12T00:24:03.455611: step 2927, loss -508.902, acc 0.875\n",
      "2017-09-12T00:24:03.610789: step 2928, loss -465.555, acc 0.90625\n",
      "2017-09-12T00:24:03.752158: step 2929, loss -3825.27, acc 1\n",
      "2017-09-12T00:24:03.889186: step 2930, loss -1968.64, acc 0.9375\n",
      "2017-09-12T00:24:04.052709: step 2931, loss 1421.65, acc 0.8125\n",
      "2017-09-12T00:24:04.194460: step 2932, loss -1092.86, acc 0.90625\n",
      "2017-09-12T00:24:04.336577: step 2933, loss -2573.46, acc 0.9375\n",
      "2017-09-12T00:24:04.471511: step 2934, loss -1967.44, acc 0.96875\n",
      "2017-09-12T00:24:04.613053: step 2935, loss -2384.18, acc 0.90625\n",
      "2017-09-12T00:24:04.751202: step 2936, loss -142.863, acc 0.90625\n",
      "2017-09-12T00:24:04.897566: step 2937, loss -2397.07, acc 0.9375\n",
      "2017-09-12T00:24:05.036336: step 2938, loss -2518.04, acc 0.9375\n",
      "2017-09-12T00:24:05.172808: step 2939, loss -3808.78, acc 0.96875\n",
      "2017-09-12T00:24:05.324864: step 2940, loss 32.0137, acc 0.90625\n",
      "2017-09-12T00:24:05.465627: step 2941, loss -2968.92, acc 0.9375\n",
      "2017-09-12T00:24:05.601813: step 2942, loss -3052.68, acc 0.9375\n",
      "2017-09-12T00:24:05.746957: step 2943, loss -1049.97, acc 0.875\n",
      "2017-09-12T00:24:05.890077: step 2944, loss -2974.85, acc 1\n",
      "2017-09-12T00:24:06.042790: step 2945, loss -1521.75, acc 0.96875\n",
      "2017-09-12T00:24:06.184972: step 2946, loss -575.93, acc 0.875\n",
      "2017-09-12T00:24:06.327172: step 2947, loss -1135.63, acc 0.875\n",
      "2017-09-12T00:24:06.480063: step 2948, loss -2528.12, acc 0.9375\n",
      "2017-09-12T00:24:06.612390: step 2949, loss -1400.39, acc 0.90625\n",
      "2017-09-12T00:24:06.769970: step 2950, loss -60.53, acc 0.90625\n",
      "2017-09-12T00:24:06.909744: step 2951, loss -2386.87, acc 0.9375\n",
      "2017-09-12T00:24:07.049777: step 2952, loss -957.23, acc 0.9375\n",
      "2017-09-12T00:24:07.190492: step 2953, loss -1509.79, acc 0.96875\n",
      "2017-09-12T00:24:07.323656: step 2954, loss -3223.68, acc 0.96875\n",
      "2017-09-12T00:24:07.473626: step 2955, loss -102.886, acc 0.9375\n",
      "2017-09-12T00:24:07.613498: step 2956, loss 439.531, acc 0.9375\n",
      "2017-09-12T00:24:07.759370: step 2957, loss -71.347, acc 0.875\n",
      "2017-09-12T00:24:07.895071: step 2958, loss -2052.91, acc 0.875\n",
      "2017-09-12T00:24:08.083117: step 2959, loss 1011.94, acc 0.84375\n",
      "2017-09-12T00:24:08.243509: step 2960, loss -4032.1, acc 0.96875\n",
      "2017-09-12T00:24:08.422006: step 2961, loss 262.017, acc 0.78125\n",
      "2017-09-12T00:24:08.560426: step 2962, loss 1528.43, acc 0.84375\n",
      "2017-09-12T00:24:08.720473: step 2963, loss -2448.97, acc 1\n",
      "2017-09-12T00:24:08.871632: step 2964, loss -2950.81, acc 0.96875\n",
      "2017-09-12T00:24:09.162624: step 2965, loss -2364.82, acc 0.9375\n",
      "2017-09-12T00:24:09.382076: step 2966, loss 884.071, acc 0.875\n",
      "2017-09-12T00:24:09.650740: step 2967, loss -2137.43, acc 0.90625\n",
      "2017-09-12T00:24:09.890289: step 2968, loss -1507.99, acc 0.9375\n",
      "2017-09-12T00:24:10.129591: step 2969, loss -1743.07, acc 0.90625\n",
      "2017-09-12T00:24:10.313121: step 2970, loss 1400.03, acc 0.84375\n",
      "2017-09-12T00:24:10.547438: step 2971, loss -3387.95, acc 0.9375\n",
      "2017-09-12T00:24:10.708616: step 2972, loss -4672.76, acc 0.96875\n",
      "2017-09-12T00:24:10.929814: step 2973, loss -595.853, acc 0.875\n",
      "2017-09-12T00:24:11.119971: step 2974, loss -1164.57, acc 0.875\n",
      "2017-09-12T00:24:11.277856: step 2975, loss -2988.14, acc 0.96875\n",
      "2017-09-12T00:24:11.495385: step 2976, loss -2543.7, acc 0.96875\n",
      "2017-09-12T00:24:11.681490: step 2977, loss -4277.65, acc 0.96875\n",
      "2017-09-12T00:24:11.872994: step 2978, loss -3717.5, acc 0.90625\n",
      "2017-09-12T00:24:12.012566: step 2979, loss -2515.93, acc 0.9375\n",
      "2017-09-12T00:24:12.158243: step 2980, loss -1464.75, acc 1\n",
      "2017-09-12T00:24:12.293817: step 2981, loss -1457.85, acc 0.96875\n",
      "2017-09-12T00:24:12.457864: step 2982, loss -1275.23, acc 0.90625\n",
      "2017-09-12T00:24:12.575004: step 2983, loss -3140.86, acc 0.9375\n",
      "2017-09-12T00:24:12.740921: step 2984, loss 1015.54, acc 0.875\n",
      "2017-09-12T00:24:12.892746: step 2985, loss -2517.84, acc 0.90625\n",
      "2017-09-12T00:24:13.036610: step 2986, loss -2460.86, acc 0.90625\n",
      "2017-09-12T00:24:13.221738: step 2987, loss -2529.75, acc 1\n",
      "2017-09-12T00:24:13.362136: step 2988, loss -898.375, acc 0.96875\n",
      "2017-09-12T00:24:13.510157: step 2989, loss -1895.1, acc 0.90625\n",
      "2017-09-12T00:24:13.639940: step 2990, loss 9.57153, acc 0.875\n",
      "2017-09-12T00:24:13.784986: step 2991, loss -111.446, acc 0.875\n",
      "2017-09-12T00:24:13.922496: step 2992, loss -1642.47, acc 0.90625\n",
      "2017-09-12T00:24:14.069801: step 2993, loss 32.9216, acc 0.90625\n",
      "2017-09-12T00:24:14.213366: step 2994, loss 868.218, acc 0.90625\n",
      "2017-09-12T00:24:14.356327: step 2995, loss -3197.87, acc 0.96875\n",
      "2017-09-12T00:24:14.519935: step 2996, loss -1396.59, acc 0.90625\n",
      "2017-09-12T00:24:14.690658: step 2997, loss -2682.27, acc 1\n",
      "2017-09-12T00:24:14.838458: step 2998, loss -515.384, acc 0.875\n",
      "2017-09-12T00:24:14.976820: step 2999, loss -2071.93, acc 0.90625\n",
      "2017-09-12T00:24:15.120232: step 3000, loss -1718.48, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:24:16.409293: step 3000, loss -2001.26, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3000\n",
      "\n",
      "2017-09-12T00:24:18.684658: step 3001, loss 3202.23, acc 0.6875\n",
      "2017-09-12T00:24:18.830663: step 3002, loss -566.743, acc 0.9375\n",
      "2017-09-12T00:24:18.991458: step 3003, loss -1468.26, acc 0.90625\n",
      "2017-09-12T00:24:19.100867: step 3004, loss -3070.7, acc 0.96875\n",
      "2017-09-12T00:24:19.223173: step 3005, loss -2003.97, acc 0.9375\n",
      "2017-09-12T00:24:19.354972: step 3006, loss -2008.05, acc 0.90625\n",
      "2017-09-12T00:24:19.486496: step 3007, loss 1333.41, acc 0.75\n",
      "2017-09-12T00:24:19.591164: step 3008, loss 1364.46, acc 0.8125\n",
      "2017-09-12T00:24:19.691380: step 3009, loss -595.83, acc 0.90625\n",
      "2017-09-12T00:24:19.787378: step 3010, loss -1137.95, acc 0.90625\n",
      "2017-09-12T00:24:19.908309: step 3011, loss -1098.25, acc 0.9375\n",
      "2017-09-12T00:24:20.013096: step 3012, loss -5108.81, acc 0.96875\n",
      "2017-09-12T00:24:20.111423: step 3013, loss -1475.92, acc 0.90625\n",
      "2017-09-12T00:24:20.204122: step 3014, loss -1145.61, acc 0.84375\n",
      "2017-09-12T00:24:20.298676: step 3015, loss -2014, acc 0.9375\n",
      "2017-09-12T00:24:20.399619: step 3016, loss -593.334, acc 0.90625\n",
      "2017-09-12T00:24:20.489980: step 3017, loss -3201.73, acc 0.9375\n",
      "2017-09-12T00:24:20.600399: step 3018, loss 350.888, acc 0.84375\n",
      "2017-09-12T00:24:20.711315: step 3019, loss -582.575, acc 0.875\n",
      "2017-09-12T00:24:20.812698: step 3020, loss -3244.05, acc 0.96875\n",
      "2017-09-12T00:24:20.907594: step 3021, loss -1429.11, acc 0.8125\n",
      "2017-09-12T00:24:21.008595: step 3022, loss -1020.89, acc 0.9375\n",
      "2017-09-12T00:24:21.100233: step 3023, loss -2061.25, acc 0.96875\n",
      "2017-09-12T00:24:21.203300: step 3024, loss -2086.22, acc 0.90625\n",
      "2017-09-12T00:24:21.306875: step 3025, loss -1494.81, acc 0.9375\n",
      "2017-09-12T00:24:21.437544: step 3026, loss -4051.82, acc 1\n",
      "2017-09-12T00:24:21.730451: step 3027, loss -4111.13, acc 1\n",
      "2017-09-12T00:24:21.886489: step 3028, loss -2982.21, acc 1\n",
      "2017-09-12T00:24:22.058579: step 3029, loss -1664.04, acc 0.90625\n",
      "2017-09-12T00:24:22.212011: step 3030, loss -2484.61, acc 0.96875\n",
      "2017-09-12T00:24:22.375562: step 3031, loss -3492.73, acc 0.96875\n",
      "2017-09-12T00:24:22.538610: step 3032, loss -2775.78, acc 0.9375\n",
      "2017-09-12T00:24:22.686067: step 3033, loss -2740.72, acc 0.9375\n",
      "2017-09-12T00:24:22.848415: step 3034, loss -3021.54, acc 0.96875\n",
      "2017-09-12T00:24:23.025043: step 3035, loss -2917.75, acc 0.96875\n",
      "2017-09-12T00:24:23.189044: step 3036, loss -1550.71, acc 0.90625\n",
      "2017-09-12T00:24:23.359949: step 3037, loss -2123.08, acc 0.9375\n",
      "2017-09-12T00:24:23.510041: step 3038, loss -1957.24, acc 0.9375\n",
      "2017-09-12T00:24:23.663554: step 3039, loss -1923.46, acc 0.96875\n",
      "2017-09-12T00:24:23.816544: step 3040, loss -3561.99, acc 0.90625\n",
      "2017-09-12T00:24:23.963242: step 3041, loss -594.55, acc 0.84375\n",
      "2017-09-12T00:24:24.130057: step 3042, loss -2296.6, acc 0.96875\n",
      "2017-09-12T00:24:24.303661: step 3043, loss 557.446, acc 0.875\n",
      "2017-09-12T00:24:24.463484: step 3044, loss -2549.9, acc 0.90625\n",
      "2017-09-12T00:24:24.620071: step 3045, loss -3314.43, acc 0.96875\n",
      "2017-09-12T00:24:24.780681: step 3046, loss -584.634, acc 0.90625\n",
      "2017-09-12T00:24:24.937199: step 3047, loss -2456.84, acc 0.90625\n",
      "2017-09-12T00:24:25.095778: step 3048, loss -2026.27, acc 0.9375\n",
      "2017-09-12T00:24:25.259223: step 3049, loss -661.568, acc 0.90625\n",
      "2017-09-12T00:24:25.415742: step 3050, loss -545.688, acc 0.96875\n",
      "2017-09-12T00:24:25.578459: step 3051, loss -106.001, acc 0.875\n",
      "2017-09-12T00:24:25.742393: step 3052, loss -1291.21, acc 0.90625\n",
      "2017-09-12T00:24:25.910899: step 3053, loss -2690.3, acc 0.90625\n",
      "2017-09-12T00:24:26.059848: step 3054, loss -2187.35, acc 0.9375\n",
      "2017-09-12T00:24:26.223052: step 3055, loss -2016.15, acc 0.96875\n",
      "2017-09-12T00:24:26.379443: step 3056, loss -2161.74, acc 0.9375\n",
      "2017-09-12T00:24:26.544558: step 3057, loss 1510.78, acc 0.84375\n",
      "2017-09-12T00:24:26.696609: step 3058, loss -2215.96, acc 0.90625\n",
      "2017-09-12T00:24:26.894822: step 3059, loss -1549.82, acc 0.9375\n",
      "2017-09-12T00:24:27.043175: step 3060, loss -2198.42, acc 0.96875\n",
      "2017-09-12T00:24:27.191719: step 3061, loss 653.922, acc 0.875\n",
      "2017-09-12T00:24:27.338819: step 3062, loss -693.304, acc 0.90625\n",
      "2017-09-12T00:24:27.518826: step 3063, loss -2341.81, acc 0.90625\n",
      "2017-09-12T00:24:27.671382: step 3064, loss -3193.52, acc 0.96875\n",
      "2017-09-12T00:24:27.842052: step 3065, loss -85.1429, acc 0.9375\n",
      "2017-09-12T00:24:27.981969: step 3066, loss -537.497, acc 0.9375\n",
      "2017-09-12T00:24:28.153544: step 3067, loss -0.737305, acc 0.9375\n",
      "2017-09-12T00:24:28.425792: step 3068, loss -4573.83, acc 0.90625\n",
      "2017-09-12T00:24:28.602911: step 3069, loss -4281.23, acc 0.96875\n",
      "2017-09-12T00:24:28.756480: step 3070, loss -1161.43, acc 0.96875\n",
      "2017-09-12T00:24:28.914170: step 3071, loss -4320.47, acc 0.9375\n",
      "2017-09-12T00:24:29.052903: step 3072, loss -1762.32, acc 0.9375\n",
      "2017-09-12T00:24:29.211807: step 3073, loss -2674.73, acc 0.96875\n",
      "2017-09-12T00:24:29.427342: step 3074, loss -4204.75, acc 0.96875\n",
      "2017-09-12T00:24:29.552051: step 3075, loss -1152.88, acc 0.9375\n",
      "2017-09-12T00:24:29.726583: step 3076, loss -1656.39, acc 0.96875\n",
      "2017-09-12T00:24:29.887931: step 3077, loss -1198.24, acc 0.96875\n",
      "2017-09-12T00:24:30.047061: step 3078, loss -4879.01, acc 0.9375\n",
      "2017-09-12T00:24:30.222372: step 3079, loss -8.82764, acc 0.90625\n",
      "2017-09-12T00:24:30.378196: step 3080, loss -2112.1, acc 0.9375\n",
      "2017-09-12T00:24:30.519826: step 3081, loss -4316.81, acc 0.9375\n",
      "2017-09-12T00:24:30.710090: step 3082, loss -78.3445, acc 0.875\n",
      "2017-09-12T00:24:30.874767: step 3083, loss -567.964, acc 0.90625\n",
      "2017-09-12T00:24:31.045492: step 3084, loss -3284.4, acc 0.9375\n",
      "2017-09-12T00:24:31.199915: step 3085, loss -1695.32, acc 0.875\n",
      "2017-09-12T00:24:31.354045: step 3086, loss -537.934, acc 0.9375\n",
      "2017-09-12T00:24:31.531363: step 3087, loss -1593.84, acc 0.90625\n",
      "2017-09-12T00:24:31.692208: step 3088, loss -2705.74, acc 0.90625\n",
      "2017-09-12T00:24:31.829867: step 3089, loss -146.221, acc 0.9375\n",
      "2017-09-12T00:24:31.982638: step 3090, loss -2636.94, acc 0.96875\n",
      "2017-09-12T00:24:32.121700: step 3091, loss -696.152, acc 0.90625\n",
      "2017-09-12T00:24:32.272747: step 3092, loss -3936.14, acc 0.96875\n",
      "2017-09-12T00:24:32.422210: step 3093, loss -318.445, acc 0.90625\n",
      "2017-09-12T00:24:32.567309: step 3094, loss -3182.94, acc 0.96875\n",
      "2017-09-12T00:24:32.714175: step 3095, loss -5078.54, acc 1\n",
      "2017-09-12T00:24:32.859040: step 3096, loss -1016.58, acc 1\n",
      "2017-09-12T00:24:33.005836: step 3097, loss -2251.42, acc 0.90625\n",
      "2017-09-12T00:24:33.154810: step 3098, loss -1768.24, acc 0.9375\n",
      "2017-09-12T00:24:33.307960: step 3099, loss -3777.94, acc 0.96875\n",
      "2017-09-12T00:24:33.452433: step 3100, loss -484.078, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:24:34.698140: step 3100, loss -2168.06, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3100\n",
      "\n",
      "2017-09-12T00:24:36.660977: step 3101, loss -6613.81, acc 0.96875\n",
      "2017-09-12T00:24:36.742224: step 3102, loss -1746.97, acc 0.9375\n",
      "2017-09-12T00:24:36.859135: step 3103, loss -1368.67, acc 0.96875\n",
      "2017-09-12T00:24:36.992475: step 3104, loss -694.083, acc 0.90625\n",
      "2017-09-12T00:24:37.133852: step 3105, loss -1016.45, acc 0.90625\n",
      "2017-09-12T00:24:37.260054: step 3106, loss -4540.87, acc 0.96875\n",
      "2017-09-12T00:24:37.391353: step 3107, loss -680.907, acc 0.9375\n",
      "2017-09-12T00:24:37.496678: step 3108, loss 107.977, acc 0.875\n",
      "2017-09-12T00:24:37.595970: step 3109, loss -2791.13, acc 0.9375\n",
      "2017-09-12T00:24:37.688685: step 3110, loss -3963.64, acc 0.96875\n",
      "2017-09-12T00:24:37.792696: step 3111, loss -1677.61, acc 0.9375\n",
      "2017-09-12T00:24:37.893968: step 3112, loss -3194.08, acc 0.9375\n",
      "2017-09-12T00:24:37.984158: step 3113, loss 1158.86, acc 0.84375\n",
      "2017-09-12T00:24:38.078467: step 3114, loss -1807.94, acc 0.90625\n",
      "2017-09-12T00:24:38.164434: step 3115, loss -4575.05, acc 0.96875\n",
      "2017-09-12T00:24:38.254863: step 3116, loss -3190.23, acc 0.96875\n",
      "2017-09-12T00:24:38.342969: step 3117, loss -3848.54, acc 1\n",
      "2017-09-12T00:24:38.428579: step 3118, loss -1643.46, acc 0.90625\n",
      "2017-09-12T00:24:38.521605: step 3119, loss -1734.57, acc 0.90625\n",
      "2017-09-12T00:24:38.609461: step 3120, loss -1812.99, acc 0.84375\n",
      "2017-09-12T00:24:38.700263: step 3121, loss -2745.75, acc 0.96875\n",
      "2017-09-12T00:24:38.798376: step 3122, loss -1438.65, acc 0.9375\n",
      "2017-09-12T00:24:38.891838: step 3123, loss 997.496, acc 0.875\n",
      "2017-09-12T00:24:38.984190: step 3124, loss -4287.51, acc 1\n",
      "2017-09-12T00:24:39.162997: step 3125, loss -2172.72, acc 0.96875\n",
      "2017-09-12T00:24:39.378815: step 3126, loss -3638.28, acc 0.875\n",
      "2017-09-12T00:24:39.517294: step 3127, loss -1581.1, acc 0.96875\n",
      "2017-09-12T00:24:39.663594: step 3128, loss -3166.73, acc 1\n",
      "2017-09-12T00:24:39.813391: step 3129, loss -1258.7, acc 0.9375\n",
      "2017-09-12T00:24:39.952839: step 3130, loss -1823.29, acc 0.90625\n",
      "2017-09-12T00:24:40.099007: step 3131, loss -465.446, acc 0.90625\n",
      "2017-09-12T00:24:40.245275: step 3132, loss -1232.59, acc 0.875\n",
      "2017-09-12T00:24:40.395211: step 3133, loss -4643.78, acc 0.875\n",
      "2017-09-12T00:24:40.540242: step 3134, loss -2203.26, acc 0.96875\n",
      "2017-09-12T00:24:40.686613: step 3135, loss -2931.75, acc 0.9375\n",
      "2017-09-12T00:24:40.833259: step 3136, loss -2327.08, acc 1\n",
      "2017-09-12T00:24:40.977596: step 3137, loss -501.12, acc 0.96875\n",
      "2017-09-12T00:24:41.125392: step 3138, loss -2770.8, acc 0.96875\n",
      "2017-09-12T00:24:41.274833: step 3139, loss -2752.11, acc 0.90625\n",
      "2017-09-12T00:24:41.407093: step 3140, loss -2787.24, acc 0.9375\n",
      "2017-09-12T00:24:41.559005: step 3141, loss -2253.79, acc 0.96875\n",
      "2017-09-12T00:24:41.707926: step 3142, loss -2930.13, acc 0.90625\n",
      "2017-09-12T00:24:41.855993: step 3143, loss -1249.23, acc 0.9375\n",
      "2017-09-12T00:24:41.998672: step 3144, loss -4525.29, acc 0.96875\n",
      "2017-09-12T00:24:42.148574: step 3145, loss -1334.77, acc 0.90625\n",
      "2017-09-12T00:24:42.286060: step 3146, loss -3934.6, acc 0.9375\n",
      "2017-09-12T00:24:42.428945: step 3147, loss -1320.2, acc 0.96875\n",
      "2017-09-12T00:24:42.585423: step 3148, loss -650.022, acc 0.875\n",
      "2017-09-12T00:24:42.712363: step 3149, loss -3624.7, acc 0.9375\n",
      "2017-09-12T00:24:42.865773: step 3150, loss -1561.29, acc 0.90625\n",
      "2017-09-12T00:24:43.012749: step 3151, loss -1969.31, acc 0.90625\n",
      "2017-09-12T00:24:43.157391: step 3152, loss -1406.56, acc 0.84375\n",
      "2017-09-12T00:24:43.313141: step 3153, loss -53.085, acc 0.90625\n",
      "2017-09-12T00:24:43.450664: step 3154, loss -2416.66, acc 0.96875\n",
      "2017-09-12T00:24:43.589458: step 3155, loss -646.002, acc 0.96875\n",
      "2017-09-12T00:24:43.632311: step 3156, loss 2312.4, acc 0.875\n",
      "2017-09-12T00:24:43.792180: step 3157, loss -2201.82, acc 0.9375\n",
      "2017-09-12T00:24:43.949598: step 3158, loss -2460.82, acc 0.90625\n",
      "2017-09-12T00:24:44.110077: step 3159, loss -3046.38, acc 0.9375\n",
      "2017-09-12T00:24:44.247308: step 3160, loss -1830.67, acc 0.96875\n",
      "2017-09-12T00:24:44.399036: step 3161, loss -3683.64, acc 0.96875\n",
      "2017-09-12T00:24:44.542733: step 3162, loss -3939.83, acc 0.9375\n",
      "2017-09-12T00:24:44.669905: step 3163, loss -2434.06, acc 0.9375\n",
      "2017-09-12T00:24:44.816515: step 3164, loss -2723.3, acc 1\n",
      "2017-09-12T00:24:44.956917: step 3165, loss -3622.16, acc 1\n",
      "2017-09-12T00:24:45.135898: step 3166, loss -1336.7, acc 0.9375\n",
      "2017-09-12T00:24:45.308944: step 3167, loss -2338.7, acc 0.875\n",
      "2017-09-12T00:24:45.459805: step 3168, loss -3039.53, acc 0.9375\n",
      "2017-09-12T00:24:45.617216: step 3169, loss -2278.06, acc 0.96875\n",
      "2017-09-12T00:24:45.772567: step 3170, loss -1251.34, acc 0.9375\n",
      "2017-09-12T00:24:45.922722: step 3171, loss -2993.56, acc 0.96875\n",
      "2017-09-12T00:24:46.069407: step 3172, loss -83.3345, acc 0.90625\n",
      "2017-09-12T00:24:46.219180: step 3173, loss -512.132, acc 0.9375\n",
      "2017-09-12T00:24:46.360385: step 3174, loss -2866.71, acc 1\n",
      "2017-09-12T00:24:46.508088: step 3175, loss -1723.51, acc 0.96875\n",
      "2017-09-12T00:24:46.666942: step 3176, loss -1207.01, acc 0.9375\n",
      "2017-09-12T00:24:46.814816: step 3177, loss -769.193, acc 0.84375\n",
      "2017-09-12T00:24:46.967889: step 3178, loss -1617.62, acc 0.9375\n",
      "2017-09-12T00:24:47.117149: step 3179, loss -1651.9, acc 0.96875\n",
      "2017-09-12T00:24:47.259850: step 3180, loss -3526.88, acc 1\n",
      "2017-09-12T00:24:47.400330: step 3181, loss -806.142, acc 0.90625\n",
      "2017-09-12T00:24:47.583347: step 3182, loss -3257.36, acc 0.90625\n",
      "2017-09-12T00:24:47.714759: step 3183, loss -5762.77, acc 1\n",
      "2017-09-12T00:24:47.868749: step 3184, loss -574.916, acc 0.9375\n",
      "2017-09-12T00:24:48.005793: step 3185, loss -1099.16, acc 0.875\n",
      "2017-09-12T00:24:48.158253: step 3186, loss -3074.62, acc 1\n",
      "2017-09-12T00:24:48.302850: step 3187, loss -2265.46, acc 0.90625\n",
      "2017-09-12T00:24:48.448141: step 3188, loss -1922.08, acc 0.9375\n",
      "2017-09-12T00:24:48.598837: step 3189, loss -5820.82, acc 1\n",
      "2017-09-12T00:24:48.745255: step 3190, loss -2963.27, acc 0.96875\n",
      "2017-09-12T00:24:48.884263: step 3191, loss -2324.22, acc 0.96875\n",
      "2017-09-12T00:24:49.040362: step 3192, loss -3630.92, acc 0.9375\n",
      "2017-09-12T00:24:49.182942: step 3193, loss -2579.23, acc 0.9375\n",
      "2017-09-12T00:24:49.341837: step 3194, loss -1679.77, acc 0.9375\n",
      "2017-09-12T00:24:49.498510: step 3195, loss -2476.86, acc 0.84375\n",
      "2017-09-12T00:24:49.633814: step 3196, loss -1694.44, acc 0.90625\n",
      "2017-09-12T00:24:49.770183: step 3197, loss -1983.92, acc 0.96875\n",
      "2017-09-12T00:24:49.922176: step 3198, loss -1978.06, acc 0.90625\n",
      "2017-09-12T00:24:50.074826: step 3199, loss -2384.78, acc 0.90625\n",
      "2017-09-12T00:24:50.206899: step 3200, loss -1695.22, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:24:51.487697: step 3200, loss -2366.17, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3200\n",
      "\n",
      "2017-09-12T00:24:53.087762: step 3201, loss -1742.58, acc 0.9375\n",
      "2017-09-12T00:24:53.174779: step 3202, loss -3811.42, acc 0.9375\n",
      "2017-09-12T00:24:53.291015: step 3203, loss -1470.81, acc 0.9375\n",
      "2017-09-12T00:24:53.424090: step 3204, loss -1837.23, acc 0.90625\n",
      "2017-09-12T00:24:53.567525: step 3205, loss -2547.56, acc 0.9375\n",
      "2017-09-12T00:24:53.706143: step 3206, loss -4286.67, acc 0.96875\n",
      "2017-09-12T00:24:53.848685: step 3207, loss -3727.81, acc 0.9375\n",
      "2017-09-12T00:24:53.994091: step 3208, loss -4890.07, acc 1\n",
      "2017-09-12T00:24:54.159550: step 3209, loss -1202.24, acc 0.90625\n",
      "2017-09-12T00:24:54.261275: step 3210, loss -3109.85, acc 0.9375\n",
      "2017-09-12T00:24:54.368553: step 3211, loss -3633.91, acc 0.9375\n",
      "2017-09-12T00:24:54.459365: step 3212, loss -2271.3, acc 0.9375\n",
      "2017-09-12T00:24:54.568230: step 3213, loss -6021.24, acc 1\n",
      "2017-09-12T00:24:54.668093: step 3214, loss -2241.81, acc 0.9375\n",
      "2017-09-12T00:24:54.764180: step 3215, loss -1846.01, acc 0.96875\n",
      "2017-09-12T00:24:54.853518: step 3216, loss -3626.04, acc 0.9375\n",
      "2017-09-12T00:24:54.943779: step 3217, loss -1822.66, acc 0.96875\n",
      "2017-09-12T00:24:55.043528: step 3218, loss -2595.12, acc 0.9375\n",
      "2017-09-12T00:24:55.133576: step 3219, loss -1046.09, acc 0.875\n",
      "2017-09-12T00:24:55.223267: step 3220, loss -728.477, acc 0.90625\n",
      "2017-09-12T00:24:55.311093: step 3221, loss 1100.24, acc 0.875\n",
      "2017-09-12T00:24:55.390191: step 3222, loss -784.452, acc 0.875\n",
      "2017-09-12T00:24:55.483062: step 3223, loss -1879.13, acc 1\n",
      "2017-09-12T00:24:55.573634: step 3224, loss -3006.82, acc 0.96875\n",
      "2017-09-12T00:24:55.670101: step 3225, loss 1170.85, acc 0.75\n",
      "2017-09-12T00:24:55.760290: step 3226, loss -3233.44, acc 0.90625\n",
      "2017-09-12T00:24:55.849735: step 3227, loss -1804.17, acc 0.9375\n",
      "2017-09-12T00:24:55.940042: step 3228, loss -2201.35, acc 0.9375\n",
      "2017-09-12T00:24:56.160628: step 3229, loss -4285.13, acc 1\n",
      "2017-09-12T00:24:56.314891: step 3230, loss -2615.09, acc 1\n",
      "2017-09-12T00:24:56.458768: step 3231, loss -1557.22, acc 0.875\n",
      "2017-09-12T00:24:56.604849: step 3232, loss 1857.58, acc 0.8125\n",
      "2017-09-12T00:24:56.753018: step 3233, loss -498.018, acc 0.875\n",
      "2017-09-12T00:24:56.903139: step 3234, loss -3552.54, acc 0.90625\n",
      "2017-09-12T00:24:57.041903: step 3235, loss -3073.61, acc 0.9375\n",
      "2017-09-12T00:24:57.200459: step 3236, loss -2015.21, acc 0.90625\n",
      "2017-09-12T00:24:57.337137: step 3237, loss -4201.35, acc 1\n",
      "2017-09-12T00:24:57.484139: step 3238, loss 642.637, acc 0.84375\n",
      "2017-09-12T00:24:57.634899: step 3239, loss -1321.12, acc 0.9375\n",
      "2017-09-12T00:24:57.784087: step 3240, loss -1377.86, acc 0.90625\n",
      "2017-09-12T00:24:57.925402: step 3241, loss -2472.2, acc 0.90625\n",
      "2017-09-12T00:24:58.078460: step 3242, loss -5607.94, acc 0.9375\n",
      "2017-09-12T00:24:58.218189: step 3243, loss -1903.64, acc 0.9375\n",
      "2017-09-12T00:24:58.376258: step 3244, loss -78.0052, acc 0.9375\n",
      "2017-09-12T00:24:58.503537: step 3245, loss 2930.92, acc 0.8125\n",
      "2017-09-12T00:24:58.651690: step 3246, loss -1803.6, acc 0.9375\n",
      "2017-09-12T00:24:58.797471: step 3247, loss -2018.42, acc 0.90625\n",
      "2017-09-12T00:24:58.947747: step 3248, loss -577.157, acc 0.9375\n",
      "2017-09-12T00:24:59.095666: step 3249, loss -1479.49, acc 0.9375\n",
      "2017-09-12T00:24:59.240830: step 3250, loss -458.913, acc 0.90625\n",
      "2017-09-12T00:24:59.390287: step 3251, loss -822.404, acc 0.84375\n",
      "2017-09-12T00:24:59.524338: step 3252, loss 358.75, acc 0.84375\n",
      "2017-09-12T00:24:59.681158: step 3253, loss -1332.56, acc 0.84375\n",
      "2017-09-12T00:24:59.823004: step 3254, loss -144.781, acc 0.78125\n",
      "2017-09-12T00:25:00.004139: step 3255, loss -1479.56, acc 0.875\n",
      "2017-09-12T00:25:00.152787: step 3256, loss -1463.03, acc 0.875\n",
      "2017-09-12T00:25:00.276546: step 3257, loss -3101.97, acc 0.9375\n",
      "2017-09-12T00:25:00.433704: step 3258, loss -2407.39, acc 0.90625\n",
      "2017-09-12T00:25:00.572928: step 3259, loss -796.517, acc 0.875\n",
      "2017-09-12T00:25:00.719302: step 3260, loss -1820.33, acc 0.96875\n",
      "2017-09-12T00:25:00.864613: step 3261, loss -2382.95, acc 0.90625\n",
      "2017-09-12T00:25:01.003908: step 3262, loss -1940.94, acc 0.9375\n",
      "2017-09-12T00:25:01.146951: step 3263, loss -3651.62, acc 0.96875\n",
      "2017-09-12T00:25:01.281489: step 3264, loss -4530.91, acc 0.96875\n",
      "2017-09-12T00:25:01.430182: step 3265, loss -4290.11, acc 0.9375\n",
      "2017-09-12T00:25:01.567153: step 3266, loss 601.798, acc 0.875\n",
      "2017-09-12T00:25:01.724259: step 3267, loss -3000.49, acc 0.875\n",
      "2017-09-12T00:25:01.868619: step 3268, loss -1470.86, acc 0.90625\n",
      "2017-09-12T00:25:02.009529: step 3269, loss -4591.58, acc 0.9375\n",
      "2017-09-12T00:25:02.143159: step 3270, loss -3767.54, acc 1\n",
      "2017-09-12T00:25:02.300524: step 3271, loss -2021.25, acc 0.875\n",
      "2017-09-12T00:25:02.438304: step 3272, loss -2070.75, acc 0.9375\n",
      "2017-09-12T00:25:02.591006: step 3273, loss -2030.87, acc 0.9375\n",
      "2017-09-12T00:25:02.737104: step 3274, loss -1823.5, acc 0.96875\n",
      "2017-09-12T00:25:02.876098: step 3275, loss 1021.35, acc 0.84375\n",
      "2017-09-12T00:25:03.018607: step 3276, loss -2634.11, acc 0.90625\n",
      "2017-09-12T00:25:03.160622: step 3277, loss -3162.21, acc 0.96875\n",
      "2017-09-12T00:25:03.310168: step 3278, loss 1179.61, acc 0.9375\n",
      "2017-09-12T00:25:03.452655: step 3279, loss -2401.7, acc 0.96875\n",
      "2017-09-12T00:25:03.607116: step 3280, loss -3067.46, acc 0.90625\n",
      "2017-09-12T00:25:03.752944: step 3281, loss -3555.12, acc 0.9375\n",
      "2017-09-12T00:25:03.899699: step 3282, loss -1535.17, acc 0.9375\n",
      "2017-09-12T00:25:04.055898: step 3283, loss -4376.86, acc 0.96875\n",
      "2017-09-12T00:25:04.205108: step 3284, loss -3118.42, acc 0.96875\n",
      "2017-09-12T00:25:04.361076: step 3285, loss -6275.31, acc 0.9375\n",
      "2017-09-12T00:25:04.494300: step 3286, loss -1834.76, acc 0.875\n",
      "2017-09-12T00:25:04.643991: step 3287, loss -1904.11, acc 0.9375\n",
      "2017-09-12T00:25:04.786050: step 3288, loss -1263.28, acc 0.90625\n",
      "2017-09-12T00:25:04.937083: step 3289, loss -2000.82, acc 0.96875\n",
      "2017-09-12T00:25:05.086169: step 3290, loss -2759.78, acc 0.96875\n",
      "2017-09-12T00:25:05.235653: step 3291, loss -2175.49, acc 0.90625\n",
      "2017-09-12T00:25:05.375772: step 3292, loss -4027.96, acc 0.9375\n",
      "2017-09-12T00:25:05.525847: step 3293, loss -3864.88, acc 0.96875\n",
      "2017-09-12T00:25:05.670028: step 3294, loss -832.786, acc 0.875\n",
      "2017-09-12T00:25:05.811859: step 3295, loss -745.903, acc 0.90625\n",
      "2017-09-12T00:25:05.964349: step 3296, loss -1952.45, acc 0.9375\n",
      "2017-09-12T00:25:06.146330: step 3297, loss -103.255, acc 0.84375\n",
      "2017-09-12T00:25:06.322070: step 3298, loss -2538.8, acc 1\n",
      "2017-09-12T00:25:06.467443: step 3299, loss -1135.81, acc 0.90625\n",
      "2017-09-12T00:25:06.625831: step 3300, loss -5220.84, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:25:07.955746: step 3300, loss -2551.28, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3300\n",
      "\n",
      "2017-09-12T00:25:10.210715: step 3301, loss -1961.23, acc 0.90625\n",
      "2017-09-12T00:25:10.296302: step 3302, loss -1334.48, acc 0.90625\n",
      "2017-09-12T00:25:10.429142: step 3303, loss -583.405, acc 0.9375\n",
      "2017-09-12T00:25:10.569920: step 3304, loss -5004.5, acc 0.90625\n",
      "2017-09-12T00:25:10.710787: step 3305, loss -2836.66, acc 0.875\n",
      "2017-09-12T00:25:10.839314: step 3306, loss -4537.82, acc 0.96875\n",
      "2017-09-12T00:25:10.945677: step 3307, loss -2639.68, acc 0.9375\n",
      "2017-09-12T00:25:11.046572: step 3308, loss -2019.67, acc 0.9375\n",
      "2017-09-12T00:25:11.144204: step 3309, loss -1375.7, acc 0.875\n",
      "2017-09-12T00:25:11.252916: step 3310, loss -1372.38, acc 0.875\n",
      "2017-09-12T00:25:11.354005: step 3311, loss 1180.53, acc 0.84375\n",
      "2017-09-12T00:25:11.453868: step 3312, loss -3368.15, acc 0.90625\n",
      "2017-09-12T00:25:11.549113: step 3313, loss -2730.91, acc 0.90625\n",
      "2017-09-12T00:25:11.638481: step 3314, loss -1452.37, acc 0.90625\n",
      "2017-09-12T00:25:11.730833: step 3315, loss -5231.23, acc 0.96875\n",
      "2017-09-12T00:25:11.820209: step 3316, loss -1840.54, acc 0.90625\n",
      "2017-09-12T00:25:11.913692: step 3317, loss -3569.91, acc 0.96875\n",
      "2017-09-12T00:25:12.002338: step 3318, loss 1033.97, acc 0.84375\n",
      "2017-09-12T00:25:12.100052: step 3319, loss -3922.95, acc 0.96875\n",
      "2017-09-12T00:25:12.191515: step 3320, loss -891.844, acc 0.9375\n",
      "2017-09-12T00:25:12.284333: step 3321, loss -3869.99, acc 0.96875\n",
      "2017-09-12T00:25:12.528866: step 3322, loss -2953.06, acc 0.9375\n",
      "2017-09-12T00:25:12.693658: step 3323, loss 518.293, acc 0.78125\n",
      "2017-09-12T00:25:12.833122: step 3324, loss -4038.51, acc 0.9375\n",
      "2017-09-12T00:25:13.001819: step 3325, loss -3425.68, acc 0.90625\n",
      "2017-09-12T00:25:13.153951: step 3326, loss -1322.83, acc 1\n",
      "2017-09-12T00:25:13.292370: step 3327, loss -1916.57, acc 0.9375\n",
      "2017-09-12T00:25:13.428719: step 3328, loss -3798.81, acc 0.9375\n",
      "2017-09-12T00:25:13.580447: step 3329, loss -1297.09, acc 0.9375\n",
      "2017-09-12T00:25:13.716046: step 3330, loss -2716.11, acc 1\n",
      "2017-09-12T00:25:13.868345: step 3331, loss -5176, acc 1\n",
      "2017-09-12T00:25:14.017518: step 3332, loss -810.026, acc 0.875\n",
      "2017-09-12T00:25:14.202008: step 3333, loss -2603.3, acc 0.96875\n",
      "2017-09-12T00:25:14.403723: step 3334, loss -1599.7, acc 0.90625\n",
      "2017-09-12T00:25:14.574195: step 3335, loss -4324.29, acc 0.96875\n",
      "2017-09-12T00:25:14.745348: step 3336, loss -2036.06, acc 0.90625\n",
      "2017-09-12T00:25:14.892009: step 3337, loss -5371.02, acc 0.96875\n",
      "2017-09-12T00:25:15.037418: step 3338, loss -6146.43, acc 0.96875\n",
      "2017-09-12T00:25:15.174602: step 3339, loss -3280.94, acc 0.90625\n",
      "2017-09-12T00:25:15.309614: step 3340, loss -776.838, acc 0.9375\n",
      "2017-09-12T00:25:15.456052: step 3341, loss 662.38, acc 0.875\n",
      "2017-09-12T00:25:15.590850: step 3342, loss -6068.69, acc 0.96875\n",
      "2017-09-12T00:25:15.744275: step 3343, loss -1534.81, acc 0.9375\n",
      "2017-09-12T00:25:15.884219: step 3344, loss 1786.66, acc 0.8125\n",
      "2017-09-12T00:25:16.030671: step 3345, loss -1996.5, acc 0.96875\n",
      "2017-09-12T00:25:16.165778: step 3346, loss -2231.83, acc 0.875\n",
      "2017-09-12T00:25:16.314608: step 3347, loss -2867.38, acc 0.9375\n",
      "2017-09-12T00:25:16.460301: step 3348, loss -702.535, acc 0.90625\n",
      "2017-09-12T00:25:16.601801: step 3349, loss -1005.76, acc 0.78125\n",
      "2017-09-12T00:25:16.758113: step 3350, loss -1358.17, acc 0.90625\n",
      "2017-09-12T00:25:16.898786: step 3351, loss -5178.71, acc 1\n",
      "2017-09-12T00:25:17.045648: step 3352, loss -3387.08, acc 0.84375\n",
      "2017-09-12T00:25:17.183359: step 3353, loss 1939.58, acc 0.84375\n",
      "2017-09-12T00:25:17.309923: step 3354, loss -1781.2, acc 0.875\n",
      "2017-09-12T00:25:17.460822: step 3355, loss -5425.52, acc 1\n",
      "2017-09-12T00:25:17.595864: step 3356, loss -18.1806, acc 0.9375\n",
      "2017-09-12T00:25:17.745144: step 3357, loss -2738.57, acc 0.9375\n",
      "2017-09-12T00:25:17.891499: step 3358, loss -1217.51, acc 0.90625\n",
      "2017-09-12T00:25:18.040760: step 3359, loss -6729.79, acc 1\n",
      "2017-09-12T00:25:18.191313: step 3360, loss -3574.48, acc 0.9375\n",
      "2017-09-12T00:25:18.318449: step 3361, loss -1948.16, acc 0.90625\n",
      "2017-09-12T00:25:18.466982: step 3362, loss -4750.72, acc 0.96875\n",
      "2017-09-12T00:25:18.608260: step 3363, loss -3434.43, acc 0.96875\n",
      "2017-09-12T00:25:18.755912: step 3364, loss 562.641, acc 0.875\n",
      "2017-09-12T00:25:18.897897: step 3365, loss -1467.14, acc 0.96875\n",
      "2017-09-12T00:25:19.025998: step 3366, loss -1989.61, acc 0.90625\n",
      "2017-09-12T00:25:19.185597: step 3367, loss -2598.45, acc 0.9375\n",
      "2017-09-12T00:25:19.327361: step 3368, loss 39.0637, acc 0.8125\n",
      "2017-09-12T00:25:19.474644: step 3369, loss -104.032, acc 0.9375\n",
      "2017-09-12T00:25:19.606992: step 3370, loss -1940.59, acc 0.96875\n",
      "2017-09-12T00:25:19.756050: step 3371, loss -802.376, acc 0.96875\n",
      "2017-09-12T00:25:19.890006: step 3372, loss 438.662, acc 0.9375\n",
      "2017-09-12T00:25:20.044075: step 3373, loss -4242.3, acc 0.9375\n",
      "2017-09-12T00:25:20.177717: step 3374, loss -679.182, acc 1\n",
      "2017-09-12T00:25:20.313197: step 3375, loss -3509.62, acc 0.9375\n",
      "2017-09-12T00:25:20.467391: step 3376, loss -6046.97, acc 1\n",
      "2017-09-12T00:25:20.593838: step 3377, loss -3674.67, acc 0.90625\n",
      "2017-09-12T00:25:20.740656: step 3378, loss -1345.49, acc 0.9375\n",
      "2017-09-12T00:25:20.879541: step 3379, loss -3294.51, acc 0.9375\n",
      "2017-09-12T00:25:21.031553: step 3380, loss -1306.05, acc 0.90625\n",
      "2017-09-12T00:25:21.172823: step 3381, loss -2693.99, acc 0.9375\n",
      "2017-09-12T00:25:21.323251: step 3382, loss -2470.6, acc 0.90625\n",
      "2017-09-12T00:25:21.461997: step 3383, loss -2709.79, acc 0.90625\n",
      "2017-09-12T00:25:21.611057: step 3384, loss 783.658, acc 0.90625\n",
      "2017-09-12T00:25:21.766334: step 3385, loss -2746.37, acc 0.90625\n",
      "2017-09-12T00:25:21.906163: step 3386, loss -2138.61, acc 0.9375\n",
      "2017-09-12T00:25:22.058059: step 3387, loss -4081.6, acc 0.96875\n",
      "2017-09-12T00:25:22.200768: step 3388, loss -3338.62, acc 0.90625\n",
      "2017-09-12T00:25:22.346813: step 3389, loss -4104.98, acc 0.9375\n",
      "2017-09-12T00:25:22.486730: step 3390, loss -829.936, acc 0.875\n",
      "2017-09-12T00:25:22.636009: step 3391, loss -5969.78, acc 0.90625\n",
      "2017-09-12T00:25:22.779620: step 3392, loss -3518.03, acc 0.96875\n",
      "2017-09-12T00:25:22.922602: step 3393, loss -2281.67, acc 0.9375\n",
      "2017-09-12T00:25:23.071900: step 3394, loss -2424.43, acc 0.90625\n",
      "2017-09-12T00:25:23.217980: step 3395, loss -1151.04, acc 0.9375\n",
      "2017-09-12T00:25:23.363844: step 3396, loss 2599.9, acc 0.75\n",
      "2017-09-12T00:25:23.505421: step 3397, loss -2198.01, acc 0.9375\n",
      "2017-09-12T00:25:23.653217: step 3398, loss -4052.73, acc 0.90625\n",
      "2017-09-12T00:25:23.814022: step 3399, loss -2929.53, acc 0.9375\n",
      "2017-09-12T00:25:23.956659: step 3400, loss -2912.32, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:25:25.283185: step 3400, loss -2752.09, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3400\n",
      "\n",
      "2017-09-12T00:25:27.753162: step 3401, loss -472.104, acc 0.84375\n",
      "2017-09-12T00:25:27.845137: step 3402, loss -3234.74, acc 0.9375\n",
      "2017-09-12T00:25:27.943601: step 3403, loss -2359.85, acc 0.9375\n",
      "2017-09-12T00:25:28.051369: step 3404, loss -54.6724, acc 0.90625\n",
      "2017-09-12T00:25:28.143121: step 3405, loss 2001.35, acc 0.875\n",
      "2017-09-12T00:25:28.250003: step 3406, loss -1442.09, acc 0.96875\n",
      "2017-09-12T00:25:28.343714: step 3407, loss -3432.89, acc 1\n",
      "2017-09-12T00:25:28.432920: step 3408, loss -136.631, acc 0.90625\n",
      "2017-09-12T00:25:28.529302: step 3409, loss -3283.35, acc 0.90625\n",
      "2017-09-12T00:25:28.646528: step 3410, loss -2809.09, acc 0.9375\n",
      "2017-09-12T00:25:28.782665: step 3411, loss -2366.57, acc 0.9375\n",
      "2017-09-12T00:25:28.889155: step 3412, loss -3234.11, acc 0.875\n",
      "2017-09-12T00:25:29.004652: step 3413, loss -1884.94, acc 1\n",
      "2017-09-12T00:25:29.099597: step 3414, loss -3629.08, acc 0.90625\n",
      "2017-09-12T00:25:29.186983: step 3415, loss -10.9944, acc 0.84375\n",
      "2017-09-12T00:25:29.306256: step 3416, loss -914.609, acc 0.90625\n",
      "2017-09-12T00:25:29.430303: step 3417, loss -3263.76, acc 0.96875\n",
      "2017-09-12T00:25:29.530673: step 3418, loss 1263.59, acc 0.875\n",
      "2017-09-12T00:25:29.579028: step 3419, loss -5969.96, acc 1\n",
      "2017-09-12T00:25:29.862813: step 3420, loss -3958.23, acc 1\n",
      "2017-09-12T00:25:30.039899: step 3421, loss -4130.2, acc 1\n",
      "2017-09-12T00:25:30.183242: step 3422, loss -414.164, acc 0.84375\n",
      "2017-09-12T00:25:30.344333: step 3423, loss -2264.45, acc 0.90625\n",
      "2017-09-12T00:25:30.505374: step 3424, loss -2900.45, acc 0.90625\n",
      "2017-09-12T00:25:30.647804: step 3425, loss -4209.03, acc 0.9375\n",
      "2017-09-12T00:25:30.796177: step 3426, loss -2057.96, acc 0.90625\n",
      "2017-09-12T00:25:30.950555: step 3427, loss -2274.48, acc 0.9375\n",
      "2017-09-12T00:25:31.096849: step 3428, loss -12.0413, acc 0.8125\n",
      "2017-09-12T00:25:31.255597: step 3429, loss -818.971, acc 0.9375\n",
      "2017-09-12T00:25:31.394954: step 3430, loss 977.162, acc 0.78125\n",
      "2017-09-12T00:25:31.563508: step 3431, loss -4999.73, acc 0.96875\n",
      "2017-09-12T00:25:31.713832: step 3432, loss 72.6957, acc 0.875\n",
      "2017-09-12T00:25:31.856884: step 3433, loss -3695.24, acc 0.90625\n",
      "2017-09-12T00:25:32.005644: step 3434, loss -3659.6, acc 0.9375\n",
      "2017-09-12T00:25:32.147366: step 3435, loss -1634.74, acc 0.9375\n",
      "2017-09-12T00:25:32.296726: step 3436, loss -5279.63, acc 0.9375\n",
      "2017-09-12T00:25:32.436615: step 3437, loss -2239.63, acc 0.9375\n",
      "2017-09-12T00:25:32.600675: step 3438, loss -301.604, acc 0.875\n",
      "2017-09-12T00:25:32.747700: step 3439, loss 307.48, acc 0.8125\n",
      "2017-09-12T00:25:32.905326: step 3440, loss -2263.38, acc 0.875\n",
      "2017-09-12T00:25:33.056307: step 3441, loss 25.9791, acc 0.90625\n",
      "2017-09-12T00:25:33.206491: step 3442, loss -3675.1, acc 0.9375\n",
      "2017-09-12T00:25:33.345265: step 3443, loss -781.118, acc 0.9375\n",
      "2017-09-12T00:25:33.479798: step 3444, loss -1517.01, acc 0.875\n",
      "2017-09-12T00:25:33.630704: step 3445, loss -44.5809, acc 0.90625\n",
      "2017-09-12T00:25:33.765764: step 3446, loss -1364.93, acc 0.9375\n",
      "2017-09-12T00:25:33.901446: step 3447, loss -3620.88, acc 0.9375\n",
      "2017-09-12T00:25:34.066308: step 3448, loss -2090.69, acc 0.875\n",
      "2017-09-12T00:25:34.213588: step 3449, loss -2647.59, acc 0.96875\n",
      "2017-09-12T00:25:34.347260: step 3450, loss -3671.8, acc 0.96875\n",
      "2017-09-12T00:25:34.480132: step 3451, loss -3643.62, acc 0.9375\n",
      "2017-09-12T00:25:34.630060: step 3452, loss -2127.28, acc 0.875\n",
      "2017-09-12T00:25:34.816252: step 3453, loss -1794.62, acc 0.84375\n",
      "2017-09-12T00:25:34.989088: step 3454, loss -1712.46, acc 0.875\n",
      "2017-09-12T00:25:35.134326: step 3455, loss -2243.91, acc 0.96875\n",
      "2017-09-12T00:25:35.266021: step 3456, loss -659.667, acc 0.875\n",
      "2017-09-12T00:25:35.415169: step 3457, loss -3447.9, acc 0.9375\n",
      "2017-09-12T00:25:35.566017: step 3458, loss -6672.25, acc 0.9375\n",
      "2017-09-12T00:25:35.703255: step 3459, loss -5175.06, acc 0.96875\n",
      "2017-09-12T00:25:35.848006: step 3460, loss -2356.83, acc 0.90625\n",
      "2017-09-12T00:25:36.004599: step 3461, loss -692.878, acc 0.90625\n",
      "2017-09-12T00:25:36.145021: step 3462, loss -1555.83, acc 0.9375\n",
      "2017-09-12T00:25:36.293761: step 3463, loss -5485.62, acc 0.96875\n",
      "2017-09-12T00:25:36.426643: step 3464, loss -4252.19, acc 0.9375\n",
      "2017-09-12T00:25:36.572171: step 3465, loss -1898.28, acc 0.90625\n",
      "2017-09-12T00:25:36.703937: step 3466, loss -832.766, acc 0.9375\n",
      "2017-09-12T00:25:36.847731: step 3467, loss -1460.26, acc 0.875\n",
      "2017-09-12T00:25:37.001670: step 3468, loss -1636.15, acc 0.9375\n",
      "2017-09-12T00:25:37.150350: step 3469, loss -3928.91, acc 0.90625\n",
      "2017-09-12T00:25:37.292212: step 3470, loss -2070.49, acc 0.84375\n",
      "2017-09-12T00:25:37.451233: step 3471, loss 2078.33, acc 0.875\n",
      "2017-09-12T00:25:37.585121: step 3472, loss -4040.49, acc 0.96875\n",
      "2017-09-12T00:25:37.740895: step 3473, loss -3848.62, acc 0.96875\n",
      "2017-09-12T00:25:37.877793: step 3474, loss -4274.4, acc 0.96875\n",
      "2017-09-12T00:25:38.017319: step 3475, loss -3757.53, acc 0.90625\n",
      "2017-09-12T00:25:38.158481: step 3476, loss -4390.35, acc 1\n",
      "2017-09-12T00:25:38.317602: step 3477, loss -980.271, acc 0.9375\n",
      "2017-09-12T00:25:38.456187: step 3478, loss -6088.32, acc 0.90625\n",
      "2017-09-12T00:25:38.600624: step 3479, loss -983.966, acc 0.90625\n",
      "2017-09-12T00:25:38.749177: step 3480, loss -324.491, acc 0.84375\n",
      "2017-09-12T00:25:38.899917: step 3481, loss -1474.33, acc 0.9375\n",
      "2017-09-12T00:25:39.039573: step 3482, loss -841.936, acc 0.875\n",
      "2017-09-12T00:25:39.181865: step 3483, loss -4365.41, acc 0.96875\n",
      "2017-09-12T00:25:39.321308: step 3484, loss -4444.47, acc 0.9375\n",
      "2017-09-12T00:25:39.468969: step 3485, loss 2691.88, acc 0.8125\n",
      "2017-09-12T00:25:39.602337: step 3486, loss -79.5657, acc 0.84375\n",
      "2017-09-12T00:25:39.757006: step 3487, loss -1961.47, acc 0.9375\n",
      "2017-09-12T00:25:39.898247: step 3488, loss -54.3228, acc 0.875\n",
      "2017-09-12T00:25:40.056431: step 3489, loss -664.066, acc 0.9375\n",
      "2017-09-12T00:25:40.202086: step 3490, loss -4367.66, acc 0.9375\n",
      "2017-09-12T00:25:40.366776: step 3491, loss -2448.86, acc 0.9375\n",
      "2017-09-12T00:25:40.504557: step 3492, loss -820.068, acc 0.90625\n",
      "2017-09-12T00:25:40.650090: step 3493, loss -2796.75, acc 0.9375\n",
      "2017-09-12T00:25:40.790221: step 3494, loss -4631.44, acc 0.9375\n",
      "2017-09-12T00:25:40.927197: step 3495, loss -2521.86, acc 0.9375\n",
      "2017-09-12T00:25:41.073463: step 3496, loss -3614.73, acc 1\n",
      "2017-09-12T00:25:41.214458: step 3497, loss -9795.78, acc 0.96875\n",
      "2017-09-12T00:25:41.343031: step 3498, loss -3292.16, acc 0.9375\n",
      "2017-09-12T00:25:41.491594: step 3499, loss -4420.86, acc 0.9375\n",
      "2017-09-12T00:25:41.630147: step 3500, loss -2382.95, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:25:42.978895: step 3500, loss -2939.56, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3500\n",
      "\n",
      "2017-09-12T00:25:44.758557: step 3501, loss -4884.17, acc 1\n",
      "2017-09-12T00:25:44.868276: step 3502, loss -3783.91, acc 0.9375\n",
      "2017-09-12T00:25:44.969182: step 3503, loss -785.544, acc 0.90625\n",
      "2017-09-12T00:25:45.064088: step 3504, loss 692.495, acc 0.9375\n",
      "2017-09-12T00:25:45.166845: step 3505, loss -3555.11, acc 0.9375\n",
      "2017-09-12T00:25:45.275340: step 3506, loss -3122.27, acc 0.90625\n",
      "2017-09-12T00:25:45.382579: step 3507, loss -787.938, acc 0.875\n",
      "2017-09-12T00:25:45.477538: step 3508, loss -3102.32, acc 0.96875\n",
      "2017-09-12T00:25:45.577392: step 3509, loss -2450.29, acc 0.90625\n",
      "2017-09-12T00:25:45.682181: step 3510, loss -3716.26, acc 0.96875\n",
      "2017-09-12T00:25:45.769766: step 3511, loss -3547.06, acc 0.875\n",
      "2017-09-12T00:25:45.864857: step 3512, loss -2093.9, acc 0.96875\n",
      "2017-09-12T00:25:45.974105: step 3513, loss -39.4119, acc 0.9375\n",
      "2017-09-12T00:25:46.080211: step 3514, loss -1424.34, acc 0.9375\n",
      "2017-09-12T00:25:46.174348: step 3515, loss -851.845, acc 0.875\n",
      "2017-09-12T00:25:46.302399: step 3516, loss -1554.03, acc 0.9375\n",
      "2017-09-12T00:25:46.398609: step 3517, loss -2932.11, acc 0.96875\n",
      "2017-09-12T00:25:46.487668: step 3518, loss -2395.68, acc 0.96875\n",
      "2017-09-12T00:25:46.581088: step 3519, loss -851.837, acc 0.9375\n",
      "2017-09-12T00:25:46.667576: step 3520, loss -362.764, acc 0.84375\n",
      "2017-09-12T00:25:46.899864: step 3521, loss -2424.68, acc 0.90625\n",
      "2017-09-12T00:25:47.117126: step 3522, loss 2182.73, acc 0.90625\n",
      "2017-09-12T00:25:47.291288: step 3523, loss -1552.75, acc 0.90625\n",
      "2017-09-12T00:25:47.428201: step 3524, loss -2512.06, acc 0.9375\n",
      "2017-09-12T00:25:47.579492: step 3525, loss -3962.54, acc 0.96875\n",
      "2017-09-12T00:25:47.728563: step 3526, loss 2043.16, acc 0.90625\n",
      "2017-09-12T00:25:47.871784: step 3527, loss -3912.33, acc 0.90625\n",
      "2017-09-12T00:25:48.017855: step 3528, loss -3172.48, acc 0.90625\n",
      "2017-09-12T00:25:48.170442: step 3529, loss -2913.75, acc 0.9375\n",
      "2017-09-12T00:25:48.300376: step 3530, loss -3029.24, acc 1\n",
      "2017-09-12T00:25:48.453524: step 3531, loss -3639.86, acc 0.9375\n",
      "2017-09-12T00:25:48.593927: step 3532, loss -5539.78, acc 0.90625\n",
      "2017-09-12T00:25:48.745815: step 3533, loss -1434.24, acc 0.9375\n",
      "2017-09-12T00:25:48.894239: step 3534, loss -1470.03, acc 0.96875\n",
      "2017-09-12T00:25:49.046319: step 3535, loss -4588.56, acc 1\n",
      "2017-09-12T00:25:49.195717: step 3536, loss -2524.02, acc 0.90625\n",
      "2017-09-12T00:25:49.335797: step 3537, loss -2931.7, acc 0.90625\n",
      "2017-09-12T00:25:49.494378: step 3538, loss -5160.94, acc 0.96875\n",
      "2017-09-12T00:25:49.670334: step 3539, loss -4705.16, acc 1\n",
      "2017-09-12T00:25:49.817971: step 3540, loss -3792.12, acc 0.96875\n",
      "2017-09-12T00:25:49.963454: step 3541, loss -3197.32, acc 0.9375\n",
      "2017-09-12T00:25:50.108240: step 3542, loss -4610.52, acc 0.9375\n",
      "2017-09-12T00:25:50.292257: step 3543, loss 588.302, acc 0.90625\n",
      "2017-09-12T00:25:50.424825: step 3544, loss -3098.54, acc 0.9375\n",
      "2017-09-12T00:25:50.590739: step 3545, loss -3249.32, acc 0.9375\n",
      "2017-09-12T00:25:50.726363: step 3546, loss -4880.26, acc 0.90625\n",
      "2017-09-12T00:25:50.887092: step 3547, loss -4444.37, acc 1\n",
      "2017-09-12T00:25:51.024359: step 3548, loss -3362.73, acc 0.90625\n",
      "2017-09-12T00:25:51.166712: step 3549, loss -2809.49, acc 0.90625\n",
      "2017-09-12T00:25:51.314142: step 3550, loss -236.075, acc 0.84375\n",
      "2017-09-12T00:25:51.452651: step 3551, loss -2373.3, acc 0.96875\n",
      "2017-09-12T00:25:51.605559: step 3552, loss -5228.66, acc 0.96875\n",
      "2017-09-12T00:25:51.749680: step 3553, loss -5779.65, acc 0.96875\n",
      "2017-09-12T00:25:51.890056: step 3554, loss -3180.74, acc 0.9375\n",
      "2017-09-12T00:25:52.025097: step 3555, loss -3511.93, acc 0.84375\n",
      "2017-09-12T00:25:52.187904: step 3556, loss -1435.6, acc 0.90625\n",
      "2017-09-12T00:25:52.328546: step 3557, loss -3252.76, acc 0.90625\n",
      "2017-09-12T00:25:52.468977: step 3558, loss -2622.4, acc 0.9375\n",
      "2017-09-12T00:25:52.626355: step 3559, loss -4851.08, acc 1\n",
      "2017-09-12T00:25:52.772459: step 3560, loss 540.894, acc 0.875\n",
      "2017-09-12T00:25:52.918936: step 3561, loss -866.124, acc 0.90625\n",
      "2017-09-12T00:25:53.073316: step 3562, loss -1339, acc 0.875\n",
      "2017-09-12T00:25:53.215374: step 3563, loss -4072.01, acc 0.96875\n",
      "2017-09-12T00:25:53.382449: step 3564, loss -10228, acc 0.96875\n",
      "2017-09-12T00:25:53.514161: step 3565, loss -3099.2, acc 1\n",
      "2017-09-12T00:25:53.653934: step 3566, loss -1567.39, acc 0.9375\n",
      "2017-09-12T00:25:53.800099: step 3567, loss -3879.89, acc 0.96875\n",
      "2017-09-12T00:25:53.934418: step 3568, loss -706.578, acc 0.9375\n",
      "2017-09-12T00:25:54.109736: step 3569, loss -4001.37, acc 1\n",
      "2017-09-12T00:25:54.262420: step 3570, loss 739.776, acc 0.9375\n",
      "2017-09-12T00:25:54.400767: step 3571, loss -7817.85, acc 0.96875\n",
      "2017-09-12T00:25:54.542069: step 3572, loss -6053.09, acc 0.96875\n",
      "2017-09-12T00:25:54.693231: step 3573, loss -819.689, acc 0.875\n",
      "2017-09-12T00:25:54.847804: step 3574, loss 2074.51, acc 0.8125\n",
      "2017-09-12T00:25:54.972180: step 3575, loss -706.644, acc 0.90625\n",
      "2017-09-12T00:25:55.123497: step 3576, loss -6080.24, acc 0.9375\n",
      "2017-09-12T00:25:55.269776: step 3577, loss -839.358, acc 0.96875\n",
      "2017-09-12T00:25:55.400675: step 3578, loss -93.4343, acc 0.8125\n",
      "2017-09-12T00:25:55.558839: step 3579, loss 632.062, acc 0.9375\n",
      "2017-09-12T00:25:55.690538: step 3580, loss -1488.62, acc 0.84375\n",
      "2017-09-12T00:25:55.854313: step 3581, loss -162.65, acc 0.9375\n",
      "2017-09-12T00:25:56.009469: step 3582, loss -8072.09, acc 0.96875\n",
      "2017-09-12T00:25:56.151097: step 3583, loss -2970.89, acc 0.9375\n",
      "2017-09-12T00:25:56.297306: step 3584, loss -214.128, acc 0.84375\n",
      "2017-09-12T00:25:56.439066: step 3585, loss -5632.41, acc 1\n",
      "2017-09-12T00:25:56.587103: step 3586, loss -4183.93, acc 1\n",
      "2017-09-12T00:25:56.729451: step 3587, loss -1080.19, acc 0.875\n",
      "2017-09-12T00:25:56.868823: step 3588, loss -5954.68, acc 0.90625\n",
      "2017-09-12T00:25:57.019161: step 3589, loss -23.3043, acc 0.90625\n",
      "2017-09-12T00:25:57.162322: step 3590, loss -2455.73, acc 0.84375\n",
      "2017-09-12T00:25:57.291871: step 3591, loss -3360.4, acc 0.96875\n",
      "2017-09-12T00:25:57.440042: step 3592, loss -2383.31, acc 0.90625\n",
      "2017-09-12T00:25:57.596746: step 3593, loss -5325.44, acc 1\n",
      "2017-09-12T00:25:57.734373: step 3594, loss -5057.14, acc 0.9375\n",
      "2017-09-12T00:25:57.873954: step 3595, loss -4397.19, acc 0.96875\n",
      "2017-09-12T00:25:58.012127: step 3596, loss -4761.5, acc 0.875\n",
      "2017-09-12T00:25:58.160720: step 3597, loss -3887.73, acc 0.96875\n",
      "2017-09-12T00:25:58.301857: step 3598, loss -953.704, acc 0.84375\n",
      "2017-09-12T00:25:58.443683: step 3599, loss -5909.58, acc 0.96875\n",
      "2017-09-12T00:25:58.591068: step 3600, loss -2507.98, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:25:59.870596: step 3600, loss -3160.89, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3600\n",
      "\n",
      "2017-09-12T00:26:01.943773: step 3601, loss -1725.82, acc 0.90625\n",
      "2017-09-12T00:26:02.039568: step 3602, loss -844.7, acc 0.90625\n",
      "2017-09-12T00:26:02.128931: step 3603, loss -4759.04, acc 0.96875\n",
      "2017-09-12T00:26:02.217305: step 3604, loss -4134.49, acc 1\n",
      "2017-09-12T00:26:02.309446: step 3605, loss -4776.25, acc 0.96875\n",
      "2017-09-12T00:26:02.408283: step 3606, loss -2136.93, acc 0.96875\n",
      "2017-09-12T00:26:02.512810: step 3607, loss -1651.58, acc 0.90625\n",
      "2017-09-12T00:26:02.594628: step 3608, loss -1445.19, acc 0.90625\n",
      "2017-09-12T00:26:02.681108: step 3609, loss -4981.53, acc 0.96875\n",
      "2017-09-12T00:26:02.769295: step 3610, loss -3066.19, acc 0.9375\n",
      "2017-09-12T00:26:02.858412: step 3611, loss -579.019, acc 0.90625\n",
      "2017-09-12T00:26:02.947309: step 3612, loss -2368.16, acc 0.90625\n",
      "2017-09-12T00:26:03.038560: step 3613, loss -1089.24, acc 0.90625\n",
      "2017-09-12T00:26:03.129581: step 3614, loss -2640.08, acc 0.96875\n",
      "2017-09-12T00:26:03.217166: step 3615, loss -1878.27, acc 0.84375\n",
      "2017-09-12T00:26:03.306864: step 3616, loss -865.149, acc 0.96875\n",
      "2017-09-12T00:26:03.399866: step 3617, loss -867.049, acc 0.875\n",
      "2017-09-12T00:26:03.488526: step 3618, loss -3949.74, acc 0.90625\n",
      "2017-09-12T00:26:03.598624: step 3619, loss -2650.89, acc 0.90625\n",
      "2017-09-12T00:26:03.867468: step 3620, loss -5869.96, acc 0.90625\n",
      "2017-09-12T00:26:04.011248: step 3621, loss -3385.34, acc 0.96875\n",
      "2017-09-12T00:26:04.126276: step 3622, loss -2422.99, acc 0.90625\n",
      "2017-09-12T00:26:04.255922: step 3623, loss -1588.98, acc 0.875\n",
      "2017-09-12T00:26:04.402578: step 3624, loss -6256.02, acc 0.90625\n",
      "2017-09-12T00:26:04.542371: step 3625, loss -4279.2, acc 0.96875\n",
      "2017-09-12T00:26:04.705833: step 3626, loss -1649.45, acc 0.9375\n",
      "2017-09-12T00:26:04.848730: step 3627, loss -765.966, acc 0.875\n",
      "2017-09-12T00:26:04.985768: step 3628, loss -2491.11, acc 0.875\n",
      "2017-09-12T00:26:05.135315: step 3629, loss -4726.48, acc 1\n",
      "2017-09-12T00:26:05.275353: step 3630, loss -728.087, acc 1\n",
      "2017-09-12T00:26:05.427077: step 3631, loss -3319.86, acc 0.96875\n",
      "2017-09-12T00:26:05.567098: step 3632, loss -3260.45, acc 0.9375\n",
      "2017-09-12T00:26:05.704781: step 3633, loss -7446.45, acc 0.96875\n",
      "2017-09-12T00:26:05.857337: step 3634, loss 200.182, acc 0.875\n",
      "2017-09-12T00:26:06.003918: step 3635, loss -880.918, acc 0.90625\n",
      "2017-09-12T00:26:06.158781: step 3636, loss -4058.9, acc 0.9375\n",
      "2017-09-12T00:26:06.294151: step 3637, loss -3166.81, acc 0.96875\n",
      "2017-09-12T00:26:06.438160: step 3638, loss -2648.55, acc 0.96875\n",
      "2017-09-12T00:26:06.579031: step 3639, loss -8085.32, acc 1\n",
      "2017-09-12T00:26:06.716443: step 3640, loss -1803.6, acc 0.875\n",
      "2017-09-12T00:26:06.862200: step 3641, loss -8177.76, acc 0.90625\n",
      "2017-09-12T00:26:07.011942: step 3642, loss -3185.16, acc 0.9375\n",
      "2017-09-12T00:26:07.163629: step 3643, loss -2297.98, acc 0.9375\n",
      "2017-09-12T00:26:07.308780: step 3644, loss -2757.04, acc 0.90625\n",
      "2017-09-12T00:26:07.454723: step 3645, loss -1594.01, acc 0.9375\n",
      "2017-09-12T00:26:07.580236: step 3646, loss -4109.56, acc 0.96875\n",
      "2017-09-12T00:26:07.735617: step 3647, loss -2160.41, acc 0.90625\n",
      "2017-09-12T00:26:07.877052: step 3648, loss -5008.34, acc 0.9375\n",
      "2017-09-12T00:26:08.018310: step 3649, loss -3297.64, acc 0.96875\n",
      "2017-09-12T00:26:08.175687: step 3650, loss -2496.79, acc 0.9375\n",
      "2017-09-12T00:26:08.308391: step 3651, loss -4185.09, acc 0.9375\n",
      "2017-09-12T00:26:08.461559: step 3652, loss -4020.92, acc 0.96875\n",
      "2017-09-12T00:26:08.577986: step 3653, loss -399.188, acc 0.84375\n",
      "2017-09-12T00:26:08.746085: step 3654, loss 561.576, acc 0.84375\n",
      "2017-09-12T00:26:08.898022: step 3655, loss -2451.02, acc 0.90625\n",
      "2017-09-12T00:26:09.046571: step 3656, loss -4961.95, acc 0.90625\n",
      "2017-09-12T00:26:09.189284: step 3657, loss -3175.64, acc 0.9375\n",
      "2017-09-12T00:26:09.313610: step 3658, loss -1626.03, acc 0.90625\n",
      "2017-09-12T00:26:09.465619: step 3659, loss -3520.56, acc 0.90625\n",
      "2017-09-12T00:26:09.613520: step 3660, loss -3382.81, acc 1\n",
      "2017-09-12T00:26:09.757410: step 3661, loss -862.609, acc 0.875\n",
      "2017-09-12T00:26:09.913428: step 3662, loss -2686.3, acc 0.875\n",
      "2017-09-12T00:26:10.052500: step 3663, loss -5186.63, acc 0.875\n",
      "2017-09-12T00:26:10.198130: step 3664, loss -3096.73, acc 0.875\n",
      "2017-09-12T00:26:10.339437: step 3665, loss -3505.19, acc 0.96875\n",
      "2017-09-12T00:26:10.479200: step 3666, loss -7592.96, acc 0.96875\n",
      "2017-09-12T00:26:10.624543: step 3667, loss -2698.33, acc 0.96875\n",
      "2017-09-12T00:26:10.789213: step 3668, loss -909.081, acc 0.9375\n",
      "2017-09-12T00:26:10.925985: step 3669, loss -2630.13, acc 0.96875\n",
      "2017-09-12T00:26:11.080985: step 3670, loss -2595.98, acc 0.9375\n",
      "2017-09-12T00:26:11.207860: step 3671, loss -3441.05, acc 0.9375\n",
      "2017-09-12T00:26:11.365246: step 3672, loss -795.053, acc 0.9375\n",
      "2017-09-12T00:26:11.501145: step 3673, loss 1685.78, acc 0.84375\n",
      "2017-09-12T00:26:11.650667: step 3674, loss -1201.62, acc 0.90625\n",
      "2017-09-12T00:26:11.805785: step 3675, loss -3379.65, acc 0.9375\n",
      "2017-09-12T00:26:11.943043: step 3676, loss -1491.91, acc 0.84375\n",
      "2017-09-12T00:26:12.095351: step 3677, loss -217.919, acc 0.84375\n",
      "2017-09-12T00:26:12.239361: step 3678, loss -2373.74, acc 0.90625\n",
      "2017-09-12T00:26:12.378755: step 3679, loss -5144.08, acc 0.96875\n",
      "2017-09-12T00:26:12.520864: step 3680, loss -1871.09, acc 0.96875\n",
      "2017-09-12T00:26:12.667650: step 3681, loss -3986.29, acc 0.96875\n",
      "2017-09-12T00:26:12.718222: step 3682, loss -6270.98, acc 1\n",
      "2017-09-12T00:26:12.878551: step 3683, loss -4586.83, acc 0.9375\n",
      "2017-09-12T00:26:13.017523: step 3684, loss -3295.01, acc 1\n",
      "2017-09-12T00:26:13.158691: step 3685, loss -4682.32, acc 1\n",
      "2017-09-12T00:26:13.308637: step 3686, loss -7604.17, acc 1\n",
      "2017-09-12T00:26:13.447199: step 3687, loss -5598.39, acc 1\n",
      "2017-09-12T00:26:13.588105: step 3688, loss -2890.02, acc 0.96875\n",
      "2017-09-12T00:26:13.737110: step 3689, loss -2862.59, acc 0.90625\n",
      "2017-09-12T00:26:13.881144: step 3690, loss -5866.39, acc 1\n",
      "2017-09-12T00:26:14.024903: step 3691, loss -4769.37, acc 0.9375\n",
      "2017-09-12T00:26:14.163856: step 3692, loss 613.488, acc 0.875\n",
      "2017-09-12T00:26:14.302208: step 3693, loss -3671.36, acc 0.96875\n",
      "2017-09-12T00:26:14.448198: step 3694, loss -2493.23, acc 0.96875\n",
      "2017-09-12T00:26:14.593355: step 3695, loss -1165.87, acc 0.90625\n",
      "2017-09-12T00:26:14.739989: step 3696, loss -5615.55, acc 0.9375\n",
      "2017-09-12T00:26:14.880187: step 3697, loss -96.0002, acc 0.84375\n",
      "2017-09-12T00:26:15.018295: step 3698, loss -1743.91, acc 0.90625\n",
      "2017-09-12T00:26:15.165445: step 3699, loss -5167.16, acc 0.90625\n",
      "2017-09-12T00:26:15.313536: step 3700, loss -366.558, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:26:16.582608: step 3700, loss -3397.15, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3700\n",
      "\n",
      "2017-09-12T00:26:18.491088: step 3701, loss -1948.13, acc 0.96875\n",
      "2017-09-12T00:26:18.583082: step 3702, loss -1507.09, acc 0.90625\n",
      "2017-09-12T00:26:18.681548: step 3703, loss -3169, acc 0.90625\n",
      "2017-09-12T00:26:18.781932: step 3704, loss -3292.68, acc 0.96875\n",
      "2017-09-12T00:26:18.867631: step 3705, loss -5213.87, acc 1\n",
      "2017-09-12T00:26:18.959851: step 3706, loss -4633.29, acc 0.96875\n",
      "2017-09-12T00:26:19.049005: step 3707, loss -2013.41, acc 0.9375\n",
      "2017-09-12T00:26:19.140551: step 3708, loss 1595.06, acc 0.84375\n",
      "2017-09-12T00:26:19.233684: step 3709, loss -2010.32, acc 0.90625\n",
      "2017-09-12T00:26:19.322931: step 3710, loss -987.093, acc 0.90625\n",
      "2017-09-12T00:26:19.433020: step 3711, loss -2450.37, acc 0.9375\n",
      "2017-09-12T00:26:19.518763: step 3712, loss -2454.85, acc 0.90625\n",
      "2017-09-12T00:26:19.608970: step 3713, loss 646.251, acc 0.875\n",
      "2017-09-12T00:26:19.700413: step 3714, loss 754.118, acc 0.8125\n",
      "2017-09-12T00:26:19.794502: step 3715, loss -2831.71, acc 0.875\n",
      "2017-09-12T00:26:20.090184: step 3716, loss -3685.19, acc 0.9375\n",
      "2017-09-12T00:26:20.239691: step 3717, loss 85.8864, acc 0.96875\n",
      "2017-09-12T00:26:20.431860: step 3718, loss -2148.23, acc 0.90625\n",
      "2017-09-12T00:26:20.576704: step 3719, loss -6191.94, acc 0.96875\n",
      "2017-09-12T00:26:20.727134: step 3720, loss -1687.82, acc 0.96875\n",
      "2017-09-12T00:26:20.872327: step 3721, loss -1978, acc 0.90625\n",
      "2017-09-12T00:26:21.015861: step 3722, loss -2787.97, acc 0.90625\n",
      "2017-09-12T00:26:21.174038: step 3723, loss -229.777, acc 0.90625\n",
      "2017-09-12T00:26:21.323125: step 3724, loss -3822.22, acc 0.90625\n",
      "2017-09-12T00:26:21.467099: step 3725, loss -3642.06, acc 0.9375\n",
      "2017-09-12T00:26:21.612064: step 3726, loss -3603.99, acc 0.9375\n",
      "2017-09-12T00:26:21.755359: step 3727, loss -6332.85, acc 0.875\n",
      "2017-09-12T00:26:21.893630: step 3728, loss -5846.43, acc 0.9375\n",
      "2017-09-12T00:26:22.039424: step 3729, loss -11405, acc 0.96875\n",
      "2017-09-12T00:26:22.185382: step 3730, loss -1633.72, acc 0.9375\n",
      "2017-09-12T00:26:22.323592: step 3731, loss -4319.13, acc 0.90625\n",
      "2017-09-12T00:26:22.463610: step 3732, loss 2628.88, acc 0.84375\n",
      "2017-09-12T00:26:22.605957: step 3733, loss -2487.68, acc 0.9375\n",
      "2017-09-12T00:26:22.751696: step 3734, loss -2816.69, acc 0.90625\n",
      "2017-09-12T00:26:22.909226: step 3735, loss -4355.21, acc 0.9375\n",
      "2017-09-12T00:26:23.048535: step 3736, loss -1745.14, acc 0.9375\n",
      "2017-09-12T00:26:23.201007: step 3737, loss -2581.72, acc 0.96875\n",
      "2017-09-12T00:26:23.347228: step 3738, loss 1611.39, acc 0.84375\n",
      "2017-09-12T00:26:23.482846: step 3739, loss -4729.2, acc 0.9375\n",
      "2017-09-12T00:26:23.622917: step 3740, loss -1995.72, acc 0.90625\n",
      "2017-09-12T00:26:23.776261: step 3741, loss -134.737, acc 0.875\n",
      "2017-09-12T00:26:23.914320: step 3742, loss 5063.98, acc 0.71875\n",
      "2017-09-12T00:26:24.062112: step 3743, loss -1631.16, acc 0.84375\n",
      "2017-09-12T00:26:24.213879: step 3744, loss -2838.32, acc 0.9375\n",
      "2017-09-12T00:26:24.357555: step 3745, loss -2733.12, acc 0.9375\n",
      "2017-09-12T00:26:24.505780: step 3746, loss -912.966, acc 0.9375\n",
      "2017-09-12T00:26:24.656726: step 3747, loss -3647.62, acc 0.90625\n",
      "2017-09-12T00:26:24.799355: step 3748, loss -5397.92, acc 0.96875\n",
      "2017-09-12T00:26:24.935585: step 3749, loss 816.686, acc 0.78125\n",
      "2017-09-12T00:26:25.092002: step 3750, loss -3941.43, acc 0.90625\n",
      "2017-09-12T00:26:25.236085: step 3751, loss -898.789, acc 0.84375\n",
      "2017-09-12T00:26:25.388346: step 3752, loss -3590.41, acc 0.90625\n",
      "2017-09-12T00:26:25.534528: step 3753, loss -1906.79, acc 0.9375\n",
      "2017-09-12T00:26:25.687827: step 3754, loss -2404.55, acc 0.875\n",
      "2017-09-12T00:26:25.828653: step 3755, loss -3612.64, acc 0.9375\n",
      "2017-09-12T00:26:25.974979: step 3756, loss -2448.96, acc 0.9375\n",
      "2017-09-12T00:26:26.092282: step 3757, loss -2595.78, acc 0.90625\n",
      "2017-09-12T00:26:26.247943: step 3758, loss -3528.68, acc 0.9375\n",
      "2017-09-12T00:26:26.386421: step 3759, loss -6316.83, acc 0.96875\n",
      "2017-09-12T00:26:26.533115: step 3760, loss -5262.5, acc 0.96875\n",
      "2017-09-12T00:26:26.676763: step 3761, loss -5942.75, acc 1\n",
      "2017-09-12T00:26:26.822580: step 3762, loss -4797.38, acc 1\n",
      "2017-09-12T00:26:26.968663: step 3763, loss -7048.06, acc 0.96875\n",
      "2017-09-12T00:26:27.112352: step 3764, loss -5360.63, acc 1\n",
      "2017-09-12T00:26:27.254217: step 3765, loss -4558.1, acc 0.875\n",
      "2017-09-12T00:26:27.392590: step 3766, loss -5379.6, acc 0.96875\n",
      "2017-09-12T00:26:27.542474: step 3767, loss -2840.37, acc 0.875\n",
      "2017-09-12T00:26:27.708343: step 3768, loss -1955.5, acc 0.875\n",
      "2017-09-12T00:26:27.856773: step 3769, loss -3614.19, acc 1\n",
      "2017-09-12T00:26:27.991182: step 3770, loss -2146.32, acc 0.9375\n",
      "2017-09-12T00:26:28.131617: step 3771, loss 1704.41, acc 0.84375\n",
      "2017-09-12T00:26:28.286567: step 3772, loss -8368.92, acc 1\n",
      "2017-09-12T00:26:28.421215: step 3773, loss -4788.01, acc 0.96875\n",
      "2017-09-12T00:26:28.572269: step 3774, loss -863.124, acc 0.875\n",
      "2017-09-12T00:26:28.714440: step 3775, loss -1547.44, acc 0.90625\n",
      "2017-09-12T00:26:28.855546: step 3776, loss -4128.17, acc 0.96875\n",
      "2017-09-12T00:26:29.016826: step 3777, loss -4117.59, acc 0.90625\n",
      "2017-09-12T00:26:29.154303: step 3778, loss -225.687, acc 0.875\n",
      "2017-09-12T00:26:29.309598: step 3779, loss -1916.34, acc 0.96875\n",
      "2017-09-12T00:26:29.456564: step 3780, loss -203.507, acc 0.9375\n",
      "2017-09-12T00:26:29.603403: step 3781, loss -3852.5, acc 0.96875\n",
      "2017-09-12T00:26:29.758907: step 3782, loss -975.182, acc 0.875\n",
      "2017-09-12T00:26:29.888841: step 3783, loss -3631.48, acc 0.90625\n",
      "2017-09-12T00:26:30.037311: step 3784, loss -6616.73, acc 0.9375\n",
      "2017-09-12T00:26:30.181444: step 3785, loss -3624.07, acc 0.84375\n",
      "2017-09-12T00:26:30.338036: step 3786, loss -3804.84, acc 0.9375\n",
      "2017-09-12T00:26:30.496932: step 3787, loss -96.0973, acc 0.90625\n",
      "2017-09-12T00:26:30.655726: step 3788, loss -5435.98, acc 0.96875\n",
      "2017-09-12T00:26:30.800475: step 3789, loss -4602.34, acc 0.96875\n",
      "2017-09-12T00:26:30.939562: step 3790, loss -6682.5, acc 0.96875\n",
      "2017-09-12T00:26:31.089989: step 3791, loss -7259.56, acc 0.96875\n",
      "2017-09-12T00:26:31.232743: step 3792, loss -5133.73, acc 0.96875\n",
      "2017-09-12T00:26:31.374107: step 3793, loss -6386.09, acc 0.875\n",
      "2017-09-12T00:26:31.517506: step 3794, loss -4649.66, acc 0.96875\n",
      "2017-09-12T00:26:31.668084: step 3795, loss -2854.36, acc 0.9375\n",
      "2017-09-12T00:26:31.810970: step 3796, loss -3309.71, acc 0.90625\n",
      "2017-09-12T00:26:31.961527: step 3797, loss -6224.62, acc 0.96875\n",
      "2017-09-12T00:26:32.106159: step 3798, loss -2023.27, acc 0.90625\n",
      "2017-09-12T00:26:32.262089: step 3799, loss -2691.76, acc 0.9375\n",
      "2017-09-12T00:26:32.400080: step 3800, loss -1175.61, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:26:33.649873: step 3800, loss -3620.47, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3800\n",
      "\n",
      "2017-09-12T00:26:35.105952: step 3801, loss -3714.8, acc 1\n",
      "2017-09-12T00:26:35.196228: step 3802, loss -3788.05, acc 0.96875\n",
      "2017-09-12T00:26:35.288289: step 3803, loss -3980.76, acc 0.9375\n",
      "2017-09-12T00:26:35.397230: step 3804, loss -2926.47, acc 0.96875\n",
      "2017-09-12T00:26:35.496502: step 3805, loss -2398.79, acc 0.9375\n",
      "2017-09-12T00:26:35.591132: step 3806, loss -3148.65, acc 0.9375\n",
      "2017-09-12T00:26:35.680850: step 3807, loss -63.2134, acc 0.875\n",
      "2017-09-12T00:26:35.769874: step 3808, loss -373.709, acc 0.90625\n",
      "2017-09-12T00:26:35.857641: step 3809, loss -5356.94, acc 1\n",
      "2017-09-12T00:26:35.950709: step 3810, loss -2969.86, acc 0.875\n",
      "2017-09-12T00:26:36.039564: step 3811, loss -1126.2, acc 0.90625\n",
      "2017-09-12T00:26:36.128732: step 3812, loss -3839.43, acc 1\n",
      "2017-09-12T00:26:36.220296: step 3813, loss -568.955, acc 0.875\n",
      "2017-09-12T00:26:36.310825: step 3814, loss -950.753, acc 0.875\n",
      "2017-09-12T00:26:36.401810: step 3815, loss -9324.35, acc 0.96875\n",
      "2017-09-12T00:26:36.492969: step 3816, loss -1235.15, acc 0.9375\n",
      "2017-09-12T00:26:36.582879: step 3817, loss -1820.17, acc 0.9375\n",
      "2017-09-12T00:26:36.672528: step 3818, loss -2096.85, acc 0.90625\n",
      "2017-09-12T00:26:36.787557: step 3819, loss -1803.58, acc 0.90625\n",
      "2017-09-12T00:26:37.060868: step 3820, loss -3768.94, acc 0.90625\n",
      "2017-09-12T00:26:37.192042: step 3821, loss 126.912, acc 0.90625\n",
      "2017-09-12T00:26:37.343556: step 3822, loss -296.575, acc 0.8125\n",
      "2017-09-12T00:26:37.493826: step 3823, loss -4780.68, acc 0.9375\n",
      "2017-09-12T00:26:37.648554: step 3824, loss -6549.66, acc 0.96875\n",
      "2017-09-12T00:26:37.797568: step 3825, loss -5746.67, acc 0.96875\n",
      "2017-09-12T00:26:37.948889: step 3826, loss -6271.5, acc 0.96875\n",
      "2017-09-12T00:26:38.103729: step 3827, loss -837.53, acc 0.90625\n",
      "2017-09-12T00:26:38.243245: step 3828, loss -936.593, acc 0.9375\n",
      "2017-09-12T00:26:38.394152: step 3829, loss -10633.5, acc 1\n",
      "2017-09-12T00:26:38.545408: step 3830, loss -4240.38, acc 0.9375\n",
      "2017-09-12T00:26:38.697534: step 3831, loss -3024.42, acc 0.9375\n",
      "2017-09-12T00:26:38.836134: step 3832, loss -5319.99, acc 0.96875\n",
      "2017-09-12T00:26:38.986589: step 3833, loss -3057.4, acc 0.90625\n",
      "2017-09-12T00:26:39.150045: step 3834, loss -2999.35, acc 0.96875\n",
      "2017-09-12T00:26:39.289156: step 3835, loss -1079.53, acc 0.9375\n",
      "2017-09-12T00:26:39.421863: step 3836, loss -3695.65, acc 0.90625\n",
      "2017-09-12T00:26:39.581362: step 3837, loss -1167.58, acc 0.90625\n",
      "2017-09-12T00:26:39.723734: step 3838, loss -3841.58, acc 0.90625\n",
      "2017-09-12T00:26:39.868200: step 3839, loss 824.593, acc 0.84375\n",
      "2017-09-12T00:26:40.018907: step 3840, loss -3169.9, acc 0.84375\n",
      "2017-09-12T00:26:40.157758: step 3841, loss -7210.41, acc 0.9375\n",
      "2017-09-12T00:26:40.305967: step 3842, loss 839.058, acc 0.9375\n",
      "2017-09-12T00:26:40.451763: step 3843, loss -4798.42, acc 0.9375\n",
      "2017-09-12T00:26:40.616970: step 3844, loss -3678.59, acc 0.96875\n",
      "2017-09-12T00:26:40.776531: step 3845, loss -2637.64, acc 0.875\n",
      "2017-09-12T00:26:40.935539: step 3846, loss -1127.94, acc 0.96875\n",
      "2017-09-12T00:26:41.083735: step 3847, loss -3274.71, acc 0.90625\n",
      "2017-09-12T00:26:41.235235: step 3848, loss -6886.95, acc 0.96875\n",
      "2017-09-12T00:26:41.369620: step 3849, loss -5572.26, acc 0.90625\n",
      "2017-09-12T00:26:41.516528: step 3850, loss -2950.68, acc 0.9375\n",
      "2017-09-12T00:26:41.664248: step 3851, loss -2006.66, acc 0.84375\n",
      "2017-09-12T00:26:41.815760: step 3852, loss -1691.86, acc 0.90625\n",
      "2017-09-12T00:26:41.957141: step 3853, loss -3260.59, acc 0.9375\n",
      "2017-09-12T00:26:42.165203: step 3854, loss -10347.4, acc 0.96875\n",
      "2017-09-12T00:26:42.338297: step 3855, loss -2893.46, acc 0.9375\n",
      "2017-09-12T00:26:42.504587: step 3856, loss -1132.6, acc 0.90625\n",
      "2017-09-12T00:26:42.698595: step 3857, loss 1743.79, acc 0.90625\n",
      "2017-09-12T00:26:42.842497: step 3858, loss 33.5634, acc 0.90625\n",
      "2017-09-12T00:26:42.988893: step 3859, loss -6472.11, acc 0.9375\n",
      "2017-09-12T00:26:43.131583: step 3860, loss -1803.01, acc 0.90625\n",
      "2017-09-12T00:26:43.288125: step 3861, loss -4480.87, acc 0.96875\n",
      "2017-09-12T00:26:43.433104: step 3862, loss -6759.25, acc 0.96875\n",
      "2017-09-12T00:26:43.643087: step 3863, loss -1385.22, acc 0.875\n",
      "2017-09-12T00:26:43.768660: step 3864, loss -5442.03, acc 0.96875\n",
      "2017-09-12T00:26:43.907189: step 3865, loss -6546.13, acc 0.96875\n",
      "2017-09-12T00:26:44.107481: step 3866, loss -10728.4, acc 0.96875\n",
      "2017-09-12T00:26:44.300189: step 3867, loss -5222.19, acc 0.9375\n",
      "2017-09-12T00:26:44.430054: step 3868, loss -2180.72, acc 0.96875\n",
      "2017-09-12T00:26:44.577408: step 3869, loss -1812.39, acc 0.90625\n",
      "2017-09-12T00:26:44.744174: step 3870, loss -842.341, acc 0.90625\n",
      "2017-09-12T00:26:44.888510: step 3871, loss -1594.22, acc 0.875\n",
      "2017-09-12T00:26:45.030462: step 3872, loss -2829.34, acc 0.96875\n",
      "2017-09-12T00:26:45.171335: step 3873, loss 62.9492, acc 0.8125\n",
      "2017-09-12T00:26:45.315984: step 3874, loss -4032.87, acc 0.96875\n",
      "2017-09-12T00:26:45.457568: step 3875, loss -3827.66, acc 0.9375\n",
      "2017-09-12T00:26:45.603831: step 3876, loss -6938.13, acc 0.96875\n",
      "2017-09-12T00:26:45.766740: step 3877, loss -2918.96, acc 0.9375\n",
      "2017-09-12T00:26:45.902932: step 3878, loss -2097.15, acc 0.9375\n",
      "2017-09-12T00:26:46.055259: step 3879, loss -1784.77, acc 0.84375\n",
      "2017-09-12T00:26:46.188571: step 3880, loss 547.348, acc 0.84375\n",
      "2017-09-12T00:26:46.341882: step 3881, loss -3201.38, acc 0.90625\n",
      "2017-09-12T00:26:46.480881: step 3882, loss -1296.74, acc 0.84375\n",
      "2017-09-12T00:26:46.637859: step 3883, loss -2120.22, acc 0.875\n",
      "2017-09-12T00:26:46.790171: step 3884, loss -5662.74, acc 0.96875\n",
      "2017-09-12T00:26:46.922633: step 3885, loss -1803.64, acc 0.96875\n",
      "2017-09-12T00:26:47.065278: step 3886, loss -2146.09, acc 0.90625\n",
      "2017-09-12T00:26:47.214617: step 3887, loss -3749.9, acc 0.90625\n",
      "2017-09-12T00:26:47.397268: step 3888, loss -3691.7, acc 0.90625\n",
      "2017-09-12T00:26:47.541949: step 3889, loss -1809.02, acc 0.9375\n",
      "2017-09-12T00:26:47.723895: step 3890, loss -5064.22, acc 0.9375\n",
      "2017-09-12T00:26:47.866892: step 3891, loss -1979.88, acc 0.96875\n",
      "2017-09-12T00:26:48.018289: step 3892, loss 1858.47, acc 0.875\n",
      "2017-09-12T00:26:48.189811: step 3893, loss -5811.59, acc 0.96875\n",
      "2017-09-12T00:26:48.351862: step 3894, loss -7430.52, acc 0.9375\n",
      "2017-09-12T00:26:48.489600: step 3895, loss -4114.67, acc 0.9375\n",
      "2017-09-12T00:26:48.637807: step 3896, loss -2162.84, acc 0.9375\n",
      "2017-09-12T00:26:48.780736: step 3897, loss 2561.73, acc 0.8125\n",
      "2017-09-12T00:26:48.940617: step 3898, loss -2065.23, acc 0.84375\n",
      "2017-09-12T00:26:49.110061: step 3899, loss -8032.35, acc 0.9375\n",
      "2017-09-12T00:26:49.244802: step 3900, loss -1087.51, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:26:50.608917: step 3900, loss -3858.26, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-3900\n",
      "\n",
      "2017-09-12T00:26:52.658181: step 3901, loss -4474.05, acc 0.90625\n",
      "2017-09-12T00:26:52.767542: step 3902, loss 1883.38, acc 0.90625\n",
      "2017-09-12T00:26:52.860343: step 3903, loss -27.1792, acc 0.90625\n",
      "2017-09-12T00:26:52.950611: step 3904, loss -5733.27, acc 0.96875\n",
      "2017-09-12T00:26:53.047882: step 3905, loss -4879.98, acc 0.9375\n",
      "2017-09-12T00:26:53.150133: step 3906, loss -4880.95, acc 0.9375\n",
      "2017-09-12T00:26:53.237261: step 3907, loss -7008.86, acc 1\n",
      "2017-09-12T00:26:53.327503: step 3908, loss -6648.57, acc 0.96875\n",
      "2017-09-12T00:26:53.432465: step 3909, loss -6391.71, acc 0.9375\n",
      "2017-09-12T00:26:53.524309: step 3910, loss -8679.91, acc 0.96875\n",
      "2017-09-12T00:26:53.634724: step 3911, loss 945.602, acc 0.875\n",
      "2017-09-12T00:26:53.727060: step 3912, loss -3207.97, acc 0.875\n",
      "2017-09-12T00:26:53.819186: step 3913, loss -3515.76, acc 0.90625\n",
      "2017-09-12T00:26:53.909741: step 3914, loss -1361.08, acc 0.90625\n",
      "2017-09-12T00:26:53.998677: step 3915, loss -4081.73, acc 0.90625\n",
      "2017-09-12T00:26:54.103228: step 3916, loss -5179.75, acc 0.9375\n",
      "2017-09-12T00:26:54.195056: step 3917, loss -3984.99, acc 0.9375\n",
      "2017-09-12T00:26:54.331954: step 3918, loss -8368.29, acc 1\n",
      "2017-09-12T00:26:54.627060: step 3919, loss -2992.53, acc 0.96875\n",
      "2017-09-12T00:26:54.751615: step 3920, loss -1081.02, acc 0.96875\n",
      "2017-09-12T00:26:54.889851: step 3921, loss -6560.55, acc 0.90625\n",
      "2017-09-12T00:26:55.054434: step 3922, loss -2054.75, acc 0.90625\n",
      "2017-09-12T00:26:55.227381: step 3923, loss -3873.05, acc 0.84375\n",
      "2017-09-12T00:26:55.360349: step 3924, loss -1270.23, acc 0.875\n",
      "2017-09-12T00:26:55.507089: step 3925, loss -5364.29, acc 0.90625\n",
      "2017-09-12T00:26:55.646620: step 3926, loss -2819.12, acc 0.90625\n",
      "2017-09-12T00:26:55.786277: step 3927, loss -4824.34, acc 0.90625\n",
      "2017-09-12T00:26:55.926892: step 3928, loss -2708.73, acc 0.84375\n",
      "2017-09-12T00:26:56.061892: step 3929, loss -1983.44, acc 0.90625\n",
      "2017-09-12T00:26:56.301186: step 3930, loss -34.2553, acc 0.9375\n",
      "2017-09-12T00:26:56.439802: step 3931, loss -1207.73, acc 0.90625\n",
      "2017-09-12T00:26:56.615586: step 3932, loss -6930.23, acc 0.96875\n",
      "2017-09-12T00:26:56.758440: step 3933, loss -5287.95, acc 0.9375\n",
      "2017-09-12T00:26:56.904401: step 3934, loss -4723.69, acc 0.96875\n",
      "2017-09-12T00:26:57.051179: step 3935, loss -2156.3, acc 0.96875\n",
      "2017-09-12T00:26:57.189344: step 3936, loss -2100.44, acc 0.96875\n",
      "2017-09-12T00:26:57.338565: step 3937, loss -4028.94, acc 0.96875\n",
      "2017-09-12T00:26:57.485459: step 3938, loss -93.5997, acc 0.875\n",
      "2017-09-12T00:26:57.636674: step 3939, loss -2145.63, acc 0.90625\n",
      "2017-09-12T00:26:57.805259: step 3940, loss -5772.1, acc 0.9375\n",
      "2017-09-12T00:26:57.950296: step 3941, loss -6934.45, acc 0.9375\n",
      "2017-09-12T00:26:58.094624: step 3942, loss -1170.18, acc 0.90625\n",
      "2017-09-12T00:26:58.225745: step 3943, loss -2174.87, acc 0.9375\n",
      "2017-09-12T00:26:58.378134: step 3944, loss -7817.58, acc 1\n",
      "2017-09-12T00:26:58.421960: step 3945, loss -4121.49, acc 1\n",
      "2017-09-12T00:26:58.653918: step 3946, loss -877.638, acc 0.90625\n",
      "2017-09-12T00:26:58.852415: step 3947, loss -4209.38, acc 0.96875\n",
      "2017-09-12T00:26:58.977591: step 3948, loss -2282.39, acc 0.90625\n",
      "2017-09-12T00:26:59.134431: step 3949, loss -2059.72, acc 0.9375\n",
      "2017-09-12T00:26:59.285376: step 3950, loss -5981.67, acc 1\n",
      "2017-09-12T00:26:59.442275: step 3951, loss -4929.54, acc 0.875\n",
      "2017-09-12T00:26:59.645652: step 3952, loss -8542.83, acc 0.96875\n",
      "2017-09-12T00:26:59.830601: step 3953, loss -7196.11, acc 1\n",
      "2017-09-12T00:26:59.977597: step 3954, loss -5090.93, acc 0.90625\n",
      "2017-09-12T00:27:00.120946: step 3955, loss -3072.04, acc 0.90625\n",
      "2017-09-12T00:27:00.259078: step 3956, loss -3251.21, acc 0.875\n",
      "2017-09-12T00:27:00.411364: step 3957, loss 630.385, acc 0.84375\n",
      "2017-09-12T00:27:00.558254: step 3958, loss -5645.62, acc 0.90625\n",
      "2017-09-12T00:27:00.704637: step 3959, loss -4005.3, acc 1\n",
      "2017-09-12T00:27:00.855049: step 3960, loss -2898.57, acc 1\n",
      "2017-09-12T00:27:01.002145: step 3961, loss -2438.97, acc 0.84375\n",
      "2017-09-12T00:27:01.157204: step 3962, loss -9006.55, acc 0.96875\n",
      "2017-09-12T00:27:01.292386: step 3963, loss -7056.53, acc 0.9375\n",
      "2017-09-12T00:27:01.445441: step 3964, loss 1469.47, acc 0.84375\n",
      "2017-09-12T00:27:01.618818: step 3965, loss -1131.55, acc 0.90625\n",
      "2017-09-12T00:27:01.753565: step 3966, loss -610.383, acc 0.875\n",
      "2017-09-12T00:27:01.901740: step 3967, loss -3949.91, acc 0.96875\n",
      "2017-09-12T00:27:02.077465: step 3968, loss -796.962, acc 0.875\n",
      "2017-09-12T00:27:02.239705: step 3969, loss -8987.76, acc 1\n",
      "2017-09-12T00:27:02.384629: step 3970, loss -9198.95, acc 0.96875\n",
      "2017-09-12T00:27:02.514514: step 3971, loss 35.6816, acc 0.9375\n",
      "2017-09-12T00:27:02.654409: step 3972, loss -2947.62, acc 0.90625\n",
      "2017-09-12T00:27:02.801853: step 3973, loss 549.727, acc 0.875\n",
      "2017-09-12T00:27:02.938165: step 3974, loss -4236.19, acc 0.96875\n",
      "2017-09-12T00:27:03.079590: step 3975, loss 345.817, acc 0.84375\n",
      "2017-09-12T00:27:03.219051: step 3976, loss -3203.47, acc 0.90625\n",
      "2017-09-12T00:27:03.359702: step 3977, loss -6053.36, acc 0.875\n",
      "2017-09-12T00:27:03.501788: step 3978, loss -4199.49, acc 0.90625\n",
      "2017-09-12T00:27:03.638112: step 3979, loss -3722.18, acc 0.9375\n",
      "2017-09-12T00:27:03.782226: step 3980, loss -4278.77, acc 0.9375\n",
      "2017-09-12T00:27:03.920302: step 3981, loss -4908.95, acc 0.9375\n",
      "2017-09-12T00:27:04.060712: step 3982, loss -7137.11, acc 1\n",
      "2017-09-12T00:27:04.203572: step 3983, loss -2823.58, acc 0.96875\n",
      "2017-09-12T00:27:04.346688: step 3984, loss 444.908, acc 0.875\n",
      "2017-09-12T00:27:04.484276: step 3985, loss -2101.83, acc 0.9375\n",
      "2017-09-12T00:27:04.619404: step 3986, loss -3119.83, acc 0.90625\n",
      "2017-09-12T00:27:04.758962: step 3987, loss -4583.92, acc 0.9375\n",
      "2017-09-12T00:27:04.911892: step 3988, loss -4025, acc 0.96875\n",
      "2017-09-12T00:27:05.052431: step 3989, loss -2899.48, acc 0.96875\n",
      "2017-09-12T00:27:05.291140: step 3990, loss -6024.27, acc 0.90625\n",
      "2017-09-12T00:27:05.445402: step 3991, loss -8273.08, acc 0.9375\n",
      "2017-09-12T00:27:05.604358: step 3992, loss -8658.93, acc 0.96875\n",
      "2017-09-12T00:27:05.763626: step 3993, loss -7324.97, acc 0.96875\n",
      "2017-09-12T00:27:05.948452: step 3994, loss -4176.08, acc 0.96875\n",
      "2017-09-12T00:27:06.117119: step 3995, loss -6505.65, acc 0.9375\n",
      "2017-09-12T00:27:06.312149: step 3996, loss -1396.07, acc 0.9375\n",
      "2017-09-12T00:27:06.472283: step 3997, loss -2187.6, acc 0.90625\n",
      "2017-09-12T00:27:06.678213: step 3998, loss -4329.8, acc 0.875\n",
      "2017-09-12T00:27:06.856170: step 3999, loss -333.262, acc 0.875\n",
      "2017-09-12T00:27:07.013465: step 4000, loss -7225.15, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:27:08.726903: step 4000, loss -4123.13, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4000\n",
      "\n",
      "2017-09-12T00:27:11.187862: step 4001, loss -2810.69, acc 0.84375\n",
      "2017-09-12T00:27:11.341015: step 4002, loss -4180.16, acc 0.96875\n",
      "2017-09-12T00:27:11.474822: step 4003, loss -1200.8, acc 0.90625\n",
      "2017-09-12T00:27:11.575191: step 4004, loss -4505.46, acc 0.90625\n",
      "2017-09-12T00:27:11.673429: step 4005, loss -768.981, acc 0.875\n",
      "2017-09-12T00:27:11.796652: step 4006, loss -4009.53, acc 0.96875\n",
      "2017-09-12T00:27:11.891318: step 4007, loss 1944.34, acc 0.84375\n",
      "2017-09-12T00:27:12.002397: step 4008, loss -2255.93, acc 0.96875\n",
      "2017-09-12T00:27:12.103393: step 4009, loss -7758.58, acc 0.9375\n",
      "2017-09-12T00:27:12.204808: step 4010, loss -2181, acc 0.875\n",
      "2017-09-12T00:27:12.311516: step 4011, loss -11601, acc 1\n",
      "2017-09-12T00:27:12.412445: step 4012, loss -7315.01, acc 0.9375\n",
      "2017-09-12T00:27:12.505986: step 4013, loss -3928.23, acc 0.9375\n",
      "2017-09-12T00:27:12.610311: step 4014, loss -7437.12, acc 0.9375\n",
      "2017-09-12T00:27:12.706531: step 4015, loss -6270.38, acc 0.90625\n",
      "2017-09-12T00:27:12.797179: step 4016, loss -10787.4, acc 0.9375\n",
      "2017-09-12T00:27:12.907137: step 4017, loss -6328.66, acc 0.96875\n",
      "2017-09-12T00:27:13.017362: step 4018, loss -8526.42, acc 0.96875\n",
      "2017-09-12T00:27:13.116725: step 4019, loss -5126.76, acc 0.90625\n",
      "2017-09-12T00:27:13.228355: step 4020, loss -3182.98, acc 0.9375\n",
      "2017-09-12T00:27:13.512595: step 4021, loss -7218.72, acc 0.90625\n",
      "2017-09-12T00:27:13.660050: step 4022, loss -6475.32, acc 0.90625\n",
      "2017-09-12T00:27:13.824440: step 4023, loss -6327.98, acc 1\n",
      "2017-09-12T00:27:13.990512: step 4024, loss -2084.81, acc 0.90625\n",
      "2017-09-12T00:27:14.144469: step 4025, loss 1057.29, acc 0.90625\n",
      "2017-09-12T00:27:14.404956: step 4026, loss 1919, acc 0.90625\n",
      "2017-09-12T00:27:14.657238: step 4027, loss -4435.56, acc 1\n",
      "2017-09-12T00:27:14.887964: step 4028, loss -4204.23, acc 0.90625\n",
      "2017-09-12T00:27:15.082977: step 4029, loss -5017.61, acc 0.90625\n",
      "2017-09-12T00:27:15.270406: step 4030, loss -346.748, acc 0.90625\n",
      "2017-09-12T00:27:15.417900: step 4031, loss -1349.38, acc 0.90625\n",
      "2017-09-12T00:27:15.574432: step 4032, loss 3818.27, acc 0.8125\n",
      "2017-09-12T00:27:15.731010: step 4033, loss -1046.86, acc 0.9375\n",
      "2017-09-12T00:27:15.878666: step 4034, loss -1882.61, acc 0.875\n",
      "2017-09-12T00:27:16.071755: step 4035, loss -8065.68, acc 1\n",
      "2017-09-12T00:27:16.217747: step 4036, loss -5187.91, acc 0.90625\n",
      "2017-09-12T00:27:16.386708: step 4037, loss -2160.78, acc 0.90625\n",
      "2017-09-12T00:27:16.533106: step 4038, loss -2413.66, acc 0.9375\n",
      "2017-09-12T00:27:16.708031: step 4039, loss -6827.03, acc 0.9375\n",
      "2017-09-12T00:27:16.841351: step 4040, loss -6355.33, acc 0.96875\n",
      "2017-09-12T00:27:16.998530: step 4041, loss -4634.19, acc 0.9375\n",
      "2017-09-12T00:27:17.153045: step 4042, loss -2445.26, acc 0.90625\n",
      "2017-09-12T00:27:17.319830: step 4043, loss -4400.36, acc 0.96875\n",
      "2017-09-12T00:27:17.484292: step 4044, loss -4273.71, acc 0.9375\n",
      "2017-09-12T00:27:17.658601: step 4045, loss -3678.53, acc 0.875\n",
      "2017-09-12T00:27:17.820893: step 4046, loss -4604.94, acc 0.90625\n",
      "2017-09-12T00:27:17.987253: step 4047, loss -4222.89, acc 0.9375\n",
      "2017-09-12T00:27:18.146466: step 4048, loss -1953.52, acc 0.9375\n",
      "2017-09-12T00:27:18.316368: step 4049, loss -153.325, acc 0.90625\n",
      "2017-09-12T00:27:18.490677: step 4050, loss -6589.7, acc 0.9375\n",
      "2017-09-12T00:27:18.650537: step 4051, loss -4579, acc 0.9375\n",
      "2017-09-12T00:27:18.805987: step 4052, loss -6449.55, acc 1\n",
      "2017-09-12T00:27:18.961312: step 4053, loss -1058.36, acc 0.90625\n",
      "2017-09-12T00:27:19.134060: step 4054, loss -3089.79, acc 0.9375\n",
      "2017-09-12T00:27:19.318719: step 4055, loss -5368.13, acc 1\n",
      "2017-09-12T00:27:19.487420: step 4056, loss -8024.21, acc 0.96875\n",
      "2017-09-12T00:27:19.635991: step 4057, loss -6341.02, acc 0.96875\n",
      "2017-09-12T00:27:19.795274: step 4058, loss -1376.31, acc 0.84375\n",
      "2017-09-12T00:27:19.977021: step 4059, loss -3437.8, acc 0.9375\n",
      "2017-09-12T00:27:20.183009: step 4060, loss -7608.48, acc 0.96875\n",
      "2017-09-12T00:27:20.334183: step 4061, loss 62.5602, acc 0.84375\n",
      "2017-09-12T00:27:20.478440: step 4062, loss 987.683, acc 0.875\n",
      "2017-09-12T00:27:20.631112: step 4063, loss 325.524, acc 0.75\n",
      "2017-09-12T00:27:20.856936: step 4064, loss -2151.05, acc 0.875\n",
      "2017-09-12T00:27:21.075575: step 4065, loss -1056.47, acc 0.875\n",
      "2017-09-12T00:27:21.219022: step 4066, loss 2176.85, acc 0.875\n",
      "2017-09-12T00:27:21.439291: step 4067, loss -6555.1, acc 0.96875\n",
      "2017-09-12T00:27:21.612270: step 4068, loss -5776.76, acc 0.90625\n",
      "2017-09-12T00:27:21.803211: step 4069, loss -4574.42, acc 0.9375\n",
      "2017-09-12T00:27:21.969396: step 4070, loss -2599.88, acc 0.90625\n",
      "2017-09-12T00:27:22.130611: step 4071, loss -3335.29, acc 0.875\n",
      "2017-09-12T00:27:22.301994: step 4072, loss -3401.18, acc 0.875\n",
      "2017-09-12T00:27:22.490894: step 4073, loss -5869.45, acc 0.90625\n",
      "2017-09-12T00:27:22.648634: step 4074, loss -9030.68, acc 0.9375\n",
      "2017-09-12T00:27:22.808624: step 4075, loss -7.25037, acc 0.875\n",
      "2017-09-12T00:27:22.974188: step 4076, loss -9168.51, acc 0.96875\n",
      "2017-09-12T00:27:23.147444: step 4077, loss -473.747, acc 0.8125\n",
      "2017-09-12T00:27:23.332494: step 4078, loss -211.269, acc 0.8125\n",
      "2017-09-12T00:27:23.490449: step 4079, loss -2160.63, acc 0.90625\n",
      "2017-09-12T00:27:23.650774: step 4080, loss -1861.08, acc 0.84375\n",
      "2017-09-12T00:27:23.810878: step 4081, loss -6625.57, acc 0.96875\n",
      "2017-09-12T00:27:23.978251: step 4082, loss -3149.69, acc 1\n",
      "2017-09-12T00:27:24.129270: step 4083, loss -3688.72, acc 0.9375\n",
      "2017-09-12T00:27:24.279697: step 4084, loss 2397.11, acc 0.84375\n",
      "2017-09-12T00:27:24.431909: step 4085, loss -4920.5, acc 0.9375\n",
      "2017-09-12T00:27:24.570447: step 4086, loss -3450.74, acc 0.90625\n",
      "2017-09-12T00:27:24.724701: step 4087, loss -3823.87, acc 0.90625\n",
      "2017-09-12T00:27:24.878889: step 4088, loss -2878.74, acc 0.9375\n",
      "2017-09-12T00:27:25.034516: step 4089, loss -2222.22, acc 1\n",
      "2017-09-12T00:27:25.181173: step 4090, loss -6255.67, acc 0.90625\n",
      "2017-09-12T00:27:25.326528: step 4091, loss 857.751, acc 0.9375\n",
      "2017-09-12T00:27:25.477909: step 4092, loss -7125.06, acc 0.9375\n",
      "2017-09-12T00:27:25.631722: step 4093, loss -3349.39, acc 1\n",
      "2017-09-12T00:27:25.784411: step 4094, loss -4548.78, acc 0.96875\n",
      "2017-09-12T00:27:25.968858: step 4095, loss -2114.95, acc 0.9375\n",
      "2017-09-12T00:27:26.141922: step 4096, loss -359.935, acc 0.90625\n",
      "2017-09-12T00:27:26.306367: step 4097, loss -182.332, acc 0.875\n",
      "2017-09-12T00:27:26.556484: step 4098, loss -2507.19, acc 0.90625\n",
      "2017-09-12T00:27:26.767677: step 4099, loss -9797.99, acc 0.9375\n",
      "2017-09-12T00:27:26.934348: step 4100, loss -6944.01, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:27:28.369479: step 4100, loss -4382.7, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4100\n",
      "\n",
      "2017-09-12T00:27:30.378180: step 4101, loss -6811.08, acc 0.90625\n",
      "2017-09-12T00:27:30.468489: step 4102, loss -2322.6, acc 0.9375\n",
      "2017-09-12T00:27:30.562280: step 4103, loss -1314.82, acc 0.96875\n",
      "2017-09-12T00:27:30.651201: step 4104, loss -8090.5, acc 0.96875\n",
      "2017-09-12T00:27:30.752406: step 4105, loss -7458.01, acc 1\n",
      "2017-09-12T00:27:30.853706: step 4106, loss -7723.68, acc 0.9375\n",
      "2017-09-12T00:27:30.949991: step 4107, loss -7316.22, acc 0.96875\n",
      "2017-09-12T00:27:31.038287: step 4108, loss -4567.74, acc 0.96875\n",
      "2017-09-12T00:27:31.132658: step 4109, loss -5956.75, acc 0.96875\n",
      "2017-09-12T00:27:31.229956: step 4110, loss -6783.45, acc 0.96875\n",
      "2017-09-12T00:27:31.338694: step 4111, loss -3780.62, acc 0.9375\n",
      "2017-09-12T00:27:31.431656: step 4112, loss -3504.91, acc 0.9375\n",
      "2017-09-12T00:27:31.534705: step 4113, loss -232.684, acc 0.9375\n",
      "2017-09-12T00:27:31.630420: step 4114, loss -944.536, acc 0.9375\n",
      "2017-09-12T00:27:31.725299: step 4115, loss -2522.65, acc 0.875\n",
      "2017-09-12T00:27:31.816286: step 4116, loss -3728.64, acc 0.90625\n",
      "2017-09-12T00:27:31.907454: step 4117, loss -10033.1, acc 1\n",
      "2017-09-12T00:27:32.004212: step 4118, loss -5877.01, acc 0.9375\n",
      "2017-09-12T00:27:32.094472: step 4119, loss 153.806, acc 0.90625\n",
      "2017-09-12T00:27:32.188898: step 4120, loss -2446.59, acc 0.9375\n",
      "2017-09-12T00:27:32.318038: step 4121, loss -4680.32, acc 0.96875\n",
      "2017-09-12T00:27:32.430225: step 4122, loss -1155.22, acc 0.9375\n",
      "2017-09-12T00:27:32.748921: step 4123, loss -6811.99, acc 0.9375\n",
      "2017-09-12T00:27:32.894821: step 4124, loss -2368.71, acc 0.875\n",
      "2017-09-12T00:27:33.050311: step 4125, loss -1029.24, acc 0.9375\n",
      "2017-09-12T00:27:33.222031: step 4126, loss -4590.62, acc 0.96875\n",
      "2017-09-12T00:27:33.398336: step 4127, loss -1524.4, acc 0.90625\n",
      "2017-09-12T00:27:33.554276: step 4128, loss -4680.08, acc 0.9375\n",
      "2017-09-12T00:27:33.712601: step 4129, loss -12304.2, acc 0.96875\n",
      "2017-09-12T00:27:33.880242: step 4130, loss -3332.81, acc 0.9375\n",
      "2017-09-12T00:27:34.115394: step 4131, loss -2758.99, acc 0.9375\n",
      "2017-09-12T00:27:34.256914: step 4132, loss -4122.31, acc 0.9375\n",
      "2017-09-12T00:27:34.406788: step 4133, loss -6704.11, acc 1\n",
      "2017-09-12T00:27:34.541675: step 4134, loss -6039.82, acc 0.9375\n",
      "2017-09-12T00:27:34.691084: step 4135, loss -2282.49, acc 0.96875\n",
      "2017-09-12T00:27:34.878401: step 4136, loss -1313.25, acc 0.96875\n",
      "2017-09-12T00:27:35.033891: step 4137, loss -2404.56, acc 0.96875\n",
      "2017-09-12T00:27:35.170810: step 4138, loss 2094.3, acc 0.90625\n",
      "2017-09-12T00:27:35.307671: step 4139, loss -9502.96, acc 0.96875\n",
      "2017-09-12T00:27:35.457833: step 4140, loss 1296.52, acc 0.90625\n",
      "2017-09-12T00:27:35.600163: step 4141, loss -973.597, acc 0.9375\n",
      "2017-09-12T00:27:35.760578: step 4142, loss -7263.75, acc 0.9375\n",
      "2017-09-12T00:27:35.908864: step 4143, loss -2432.84, acc 0.9375\n",
      "2017-09-12T00:27:36.065375: step 4144, loss -5820.85, acc 0.875\n",
      "2017-09-12T00:27:36.203603: step 4145, loss -5652.61, acc 0.96875\n",
      "2017-09-12T00:27:36.351549: step 4146, loss -5997.03, acc 0.96875\n",
      "2017-09-12T00:27:36.495961: step 4147, loss -250.942, acc 0.875\n",
      "2017-09-12T00:27:36.674113: step 4148, loss -3582.68, acc 0.9375\n",
      "2017-09-12T00:27:36.836585: step 4149, loss -1625.77, acc 0.90625\n",
      "2017-09-12T00:27:37.020253: step 4150, loss -4631.7, acc 1\n",
      "2017-09-12T00:27:37.164332: step 4151, loss -911.813, acc 0.875\n",
      "2017-09-12T00:27:37.326513: step 4152, loss 1017.93, acc 0.90625\n",
      "2017-09-12T00:27:37.496097: step 4153, loss -3308.86, acc 0.9375\n",
      "2017-09-12T00:27:37.638925: step 4154, loss -53.5426, acc 0.90625\n",
      "2017-09-12T00:27:37.776462: step 4155, loss -4838.43, acc 0.9375\n",
      "2017-09-12T00:27:37.927846: step 4156, loss -8082.64, acc 0.96875\n",
      "2017-09-12T00:27:38.070947: step 4157, loss -5659.83, acc 1\n",
      "2017-09-12T00:27:38.228339: step 4158, loss -2670.55, acc 0.90625\n",
      "2017-09-12T00:27:38.385737: step 4159, loss -5816.45, acc 0.9375\n",
      "2017-09-12T00:27:38.561611: step 4160, loss -6736.99, acc 0.9375\n",
      "2017-09-12T00:27:38.707047: step 4161, loss -6983.52, acc 0.9375\n",
      "2017-09-12T00:27:38.851193: step 4162, loss -6007.36, acc 0.96875\n",
      "2017-09-12T00:27:39.005418: step 4163, loss -6018.33, acc 0.96875\n",
      "2017-09-12T00:27:39.157393: step 4164, loss 3164.46, acc 0.75\n",
      "2017-09-12T00:27:39.332301: step 4165, loss -5741.16, acc 0.90625\n",
      "2017-09-12T00:27:39.492884: step 4166, loss -5070.72, acc 1\n",
      "2017-09-12T00:27:39.720858: step 4167, loss -2677.61, acc 0.9375\n",
      "2017-09-12T00:27:39.878302: step 4168, loss -3653.23, acc 0.96875\n",
      "2017-09-12T00:27:40.021087: step 4169, loss 2881.75, acc 0.8125\n",
      "2017-09-12T00:27:40.184114: step 4170, loss -2654.41, acc 0.84375\n",
      "2017-09-12T00:27:40.326267: step 4171, loss -5371.21, acc 0.9375\n",
      "2017-09-12T00:27:40.476772: step 4172, loss -3530.83, acc 0.9375\n",
      "2017-09-12T00:27:40.678126: step 4173, loss -4641.18, acc 1\n",
      "2017-09-12T00:27:40.825044: step 4174, loss -1445.65, acc 0.9375\n",
      "2017-09-12T00:27:40.972986: step 4175, loss 2128.54, acc 0.875\n",
      "2017-09-12T00:27:41.109718: step 4176, loss -5549.24, acc 0.9375\n",
      "2017-09-12T00:27:41.310158: step 4177, loss -3043.03, acc 0.84375\n",
      "2017-09-12T00:27:41.441631: step 4178, loss -9548.36, acc 0.9375\n",
      "2017-09-12T00:27:41.576431: step 4179, loss -5070.05, acc 0.84375\n",
      "2017-09-12T00:27:41.724263: step 4180, loss -8429.14, acc 0.90625\n",
      "2017-09-12T00:27:41.873209: step 4181, loss -6934.03, acc 0.9375\n",
      "2017-09-12T00:27:42.025582: step 4182, loss 6445.18, acc 0.71875\n",
      "2017-09-12T00:27:42.168525: step 4183, loss -3378.46, acc 0.96875\n",
      "2017-09-12T00:27:42.318186: step 4184, loss -7907.01, acc 1\n",
      "2017-09-12T00:27:42.467537: step 4185, loss -5081.43, acc 0.90625\n",
      "2017-09-12T00:27:42.608139: step 4186, loss -5976.4, acc 0.9375\n",
      "2017-09-12T00:27:42.758545: step 4187, loss -9332.22, acc 1\n",
      "2017-09-12T00:27:42.918877: step 4188, loss 73.0566, acc 0.84375\n",
      "2017-09-12T00:27:43.061672: step 4189, loss -4168.14, acc 0.875\n",
      "2017-09-12T00:27:43.202254: step 4190, loss -1257.65, acc 0.9375\n",
      "2017-09-12T00:27:43.348646: step 4191, loss -2160.53, acc 0.9375\n",
      "2017-09-12T00:27:43.504305: step 4192, loss -3855, acc 0.90625\n",
      "2017-09-12T00:27:43.655010: step 4193, loss -3480.08, acc 0.96875\n",
      "2017-09-12T00:27:43.797896: step 4194, loss -4868.18, acc 0.96875\n",
      "2017-09-12T00:27:43.954299: step 4195, loss -8665.39, acc 0.96875\n",
      "2017-09-12T00:27:44.093751: step 4196, loss -388.704, acc 0.875\n",
      "2017-09-12T00:27:44.245463: step 4197, loss -211.885, acc 0.84375\n",
      "2017-09-12T00:27:44.404516: step 4198, loss -2183.6, acc 0.9375\n",
      "2017-09-12T00:27:44.560040: step 4199, loss -875.429, acc 0.9375\n",
      "2017-09-12T00:27:44.706584: step 4200, loss -4790.9, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:27:46.026496: step 4200, loss -4645.31, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4200\n",
      "\n",
      "2017-09-12T00:27:47.901150: step 4201, loss -2658.47, acc 0.875\n",
      "2017-09-12T00:27:47.993173: step 4202, loss -4690.58, acc 0.9375\n",
      "2017-09-12T00:27:48.084993: step 4203, loss -2456.69, acc 0.875\n",
      "2017-09-12T00:27:48.180368: step 4204, loss -375.53, acc 0.875\n",
      "2017-09-12T00:27:48.285303: step 4205, loss -1023.77, acc 0.875\n",
      "2017-09-12T00:27:48.388285: step 4206, loss -7050.87, acc 0.9375\n",
      "2017-09-12T00:27:48.483559: step 4207, loss -3502.97, acc 0.875\n",
      "2017-09-12T00:27:48.523179: step 4208, loss -1050.26, acc 0.875\n",
      "2017-09-12T00:27:48.625345: step 4209, loss -5810.26, acc 0.96875\n",
      "2017-09-12T00:27:48.714624: step 4210, loss -4017.98, acc 0.90625\n",
      "2017-09-12T00:27:48.809474: step 4211, loss -7391.75, acc 0.9375\n",
      "2017-09-12T00:27:48.909236: step 4212, loss -160.402, acc 0.875\n",
      "2017-09-12T00:27:49.008125: step 4213, loss -13769.2, acc 1\n",
      "2017-09-12T00:27:49.098879: step 4214, loss -2450.04, acc 0.84375\n",
      "2017-09-12T00:27:49.195261: step 4215, loss -99.1519, acc 0.9375\n",
      "2017-09-12T00:27:49.294253: step 4216, loss -5771.63, acc 0.9375\n",
      "2017-09-12T00:27:49.401981: step 4217, loss 1868, acc 0.78125\n",
      "2017-09-12T00:27:49.649972: step 4218, loss -4785.15, acc 0.96875\n",
      "2017-09-12T00:27:49.787389: step 4219, loss 43.1204, acc 0.9375\n",
      "2017-09-12T00:27:49.926523: step 4220, loss -2747.48, acc 0.875\n",
      "2017-09-12T00:27:50.089594: step 4221, loss -4991.84, acc 0.875\n",
      "2017-09-12T00:27:50.237695: step 4222, loss -1280.28, acc 0.9375\n",
      "2017-09-12T00:27:50.378814: step 4223, loss -6685.03, acc 0.9375\n",
      "2017-09-12T00:27:50.529483: step 4224, loss -939.034, acc 0.9375\n",
      "2017-09-12T00:27:50.672051: step 4225, loss -3745.85, acc 0.875\n",
      "2017-09-12T00:27:50.817727: step 4226, loss -3969.21, acc 0.84375\n",
      "2017-09-12T00:27:50.959734: step 4227, loss 1196.63, acc 0.84375\n",
      "2017-09-12T00:27:51.113480: step 4228, loss -2027.83, acc 0.84375\n",
      "2017-09-12T00:27:51.257883: step 4229, loss -8705.58, acc 0.90625\n",
      "2017-09-12T00:27:51.399784: step 4230, loss -3624.68, acc 0.96875\n",
      "2017-09-12T00:27:51.543448: step 4231, loss -7165.7, acc 0.96875\n",
      "2017-09-12T00:27:51.691146: step 4232, loss -8441.87, acc 0.96875\n",
      "2017-09-12T00:27:51.845243: step 4233, loss -2494.7, acc 0.90625\n",
      "2017-09-12T00:27:51.992984: step 4234, loss -6159.88, acc 0.96875\n",
      "2017-09-12T00:27:52.144214: step 4235, loss -308.937, acc 0.8125\n",
      "2017-09-12T00:27:52.285641: step 4236, loss -7336.63, acc 0.90625\n",
      "2017-09-12T00:27:52.430648: step 4237, loss -4778.42, acc 0.96875\n",
      "2017-09-12T00:27:52.579738: step 4238, loss 2767.85, acc 0.78125\n",
      "2017-09-12T00:27:52.727037: step 4239, loss -4844.48, acc 1\n",
      "2017-09-12T00:27:52.869270: step 4240, loss -5102.92, acc 0.9375\n",
      "2017-09-12T00:27:53.007943: step 4241, loss -1032.41, acc 0.9375\n",
      "2017-09-12T00:27:53.147638: step 4242, loss -7694.42, acc 0.9375\n",
      "2017-09-12T00:27:53.293050: step 4243, loss -3338.01, acc 0.9375\n",
      "2017-09-12T00:27:53.444993: step 4244, loss -3943.11, acc 0.90625\n",
      "2017-09-12T00:27:53.576757: step 4245, loss -482.257, acc 0.90625\n",
      "2017-09-12T00:27:53.742147: step 4246, loss -6048.19, acc 0.90625\n",
      "2017-09-12T00:27:53.881855: step 4247, loss 758.449, acc 0.90625\n",
      "2017-09-12T00:27:54.036421: step 4248, loss -1442.97, acc 0.875\n",
      "2017-09-12T00:27:54.160257: step 4249, loss -6263.1, acc 0.96875\n",
      "2017-09-12T00:27:54.315631: step 4250, loss -3527.14, acc 0.90625\n",
      "2017-09-12T00:27:54.460640: step 4251, loss -9373.7, acc 0.9375\n",
      "2017-09-12T00:27:54.610728: step 4252, loss -1653.1, acc 0.90625\n",
      "2017-09-12T00:27:54.769633: step 4253, loss -10528.4, acc 0.9375\n",
      "2017-09-12T00:27:54.904359: step 4254, loss -2622.9, acc 0.90625\n",
      "2017-09-12T00:27:55.060202: step 4255, loss 1047.6, acc 0.875\n",
      "2017-09-12T00:27:55.207479: step 4256, loss -5399.51, acc 0.90625\n",
      "2017-09-12T00:27:55.346070: step 4257, loss -4066.72, acc 0.875\n",
      "2017-09-12T00:27:55.500088: step 4258, loss -286.928, acc 0.875\n",
      "2017-09-12T00:27:55.643387: step 4259, loss -1250.37, acc 0.9375\n",
      "2017-09-12T00:27:55.796284: step 4260, loss -1537.53, acc 0.875\n",
      "2017-09-12T00:27:55.936722: step 4261, loss -2734.95, acc 0.90625\n",
      "2017-09-12T00:27:56.089132: step 4262, loss -7650.63, acc 0.96875\n",
      "2017-09-12T00:27:56.228673: step 4263, loss -11046.6, acc 1\n",
      "2017-09-12T00:27:56.373766: step 4264, loss -6139.23, acc 0.96875\n",
      "2017-09-12T00:27:56.526352: step 4265, loss -1378.66, acc 0.90625\n",
      "2017-09-12T00:27:56.678646: step 4266, loss -6482.19, acc 0.84375\n",
      "2017-09-12T00:27:56.833389: step 4267, loss -2137.89, acc 0.9375\n",
      "2017-09-12T00:27:56.980654: step 4268, loss -6542.03, acc 0.9375\n",
      "2017-09-12T00:27:57.128624: step 4269, loss -4974.33, acc 0.9375\n",
      "2017-09-12T00:27:57.280540: step 4270, loss -9318.37, acc 1\n",
      "2017-09-12T00:27:57.437739: step 4271, loss -2815.4, acc 0.96875\n",
      "2017-09-12T00:27:57.565140: step 4272, loss -1355.13, acc 0.90625\n",
      "2017-09-12T00:27:57.727854: step 4273, loss -3856.65, acc 0.96875\n",
      "2017-09-12T00:27:57.860855: step 4274, loss -3934.25, acc 0.90625\n",
      "2017-09-12T00:27:58.014156: step 4275, loss -5574.96, acc 0.9375\n",
      "2017-09-12T00:27:58.160743: step 4276, loss -5709.63, acc 0.96875\n",
      "2017-09-12T00:27:58.309247: step 4277, loss -2748.71, acc 0.84375\n",
      "2017-09-12T00:27:58.445530: step 4278, loss -7942.88, acc 1\n",
      "2017-09-12T00:27:58.594811: step 4279, loss 1471.96, acc 0.84375\n",
      "2017-09-12T00:27:58.740222: step 4280, loss -6255.68, acc 1\n",
      "2017-09-12T00:27:58.879402: step 4281, loss -6362.31, acc 0.84375\n",
      "2017-09-12T00:27:59.030403: step 4282, loss -5235.51, acc 0.9375\n",
      "2017-09-12T00:27:59.178389: step 4283, loss -6987.26, acc 0.96875\n",
      "2017-09-12T00:27:59.309345: step 4284, loss -2475.03, acc 0.9375\n",
      "2017-09-12T00:27:59.470746: step 4285, loss -4822.82, acc 0.96875\n",
      "2017-09-12T00:27:59.597822: step 4286, loss -11643.2, acc 0.9375\n",
      "2017-09-12T00:27:59.745753: step 4287, loss -3938.82, acc 0.90625\n",
      "2017-09-12T00:27:59.896099: step 4288, loss -4992.37, acc 0.9375\n",
      "2017-09-12T00:28:00.046956: step 4289, loss -2104.88, acc 0.96875\n",
      "2017-09-12T00:28:00.196185: step 4290, loss -3611.19, acc 0.96875\n",
      "2017-09-12T00:28:00.340081: step 4291, loss -10678.1, acc 0.9375\n",
      "2017-09-12T00:28:00.494749: step 4292, loss 830.356, acc 0.90625\n",
      "2017-09-12T00:28:00.637542: step 4293, loss 531.385, acc 0.84375\n",
      "2017-09-12T00:28:00.772189: step 4294, loss -8823.33, acc 0.96875\n",
      "2017-09-12T00:28:00.935793: step 4295, loss -7813.31, acc 0.96875\n",
      "2017-09-12T00:28:01.082965: step 4296, loss -372.884, acc 0.875\n",
      "2017-09-12T00:28:01.218880: step 4297, loss -3653.75, acc 0.9375\n",
      "2017-09-12T00:28:01.364678: step 4298, loss -2538.13, acc 0.90625\n",
      "2017-09-12T00:28:01.515895: step 4299, loss -6494.49, acc 0.96875\n",
      "2017-09-12T00:28:01.666570: step 4300, loss -7129.72, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:28:03.001540: step 4300, loss -4906.51, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4300\n",
      "\n",
      "2017-09-12T00:28:04.916165: step 4301, loss -7727.74, acc 0.90625\n",
      "2017-09-12T00:28:05.016345: step 4302, loss -2897.08, acc 0.875\n",
      "2017-09-12T00:28:05.116680: step 4303, loss -7521.34, acc 0.9375\n",
      "2017-09-12T00:28:05.217036: step 4304, loss -11870, acc 1\n",
      "2017-09-12T00:28:05.310369: step 4305, loss -8648.66, acc 0.96875\n",
      "2017-09-12T00:28:05.402741: step 4306, loss -2002.32, acc 0.96875\n",
      "2017-09-12T00:28:05.496167: step 4307, loss -1777.49, acc 0.875\n",
      "2017-09-12T00:28:05.590900: step 4308, loss -1204.29, acc 0.9375\n",
      "2017-09-12T00:28:05.683122: step 4309, loss -7826.99, acc 0.90625\n",
      "2017-09-12T00:28:05.781194: step 4310, loss -7400.03, acc 0.9375\n",
      "2017-09-12T00:28:05.876662: step 4311, loss -7423.03, acc 0.9375\n",
      "2017-09-12T00:28:05.968142: step 4312, loss -1514.22, acc 0.90625\n",
      "2017-09-12T00:28:06.058178: step 4313, loss -2785.36, acc 0.875\n",
      "2017-09-12T00:28:06.147156: step 4314, loss 2307.63, acc 0.84375\n",
      "2017-09-12T00:28:06.240315: step 4315, loss -5854.8, acc 0.96875\n",
      "2017-09-12T00:28:06.342895: step 4316, loss -5045.62, acc 0.96875\n",
      "2017-09-12T00:28:06.434628: step 4317, loss -3969.29, acc 0.9375\n",
      "2017-09-12T00:28:06.516895: step 4318, loss -6305.37, acc 1\n",
      "2017-09-12T00:28:06.603366: step 4319, loss -7149.4, acc 0.9375\n",
      "2017-09-12T00:28:06.705212: step 4320, loss -6082.12, acc 0.96875\n",
      "2017-09-12T00:28:06.794270: step 4321, loss -8163.01, acc 0.96875\n",
      "2017-09-12T00:28:07.030817: step 4322, loss -2783.17, acc 0.9375\n",
      "2017-09-12T00:28:07.186068: step 4323, loss -2588.69, acc 0.9375\n",
      "2017-09-12T00:28:07.335201: step 4324, loss -4617.68, acc 0.9375\n",
      "2017-09-12T00:28:07.490503: step 4325, loss -2783.67, acc 0.9375\n",
      "2017-09-12T00:28:07.632362: step 4326, loss -5510.86, acc 0.9375\n",
      "2017-09-12T00:28:07.792147: step 4327, loss -8597.44, acc 0.90625\n",
      "2017-09-12T00:28:07.948111: step 4328, loss 996.465, acc 0.90625\n",
      "2017-09-12T00:28:08.128799: step 4329, loss -3809.44, acc 0.8125\n",
      "2017-09-12T00:28:08.272158: step 4330, loss -2621.21, acc 0.90625\n",
      "2017-09-12T00:28:08.415180: step 4331, loss -8650.42, acc 1\n",
      "2017-09-12T00:28:08.563419: step 4332, loss -9945.27, acc 0.9375\n",
      "2017-09-12T00:28:08.713635: step 4333, loss 2007.94, acc 0.8125\n",
      "2017-09-12T00:28:08.856670: step 4334, loss -3300.15, acc 0.84375\n",
      "2017-09-12T00:28:09.002161: step 4335, loss -3820.36, acc 0.9375\n",
      "2017-09-12T00:28:09.144679: step 4336, loss -1422.94, acc 0.875\n",
      "2017-09-12T00:28:09.291172: step 4337, loss -7470.92, acc 1\n",
      "2017-09-12T00:28:09.445199: step 4338, loss -1201.46, acc 0.875\n",
      "2017-09-12T00:28:09.592363: step 4339, loss -259.455, acc 0.9375\n",
      "2017-09-12T00:28:09.740715: step 4340, loss 864.136, acc 0.875\n",
      "2017-09-12T00:28:09.874122: step 4341, loss -3621.49, acc 0.9375\n",
      "2017-09-12T00:28:10.041698: step 4342, loss -8054.73, acc 0.9375\n",
      "2017-09-12T00:28:10.199173: step 4343, loss 104.287, acc 0.9375\n",
      "2017-09-12T00:28:10.330847: step 4344, loss 1199.65, acc 0.84375\n",
      "2017-09-12T00:28:10.497762: step 4345, loss -1581.12, acc 0.84375\n",
      "2017-09-12T00:28:10.651415: step 4346, loss -1329.64, acc 0.96875\n",
      "2017-09-12T00:28:10.793971: step 4347, loss -4158.38, acc 0.9375\n",
      "2017-09-12T00:28:10.932838: step 4348, loss -3516.9, acc 0.84375\n",
      "2017-09-12T00:28:11.097220: step 4349, loss -2574.94, acc 0.875\n",
      "2017-09-12T00:28:11.246784: step 4350, loss -6456.77, acc 0.9375\n",
      "2017-09-12T00:28:11.463009: step 4351, loss -6680.05, acc 0.9375\n",
      "2017-09-12T00:28:11.616225: step 4352, loss 2217.38, acc 0.8125\n",
      "2017-09-12T00:28:11.768715: step 4353, loss -2754.8, acc 0.96875\n",
      "2017-09-12T00:28:11.896871: step 4354, loss -5027.93, acc 0.90625\n",
      "2017-09-12T00:28:12.051613: step 4355, loss -2533.98, acc 0.90625\n",
      "2017-09-12T00:28:12.212250: step 4356, loss -1688.84, acc 0.90625\n",
      "2017-09-12T00:28:12.336745: step 4357, loss -6535.55, acc 0.9375\n",
      "2017-09-12T00:28:12.496604: step 4358, loss -5166.44, acc 0.90625\n",
      "2017-09-12T00:28:12.640581: step 4359, loss -7477.56, acc 1\n",
      "2017-09-12T00:28:12.777550: step 4360, loss -414.844, acc 0.90625\n",
      "2017-09-12T00:28:12.936479: step 4361, loss -1238.73, acc 0.84375\n",
      "2017-09-12T00:28:13.070835: step 4362, loss -3943.04, acc 0.90625\n",
      "2017-09-12T00:28:13.217420: step 4363, loss -3195.04, acc 0.90625\n",
      "2017-09-12T00:28:13.361179: step 4364, loss -8032.18, acc 0.90625\n",
      "2017-09-12T00:28:13.507760: step 4365, loss -3100.29, acc 0.875\n",
      "2017-09-12T00:28:13.655620: step 4366, loss -4183.98, acc 0.9375\n",
      "2017-09-12T00:28:13.789580: step 4367, loss -4197.09, acc 0.9375\n",
      "2017-09-12T00:28:13.931210: step 4368, loss -2531.03, acc 0.9375\n",
      "2017-09-12T00:28:14.080774: step 4369, loss -4252.86, acc 0.9375\n",
      "2017-09-12T00:28:14.231694: step 4370, loss -6263.01, acc 0.96875\n",
      "2017-09-12T00:28:14.374864: step 4371, loss -7821.85, acc 0.9375\n",
      "2017-09-12T00:28:14.513519: step 4372, loss 111.913, acc 0.90625\n",
      "2017-09-12T00:28:14.664308: step 4373, loss 3300.07, acc 0.84375\n",
      "2017-09-12T00:28:14.812427: step 4374, loss -7630.98, acc 1\n",
      "2017-09-12T00:28:14.954091: step 4375, loss -1114.7, acc 0.875\n",
      "2017-09-12T00:28:15.093627: step 4376, loss -1616.97, acc 0.9375\n",
      "2017-09-12T00:28:15.250752: step 4377, loss -9958.05, acc 1\n",
      "2017-09-12T00:28:15.397728: step 4378, loss -1731.35, acc 0.90625\n",
      "2017-09-12T00:28:15.536351: step 4379, loss -3029.29, acc 0.90625\n",
      "2017-09-12T00:28:15.680134: step 4380, loss -5261.13, acc 1\n",
      "2017-09-12T00:28:15.833026: step 4381, loss -7770.11, acc 0.9375\n",
      "2017-09-12T00:28:15.985050: step 4382, loss -2405.63, acc 0.9375\n",
      "2017-09-12T00:28:16.150594: step 4383, loss -8050.46, acc 0.875\n",
      "2017-09-12T00:28:16.299273: step 4384, loss -444.782, acc 0.84375\n",
      "2017-09-12T00:28:16.438288: step 4385, loss -2724.9, acc 0.875\n",
      "2017-09-12T00:28:16.591816: step 4386, loss -4979.15, acc 0.9375\n",
      "2017-09-12T00:28:16.753056: step 4387, loss -6318.64, acc 1\n",
      "2017-09-12T00:28:16.892155: step 4388, loss -5506.99, acc 0.96875\n",
      "2017-09-12T00:28:17.044873: step 4389, loss -2341.51, acc 0.9375\n",
      "2017-09-12T00:28:17.192344: step 4390, loss -4990.11, acc 1\n",
      "2017-09-12T00:28:17.342077: step 4391, loss -2608.14, acc 0.9375\n",
      "2017-09-12T00:28:17.496065: step 4392, loss -5477.81, acc 0.9375\n",
      "2017-09-12T00:28:17.651232: step 4393, loss -3871.63, acc 0.9375\n",
      "2017-09-12T00:28:17.797859: step 4394, loss -6693.82, acc 0.96875\n",
      "2017-09-12T00:28:17.953045: step 4395, loss 1140.43, acc 0.84375\n",
      "2017-09-12T00:28:18.092021: step 4396, loss -5733, acc 0.9375\n",
      "2017-09-12T00:28:18.247017: step 4397, loss -1266.11, acc 0.84375\n",
      "2017-09-12T00:28:18.364587: step 4398, loss -10551.1, acc 1\n",
      "2017-09-12T00:28:18.530246: step 4399, loss -6458.46, acc 0.9375\n",
      "2017-09-12T00:28:18.664657: step 4400, loss -10034.5, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:28:19.919379: step 4400, loss -5170.17, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4400\n",
      "\n",
      "2017-09-12T00:28:21.908211: step 4401, loss -5257.83, acc 0.9375\n",
      "2017-09-12T00:28:22.011072: step 4402, loss 4765.48, acc 0.84375\n",
      "2017-09-12T00:28:22.111998: step 4403, loss -2024.15, acc 0.9375\n",
      "2017-09-12T00:28:22.207467: step 4404, loss -8152.48, acc 0.96875\n",
      "2017-09-12T00:28:22.308227: step 4405, loss -2420.37, acc 0.96875\n",
      "2017-09-12T00:28:22.399454: step 4406, loss -5696.91, acc 0.90625\n",
      "2017-09-12T00:28:22.497989: step 4407, loss -4165.1, acc 0.90625\n",
      "2017-09-12T00:28:22.595535: step 4408, loss -2811.52, acc 0.9375\n",
      "2017-09-12T00:28:22.690329: step 4409, loss -10205.8, acc 1\n",
      "2017-09-12T00:28:22.781893: step 4410, loss 1004.91, acc 0.84375\n",
      "2017-09-12T00:28:22.874552: step 4411, loss -1652.46, acc 0.90625\n",
      "2017-09-12T00:28:22.971125: step 4412, loss -1674.12, acc 0.90625\n",
      "2017-09-12T00:28:23.067784: step 4413, loss -7553.08, acc 0.96875\n",
      "2017-09-12T00:28:23.160047: step 4414, loss -6694.9, acc 0.96875\n",
      "2017-09-12T00:28:23.252067: step 4415, loss -12703.9, acc 1\n",
      "2017-09-12T00:28:23.340993: step 4416, loss -6142.82, acc 0.9375\n",
      "2017-09-12T00:28:23.439262: step 4417, loss -705.975, acc 0.8125\n",
      "2017-09-12T00:28:23.531933: step 4418, loss -8692.32, acc 1\n",
      "2017-09-12T00:28:23.622040: step 4419, loss -9787.42, acc 0.9375\n",
      "2017-09-12T00:28:23.903718: step 4420, loss -6204.18, acc 0.96875\n",
      "2017-09-12T00:28:24.047505: step 4421, loss -23.0853, acc 0.9375\n",
      "2017-09-12T00:28:24.198315: step 4422, loss -4429.68, acc 0.90625\n",
      "2017-09-12T00:28:24.346711: step 4423, loss -6906.03, acc 0.9375\n",
      "2017-09-12T00:28:24.489727: step 4424, loss -6553.32, acc 0.9375\n",
      "2017-09-12T00:28:24.640806: step 4425, loss -10949, acc 1\n",
      "2017-09-12T00:28:24.778073: step 4426, loss -3821.98, acc 0.9375\n",
      "2017-09-12T00:28:24.929256: step 4427, loss -3927.48, acc 0.96875\n",
      "2017-09-12T00:28:25.074039: step 4428, loss 1483.86, acc 0.90625\n",
      "2017-09-12T00:28:25.221058: step 4429, loss 2643.77, acc 0.90625\n",
      "2017-09-12T00:28:25.363485: step 4430, loss -1149.11, acc 0.84375\n",
      "2017-09-12T00:28:25.512519: step 4431, loss -8988.35, acc 0.9375\n",
      "2017-09-12T00:28:25.658048: step 4432, loss -6830.8, acc 0.90625\n",
      "2017-09-12T00:28:25.792133: step 4433, loss -7046.35, acc 0.9375\n",
      "2017-09-12T00:28:25.948126: step 4434, loss 758.884, acc 0.8125\n",
      "2017-09-12T00:28:26.090869: step 4435, loss -11490.5, acc 1\n",
      "2017-09-12T00:28:26.239924: step 4436, loss -4854.99, acc 1\n",
      "2017-09-12T00:28:26.377490: step 4437, loss -330.839, acc 0.875\n",
      "2017-09-12T00:28:26.515861: step 4438, loss -5617.87, acc 0.9375\n",
      "2017-09-12T00:28:26.662787: step 4439, loss -2808.16, acc 0.96875\n",
      "2017-09-12T00:28:26.804591: step 4440, loss -1676.21, acc 0.90625\n",
      "2017-09-12T00:28:26.956010: step 4441, loss -1405.04, acc 0.9375\n",
      "2017-09-12T00:28:27.096394: step 4442, loss -4626.73, acc 0.9375\n",
      "2017-09-12T00:28:27.244006: step 4443, loss -1631.88, acc 0.90625\n",
      "2017-09-12T00:28:27.389145: step 4444, loss -5040.39, acc 0.96875\n",
      "2017-09-12T00:28:27.535927: step 4445, loss -3893.03, acc 0.875\n",
      "2017-09-12T00:28:27.671686: step 4446, loss -9302.52, acc 0.96875\n",
      "2017-09-12T00:28:27.823217: step 4447, loss -7672.44, acc 0.90625\n",
      "2017-09-12T00:28:27.963954: step 4448, loss -2571.6, acc 0.96875\n",
      "2017-09-12T00:28:28.098180: step 4449, loss -5454.29, acc 0.9375\n",
      "2017-09-12T00:28:28.245967: step 4450, loss -5413.49, acc 0.96875\n",
      "2017-09-12T00:28:28.397006: step 4451, loss -2979.69, acc 0.90625\n",
      "2017-09-12T00:28:28.542282: step 4452, loss -4065.97, acc 0.9375\n",
      "2017-09-12T00:28:28.684590: step 4453, loss -3227.79, acc 0.9375\n",
      "2017-09-12T00:28:28.831450: step 4454, loss -3014.64, acc 0.90625\n",
      "2017-09-12T00:28:28.980639: step 4455, loss -13904.4, acc 1\n",
      "2017-09-12T00:28:29.117836: step 4456, loss -9303.75, acc 0.90625\n",
      "2017-09-12T00:28:29.268097: step 4457, loss -5521.82, acc 0.9375\n",
      "2017-09-12T00:28:29.409603: step 4458, loss -1279.82, acc 0.90625\n",
      "2017-09-12T00:28:29.563823: step 4459, loss -2954.25, acc 0.90625\n",
      "2017-09-12T00:28:29.712239: step 4460, loss -6850.61, acc 0.84375\n",
      "2017-09-12T00:28:29.854195: step 4461, loss -13073.9, acc 1\n",
      "2017-09-12T00:28:30.014012: step 4462, loss -1873.46, acc 0.90625\n",
      "2017-09-12T00:28:30.150392: step 4463, loss -5781.48, acc 0.9375\n",
      "2017-09-12T00:28:30.291122: step 4464, loss -2785.77, acc 0.9375\n",
      "2017-09-12T00:28:30.433042: step 4465, loss -9139.46, acc 1\n",
      "2017-09-12T00:28:30.577261: step 4466, loss -8213.57, acc 0.90625\n",
      "2017-09-12T00:28:30.727548: step 4467, loss -13927.1, acc 0.96875\n",
      "2017-09-12T00:28:30.875889: step 4468, loss -10747.9, acc 0.9375\n",
      "2017-09-12T00:28:31.013207: step 4469, loss -7702.44, acc 1\n",
      "2017-09-12T00:28:31.170140: step 4470, loss -8594.78, acc 1\n",
      "2017-09-12T00:28:31.212948: step 4471, loss 3648.4, acc 0.75\n",
      "2017-09-12T00:28:31.370527: step 4472, loss -5386.28, acc 0.96875\n",
      "2017-09-12T00:28:31.512936: step 4473, loss 2153.39, acc 0.8125\n",
      "2017-09-12T00:28:31.647927: step 4474, loss -7181.95, acc 0.9375\n",
      "2017-09-12T00:28:31.793240: step 4475, loss -1486.16, acc 0.875\n",
      "2017-09-12T00:28:31.953790: step 4476, loss -7143.44, acc 1\n",
      "2017-09-12T00:28:32.096416: step 4477, loss -14679.1, acc 1\n",
      "2017-09-12T00:28:32.237234: step 4478, loss -7835.81, acc 0.9375\n",
      "2017-09-12T00:28:32.377641: step 4479, loss -9003.3, acc 0.9375\n",
      "2017-09-12T00:28:32.528997: step 4480, loss -7455.42, acc 0.96875\n",
      "2017-09-12T00:28:32.666490: step 4481, loss -1831.22, acc 0.9375\n",
      "2017-09-12T00:28:32.810829: step 4482, loss -6906.95, acc 0.90625\n",
      "2017-09-12T00:28:32.963188: step 4483, loss -6834.16, acc 0.96875\n",
      "2017-09-12T00:28:33.109420: step 4484, loss -4.93848, acc 0.90625\n",
      "2017-09-12T00:28:33.251015: step 4485, loss -8218.31, acc 0.9375\n",
      "2017-09-12T00:28:33.399571: step 4486, loss 2696.48, acc 0.84375\n",
      "2017-09-12T00:28:33.558450: step 4487, loss -8685.82, acc 0.96875\n",
      "2017-09-12T00:28:33.703366: step 4488, loss -4972.67, acc 0.84375\n",
      "2017-09-12T00:28:33.857700: step 4489, loss 2823.25, acc 0.875\n",
      "2017-09-12T00:28:34.002541: step 4490, loss -1905.76, acc 0.875\n",
      "2017-09-12T00:28:34.150576: step 4491, loss -6690.68, acc 0.9375\n",
      "2017-09-12T00:28:34.291511: step 4492, loss 1102.58, acc 0.84375\n",
      "2017-09-12T00:28:34.435796: step 4493, loss 1581.12, acc 0.875\n",
      "2017-09-12T00:28:34.575485: step 4494, loss -5813.67, acc 0.9375\n",
      "2017-09-12T00:28:34.727768: step 4495, loss -1499.98, acc 0.96875\n",
      "2017-09-12T00:28:34.882086: step 4496, loss -8245.91, acc 0.90625\n",
      "2017-09-12T00:28:35.033372: step 4497, loss -14881.4, acc 1\n",
      "2017-09-12T00:28:35.172296: step 4498, loss -4236.58, acc 0.9375\n",
      "2017-09-12T00:28:35.320069: step 4499, loss -3027.49, acc 0.9375\n",
      "2017-09-12T00:28:35.471547: step 4500, loss -4070.28, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:28:36.770756: step 4500, loss -5482.68, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4500\n",
      "\n",
      "2017-09-12T00:28:38.426075: step 4501, loss -12362.2, acc 0.96875\n",
      "2017-09-12T00:28:38.506496: step 4502, loss -3554.57, acc 0.9375\n",
      "2017-09-12T00:28:38.628886: step 4503, loss -7143.61, acc 1\n",
      "2017-09-12T00:28:38.735276: step 4504, loss -1824.29, acc 0.90625\n",
      "2017-09-12T00:28:38.837550: step 4505, loss -5854.74, acc 0.90625\n",
      "2017-09-12T00:28:38.943644: step 4506, loss -4298.6, acc 0.9375\n",
      "2017-09-12T00:28:39.047007: step 4507, loss -2910.08, acc 0.9375\n",
      "2017-09-12T00:28:39.153738: step 4508, loss 543.41, acc 0.84375\n",
      "2017-09-12T00:28:39.262118: step 4509, loss 1930.86, acc 0.84375\n",
      "2017-09-12T00:28:39.365302: step 4510, loss -5659.15, acc 0.96875\n",
      "2017-09-12T00:28:39.454859: step 4511, loss -2266.94, acc 0.875\n",
      "2017-09-12T00:28:39.548244: step 4512, loss -11122.6, acc 0.9375\n",
      "2017-09-12T00:28:39.645477: step 4513, loss -4199.19, acc 0.90625\n",
      "2017-09-12T00:28:39.731033: step 4514, loss 532.736, acc 0.84375\n",
      "2017-09-12T00:28:39.830689: step 4515, loss -3319.63, acc 0.9375\n",
      "2017-09-12T00:28:39.927133: step 4516, loss -3170.92, acc 0.90625\n",
      "2017-09-12T00:28:40.017167: step 4517, loss -4962.47, acc 0.875\n",
      "2017-09-12T00:28:40.110006: step 4518, loss -4180.21, acc 0.90625\n",
      "2017-09-12T00:28:40.210506: step 4519, loss -4171.91, acc 1\n",
      "2017-09-12T00:28:40.305581: step 4520, loss -4114.27, acc 0.9375\n",
      "2017-09-12T00:28:40.401851: step 4521, loss -4207.76, acc 0.96875\n",
      "2017-09-12T00:28:40.491612: step 4522, loss 2941.07, acc 0.875\n",
      "2017-09-12T00:28:40.671299: step 4523, loss -29.1093, acc 0.90625\n",
      "2017-09-12T00:28:40.887687: step 4524, loss -2522.57, acc 0.90625\n",
      "2017-09-12T00:28:41.027629: step 4525, loss -1497.49, acc 0.9375\n",
      "2017-09-12T00:28:41.177455: step 4526, loss -4144.37, acc 0.96875\n",
      "2017-09-12T00:28:41.327046: step 4527, loss -5725.62, acc 0.9375\n",
      "2017-09-12T00:28:41.461168: step 4528, loss 3867.25, acc 0.84375\n",
      "2017-09-12T00:28:41.608650: step 4529, loss 4271.03, acc 0.84375\n",
      "2017-09-12T00:28:41.758418: step 4530, loss -8468.09, acc 0.96875\n",
      "2017-09-12T00:28:41.902995: step 4531, loss -2690.46, acc 0.875\n",
      "2017-09-12T00:28:42.047382: step 4532, loss -1517.54, acc 0.90625\n",
      "2017-09-12T00:28:42.205080: step 4533, loss 3130.73, acc 0.78125\n",
      "2017-09-12T00:28:42.351735: step 4534, loss -3415.63, acc 0.875\n",
      "2017-09-12T00:28:42.496815: step 4535, loss -936.541, acc 0.875\n",
      "2017-09-12T00:28:42.646929: step 4536, loss -167.87, acc 0.84375\n",
      "2017-09-12T00:28:42.790814: step 4537, loss -5567.03, acc 0.96875\n",
      "2017-09-12T00:28:42.945405: step 4538, loss -5711.2, acc 0.9375\n",
      "2017-09-12T00:28:43.092383: step 4539, loss -7243.12, acc 0.96875\n",
      "2017-09-12T00:28:43.233556: step 4540, loss -1514.42, acc 0.90625\n",
      "2017-09-12T00:28:43.374847: step 4541, loss -9366.85, acc 1\n",
      "2017-09-12T00:28:43.538744: step 4542, loss -10435.4, acc 0.9375\n",
      "2017-09-12T00:28:43.652895: step 4543, loss -2697.71, acc 0.875\n",
      "2017-09-12T00:28:43.805071: step 4544, loss -4555.28, acc 0.875\n",
      "2017-09-12T00:28:43.948497: step 4545, loss -5745.67, acc 0.90625\n",
      "2017-09-12T00:28:44.088765: step 4546, loss -6801.58, acc 0.96875\n",
      "2017-09-12T00:28:44.255541: step 4547, loss -8528.37, acc 0.96875\n",
      "2017-09-12T00:28:44.397880: step 4548, loss -5198.45, acc 0.9375\n",
      "2017-09-12T00:28:44.544363: step 4549, loss -6149.5, acc 0.96875\n",
      "2017-09-12T00:28:44.689632: step 4550, loss -5726.77, acc 0.9375\n",
      "2017-09-12T00:28:44.836994: step 4551, loss -4170.23, acc 0.90625\n",
      "2017-09-12T00:28:44.984240: step 4552, loss -4206.54, acc 0.90625\n",
      "2017-09-12T00:28:45.122246: step 4553, loss -7390.8, acc 0.9375\n",
      "2017-09-12T00:28:45.263292: step 4554, loss -1801.67, acc 0.90625\n",
      "2017-09-12T00:28:45.409379: step 4555, loss -572.314, acc 0.8125\n",
      "2017-09-12T00:28:45.558465: step 4556, loss -5953.7, acc 0.96875\n",
      "2017-09-12T00:28:45.698422: step 4557, loss -2760.56, acc 0.9375\n",
      "2017-09-12T00:28:45.833934: step 4558, loss -263.011, acc 0.875\n",
      "2017-09-12T00:28:45.987644: step 4559, loss 2763.79, acc 0.875\n",
      "2017-09-12T00:28:46.128388: step 4560, loss -340.299, acc 0.84375\n",
      "2017-09-12T00:28:46.266788: step 4561, loss -10545.9, acc 0.96875\n",
      "2017-09-12T00:28:46.425029: step 4562, loss -4097.58, acc 0.90625\n",
      "2017-09-12T00:28:46.570320: step 4563, loss -5394.02, acc 0.9375\n",
      "2017-09-12T00:28:46.724443: step 4564, loss -11180.6, acc 0.9375\n",
      "2017-09-12T00:28:46.863335: step 4565, loss 897.432, acc 0.84375\n",
      "2017-09-12T00:28:47.015033: step 4566, loss -10107, acc 0.9375\n",
      "2017-09-12T00:28:47.163079: step 4567, loss -8319.19, acc 0.90625\n",
      "2017-09-12T00:28:47.322248: step 4568, loss -8749.55, acc 0.96875\n",
      "2017-09-12T00:28:47.467208: step 4569, loss -1255.7, acc 0.9375\n",
      "2017-09-12T00:28:47.616502: step 4570, loss -8189.44, acc 0.9375\n",
      "2017-09-12T00:28:47.755827: step 4571, loss -2702.75, acc 0.875\n",
      "2017-09-12T00:28:47.908700: step 4572, loss -3090.35, acc 0.875\n",
      "2017-09-12T00:28:48.047916: step 4573, loss -166.203, acc 0.875\n",
      "2017-09-12T00:28:48.193451: step 4574, loss -7484.8, acc 0.96875\n",
      "2017-09-12T00:28:48.337500: step 4575, loss -6225.17, acc 0.96875\n",
      "2017-09-12T00:28:48.475892: step 4576, loss -10527.9, acc 0.9375\n",
      "2017-09-12T00:28:48.624295: step 4577, loss -1858.75, acc 0.9375\n",
      "2017-09-12T00:28:48.776120: step 4578, loss -4333.14, acc 0.96875\n",
      "2017-09-12T00:28:48.931509: step 4579, loss -4399.72, acc 0.9375\n",
      "2017-09-12T00:28:49.087611: step 4580, loss -9969.75, acc 0.9375\n",
      "2017-09-12T00:28:49.228591: step 4581, loss -11333.5, acc 1\n",
      "2017-09-12T00:28:49.378195: step 4582, loss -8619.92, acc 0.9375\n",
      "2017-09-12T00:28:49.523800: step 4583, loss -12015.4, acc 1\n",
      "2017-09-12T00:28:49.671468: step 4584, loss -3101.2, acc 0.90625\n",
      "2017-09-12T00:28:49.832404: step 4585, loss -6371.52, acc 0.90625\n",
      "2017-09-12T00:28:49.969906: step 4586, loss -3029.16, acc 0.90625\n",
      "2017-09-12T00:28:50.133295: step 4587, loss -4196.27, acc 0.90625\n",
      "2017-09-12T00:28:50.280485: step 4588, loss -9716.18, acc 0.96875\n",
      "2017-09-12T00:28:50.433121: step 4589, loss -8583.54, acc 0.96875\n",
      "2017-09-12T00:28:50.573372: step 4590, loss -683.648, acc 0.8125\n",
      "2017-09-12T00:28:50.727851: step 4591, loss -138.364, acc 0.9375\n",
      "2017-09-12T00:28:50.881704: step 4592, loss -6190.37, acc 0.875\n",
      "2017-09-12T00:28:51.036816: step 4593, loss -2930.4, acc 0.90625\n",
      "2017-09-12T00:28:51.179316: step 4594, loss -9104.85, acc 0.96875\n",
      "2017-09-12T00:28:51.327226: step 4595, loss -8807.74, acc 1\n",
      "2017-09-12T00:28:51.465483: step 4596, loss -3385.37, acc 0.9375\n",
      "2017-09-12T00:28:51.616213: step 4597, loss -9181.45, acc 1\n",
      "2017-09-12T00:28:51.761727: step 4598, loss -3101.94, acc 0.96875\n",
      "2017-09-12T00:28:51.935876: step 4599, loss -5946.64, acc 0.96875\n",
      "2017-09-12T00:28:52.067302: step 4600, loss -8431.18, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:28:53.350799: step 4600, loss -5753.4, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4600\n",
      "\n",
      "2017-09-12T00:28:55.388926: step 4601, loss -11778.6, acc 0.96875\n",
      "2017-09-12T00:28:55.484873: step 4602, loss -8305.71, acc 0.96875\n",
      "2017-09-12T00:28:55.586122: step 4603, loss 2374.02, acc 0.84375\n",
      "2017-09-12T00:28:55.688429: step 4604, loss -7906.77, acc 0.96875\n",
      "2017-09-12T00:28:55.785831: step 4605, loss -6809.8, acc 0.9375\n",
      "2017-09-12T00:28:55.891735: step 4606, loss -2581.58, acc 0.84375\n",
      "2017-09-12T00:28:55.992749: step 4607, loss -5588.34, acc 0.9375\n",
      "2017-09-12T00:28:56.085941: step 4608, loss 1122.7, acc 0.90625\n",
      "2017-09-12T00:28:56.183133: step 4609, loss -2190.63, acc 0.9375\n",
      "2017-09-12T00:28:56.279863: step 4610, loss -8455.87, acc 0.9375\n",
      "2017-09-12T00:28:56.369317: step 4611, loss -6497.45, acc 0.90625\n",
      "2017-09-12T00:28:56.471364: step 4612, loss -9280.04, acc 0.96875\n",
      "2017-09-12T00:28:56.561418: step 4613, loss -4614.54, acc 0.90625\n",
      "2017-09-12T00:28:56.650522: step 4614, loss -7581.02, acc 1\n",
      "2017-09-12T00:28:56.741456: step 4615, loss -8796.32, acc 1\n",
      "2017-09-12T00:28:56.832733: step 4616, loss -2927.81, acc 0.9375\n",
      "2017-09-12T00:28:56.925303: step 4617, loss -5116.31, acc 0.90625\n",
      "2017-09-12T00:28:57.086985: step 4618, loss -4033.61, acc 0.9375\n",
      "2017-09-12T00:28:57.320740: step 4619, loss -4315.74, acc 0.9375\n",
      "2017-09-12T00:28:57.462122: step 4620, loss -6006.2, acc 0.9375\n",
      "2017-09-12T00:28:57.553592: step 4621, loss -4262.73, acc 0.90625\n",
      "2017-09-12T00:28:57.685471: step 4622, loss -3211.08, acc 0.875\n",
      "2017-09-12T00:28:57.835876: step 4623, loss -13230.8, acc 0.96875\n",
      "2017-09-12T00:28:57.978265: step 4624, loss -3788.48, acc 0.90625\n",
      "2017-09-12T00:28:58.121443: step 4625, loss -8981.43, acc 0.96875\n",
      "2017-09-12T00:28:58.264926: step 4626, loss -2514.61, acc 0.875\n",
      "2017-09-12T00:28:58.418262: step 4627, loss -7741.19, acc 0.9375\n",
      "2017-09-12T00:28:58.563897: step 4628, loss -3641.54, acc 0.90625\n",
      "2017-09-12T00:28:58.709526: step 4629, loss 1225.64, acc 0.875\n",
      "2017-09-12T00:28:58.860415: step 4630, loss -4149.74, acc 0.90625\n",
      "2017-09-12T00:28:59.002050: step 4631, loss -15.0049, acc 0.90625\n",
      "2017-09-12T00:28:59.152477: step 4632, loss -10557.6, acc 0.9375\n",
      "2017-09-12T00:28:59.296750: step 4633, loss -6122.33, acc 1\n",
      "2017-09-12T00:28:59.446044: step 4634, loss -424.097, acc 0.875\n",
      "2017-09-12T00:28:59.593296: step 4635, loss -6715.95, acc 0.96875\n",
      "2017-09-12T00:28:59.700925: step 4636, loss -1764.11, acc 0.84375\n",
      "2017-09-12T00:28:59.851189: step 4637, loss -10646.6, acc 1\n",
      "2017-09-12T00:28:59.998557: step 4638, loss -4609.27, acc 1\n",
      "2017-09-12T00:29:00.150856: step 4639, loss -8587.79, acc 0.96875\n",
      "2017-09-12T00:29:00.288184: step 4640, loss -1930.57, acc 0.875\n",
      "2017-09-12T00:29:00.440286: step 4641, loss -5155.46, acc 0.875\n",
      "2017-09-12T00:29:00.568571: step 4642, loss -5512.29, acc 0.9375\n",
      "2017-09-12T00:29:00.761069: step 4643, loss -5212.34, acc 0.90625\n",
      "2017-09-12T00:29:00.929362: step 4644, loss 1306.45, acc 0.875\n",
      "2017-09-12T00:29:01.072855: step 4645, loss -4341.22, acc 1\n",
      "2017-09-12T00:29:01.240046: step 4646, loss -3076.36, acc 0.9375\n",
      "2017-09-12T00:29:01.472850: step 4647, loss -7230.5, acc 0.96875\n",
      "2017-09-12T00:29:01.629707: step 4648, loss -1804.47, acc 0.90625\n",
      "2017-09-12T00:29:01.792072: step 4649, loss -2565.88, acc 0.9375\n",
      "2017-09-12T00:29:02.049464: step 4650, loss -4293.7, acc 0.90625\n",
      "2017-09-12T00:29:02.250928: step 4651, loss -7536.78, acc 0.9375\n",
      "2017-09-12T00:29:02.445722: step 4652, loss -1846.74, acc 0.9375\n",
      "2017-09-12T00:29:02.591403: step 4653, loss -1236.31, acc 0.84375\n",
      "2017-09-12T00:29:02.738356: step 4654, loss -5409.69, acc 0.9375\n",
      "2017-09-12T00:29:02.874203: step 4655, loss -79.8845, acc 0.96875\n",
      "2017-09-12T00:29:03.021560: step 4656, loss -10497.1, acc 0.96875\n",
      "2017-09-12T00:29:03.169532: step 4657, loss -15005.7, acc 1\n",
      "2017-09-12T00:29:03.315335: step 4658, loss -3258.2, acc 0.90625\n",
      "2017-09-12T00:29:03.466040: step 4659, loss -7491.03, acc 0.90625\n",
      "2017-09-12T00:29:03.614347: step 4660, loss -4263.87, acc 0.9375\n",
      "2017-09-12T00:29:03.766345: step 4661, loss -6283.53, acc 0.90625\n",
      "2017-09-12T00:29:03.909750: step 4662, loss -10278.1, acc 1\n",
      "2017-09-12T00:29:04.071175: step 4663, loss -6300.79, acc 0.96875\n",
      "2017-09-12T00:29:04.246406: step 4664, loss -1901.82, acc 0.90625\n",
      "2017-09-12T00:29:04.385109: step 4665, loss -2057.45, acc 0.84375\n",
      "2017-09-12T00:29:04.629307: step 4666, loss -5223.28, acc 0.90625\n",
      "2017-09-12T00:29:04.735878: step 4667, loss -6123.68, acc 0.84375\n",
      "2017-09-12T00:29:04.884626: step 4668, loss -4587.58, acc 0.90625\n",
      "2017-09-12T00:29:05.035246: step 4669, loss -9355.01, acc 0.96875\n",
      "2017-09-12T00:29:05.183287: step 4670, loss -7387.93, acc 0.90625\n",
      "2017-09-12T00:29:05.335573: step 4671, loss -5969.66, acc 0.96875\n",
      "2017-09-12T00:29:05.482773: step 4672, loss -1716.37, acc 0.9375\n",
      "2017-09-12T00:29:05.638842: step 4673, loss -13771.8, acc 0.90625\n",
      "2017-09-12T00:29:05.777341: step 4674, loss -5955.39, acc 1\n",
      "2017-09-12T00:29:05.928389: step 4675, loss -11692.1, acc 0.96875\n",
      "2017-09-12T00:29:06.072515: step 4676, loss 2653.8, acc 0.8125\n",
      "2017-09-12T00:29:06.220535: step 4677, loss -9606.79, acc 0.96875\n",
      "2017-09-12T00:29:06.370916: step 4678, loss -6399.74, acc 0.9375\n",
      "2017-09-12T00:29:06.509870: step 4679, loss -2113.3, acc 0.875\n",
      "2017-09-12T00:29:06.659850: step 4680, loss -2143.61, acc 0.875\n",
      "2017-09-12T00:29:06.792865: step 4681, loss -15736.6, acc 0.96875\n",
      "2017-09-12T00:29:06.938277: step 4682, loss -5890.55, acc 0.9375\n",
      "2017-09-12T00:29:07.101184: step 4683, loss -10884.9, acc 0.9375\n",
      "2017-09-12T00:29:07.253868: step 4684, loss -7256.34, acc 0.90625\n",
      "2017-09-12T00:29:07.397266: step 4685, loss -5849.09, acc 0.96875\n",
      "2017-09-12T00:29:07.535563: step 4686, loss -6413.74, acc 0.9375\n",
      "2017-09-12T00:29:07.691562: step 4687, loss -10764.7, acc 0.96875\n",
      "2017-09-12T00:29:07.838195: step 4688, loss -233.517, acc 0.875\n",
      "2017-09-12T00:29:07.993311: step 4689, loss -6380.31, acc 0.96875\n",
      "2017-09-12T00:29:08.150349: step 4690, loss -9684.28, acc 1\n",
      "2017-09-12T00:29:08.304114: step 4691, loss -10937.2, acc 0.84375\n",
      "2017-09-12T00:29:08.482497: step 4692, loss -15057.5, acc 1\n",
      "2017-09-12T00:29:08.633163: step 4693, loss -9649.41, acc 0.96875\n",
      "2017-09-12T00:29:08.783230: step 4694, loss -2881.05, acc 0.96875\n",
      "2017-09-12T00:29:08.936798: step 4695, loss -6218.66, acc 0.96875\n",
      "2017-09-12T00:29:09.072859: step 4696, loss -370.93, acc 0.9375\n",
      "2017-09-12T00:29:09.214880: step 4697, loss -10526.2, acc 1\n",
      "2017-09-12T00:29:09.360353: step 4698, loss -8082.21, acc 0.9375\n",
      "2017-09-12T00:29:09.495750: step 4699, loss -7518.12, acc 0.96875\n",
      "2017-09-12T00:29:09.661208: step 4700, loss -6352.41, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:29:10.960696: step 4700, loss -6091.74, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4700\n",
      "\n",
      "2017-09-12T00:29:12.868803: step 4701, loss -10058.5, acc 0.9375\n",
      "2017-09-12T00:29:12.969713: step 4702, loss 1763.59, acc 0.8125\n",
      "2017-09-12T00:29:13.068278: step 4703, loss 1143.4, acc 0.875\n",
      "2017-09-12T00:29:13.168178: step 4704, loss -13774.3, acc 1\n",
      "2017-09-12T00:29:13.259736: step 4705, loss -1558.76, acc 0.9375\n",
      "2017-09-12T00:29:13.349215: step 4706, loss -2796.87, acc 0.9375\n",
      "2017-09-12T00:29:13.446820: step 4707, loss -16047.4, acc 0.90625\n",
      "2017-09-12T00:29:13.547295: step 4708, loss -4975.23, acc 0.9375\n",
      "2017-09-12T00:29:13.635176: step 4709, loss -10589.4, acc 0.875\n",
      "2017-09-12T00:29:13.726134: step 4710, loss -3802.24, acc 0.90625\n",
      "2017-09-12T00:29:13.814081: step 4711, loss -3658.51, acc 0.875\n",
      "2017-09-12T00:29:13.905546: step 4712, loss -2952.46, acc 0.9375\n",
      "2017-09-12T00:29:13.995894: step 4713, loss -8521.35, acc 0.90625\n",
      "2017-09-12T00:29:14.088728: step 4714, loss 2792.31, acc 0.875\n",
      "2017-09-12T00:29:14.178024: step 4715, loss -10513.1, acc 0.9375\n",
      "2017-09-12T00:29:14.273170: step 4716, loss -6706.57, acc 0.9375\n",
      "2017-09-12T00:29:14.363470: step 4717, loss -6675.54, acc 1\n",
      "2017-09-12T00:29:14.453817: step 4718, loss -688.003, acc 0.90625\n",
      "2017-09-12T00:29:14.728376: step 4719, loss -10226, acc 1\n",
      "2017-09-12T00:29:14.877319: step 4720, loss -7459.05, acc 0.96875\n",
      "2017-09-12T00:29:15.020340: step 4721, loss 305.334, acc 0.875\n",
      "2017-09-12T00:29:15.170658: step 4722, loss -4997.29, acc 0.9375\n",
      "2017-09-12T00:29:15.319921: step 4723, loss 3104.35, acc 0.90625\n",
      "2017-09-12T00:29:15.463836: step 4724, loss -7002.69, acc 0.9375\n",
      "2017-09-12T00:29:15.601099: step 4725, loss -3469.48, acc 0.90625\n",
      "2017-09-12T00:29:15.767296: step 4726, loss 3028.85, acc 0.84375\n",
      "2017-09-12T00:29:15.903480: step 4727, loss -10636.3, acc 0.96875\n",
      "2017-09-12T00:29:16.050562: step 4728, loss -7807.35, acc 0.9375\n",
      "2017-09-12T00:29:16.194517: step 4729, loss -3324.13, acc 0.9375\n",
      "2017-09-12T00:29:16.347598: step 4730, loss -7663.9, acc 0.9375\n",
      "2017-09-12T00:29:16.490404: step 4731, loss -1714.17, acc 0.78125\n",
      "2017-09-12T00:29:16.634670: step 4732, loss -11755.7, acc 0.9375\n",
      "2017-09-12T00:29:16.775287: step 4733, loss -1908.57, acc 0.84375\n",
      "2017-09-12T00:29:16.824864: step 4734, loss -7411.04, acc 1\n",
      "2017-09-12T00:29:16.975865: step 4735, loss -5982.69, acc 0.90625\n",
      "2017-09-12T00:29:17.122844: step 4736, loss -5121.45, acc 0.9375\n",
      "2017-09-12T00:29:17.252859: step 4737, loss -6432.1, acc 0.90625\n",
      "2017-09-12T00:29:17.395678: step 4738, loss -1718.42, acc 0.9375\n",
      "2017-09-12T00:29:17.546117: step 4739, loss -5694.35, acc 0.96875\n",
      "2017-09-12T00:29:17.687783: step 4740, loss -13552.1, acc 0.9375\n",
      "2017-09-12T00:29:17.839976: step 4741, loss -2995.36, acc 0.84375\n",
      "2017-09-12T00:29:17.982153: step 4742, loss -1160.76, acc 0.84375\n",
      "2017-09-12T00:29:18.127567: step 4743, loss -11287.5, acc 0.96875\n",
      "2017-09-12T00:29:18.267700: step 4744, loss -492.945, acc 0.90625\n",
      "2017-09-12T00:29:18.411646: step 4745, loss -3167.25, acc 0.875\n",
      "2017-09-12T00:29:18.565779: step 4746, loss -15989.4, acc 1\n",
      "2017-09-12T00:29:18.704891: step 4747, loss -12916, acc 0.9375\n",
      "2017-09-12T00:29:18.860953: step 4748, loss -2584.66, acc 0.90625\n",
      "2017-09-12T00:29:18.988261: step 4749, loss -7802.23, acc 0.96875\n",
      "2017-09-12T00:29:19.137643: step 4750, loss -9132.84, acc 0.9375\n",
      "2017-09-12T00:29:19.284381: step 4751, loss -3561.85, acc 0.90625\n",
      "2017-09-12T00:29:19.425270: step 4752, loss -2097.5, acc 0.90625\n",
      "2017-09-12T00:29:19.585649: step 4753, loss -9561.44, acc 0.9375\n",
      "2017-09-12T00:29:19.733128: step 4754, loss 730.635, acc 0.84375\n",
      "2017-09-12T00:29:19.879157: step 4755, loss -3182.77, acc 0.96875\n",
      "2017-09-12T00:29:20.016088: step 4756, loss -4830.36, acc 0.90625\n",
      "2017-09-12T00:29:20.164503: step 4757, loss -2541.49, acc 0.90625\n",
      "2017-09-12T00:29:20.315508: step 4758, loss -6188.18, acc 0.9375\n",
      "2017-09-12T00:29:20.462768: step 4759, loss -3343.05, acc 0.9375\n",
      "2017-09-12T00:29:20.613246: step 4760, loss 60.2251, acc 0.9375\n",
      "2017-09-12T00:29:20.751272: step 4761, loss 33.729, acc 0.96875\n",
      "2017-09-12T00:29:20.890026: step 4762, loss -575.785, acc 0.875\n",
      "2017-09-12T00:29:21.039595: step 4763, loss -12755.5, acc 0.96875\n",
      "2017-09-12T00:29:21.179643: step 4764, loss -3339.69, acc 0.875\n",
      "2017-09-12T00:29:21.324956: step 4765, loss -905.46, acc 0.875\n",
      "2017-09-12T00:29:21.484390: step 4766, loss -3326.02, acc 0.90625\n",
      "2017-09-12T00:29:21.621442: step 4767, loss -6447.92, acc 0.96875\n",
      "2017-09-12T00:29:21.763903: step 4768, loss -10490.7, acc 1\n",
      "2017-09-12T00:29:21.904701: step 4769, loss -1492.97, acc 0.875\n",
      "2017-09-12T00:29:22.052266: step 4770, loss -9187.44, acc 1\n",
      "2017-09-12T00:29:22.208192: step 4771, loss -6445.66, acc 0.9375\n",
      "2017-09-12T00:29:22.350100: step 4772, loss -3403.34, acc 0.9375\n",
      "2017-09-12T00:29:22.501716: step 4773, loss -1597.77, acc 0.9375\n",
      "2017-09-12T00:29:22.649392: step 4774, loss -10856.5, acc 1\n",
      "2017-09-12T00:29:22.793353: step 4775, loss -3561.85, acc 0.90625\n",
      "2017-09-12T00:29:22.946595: step 4776, loss -1666.12, acc 0.90625\n",
      "2017-09-12T00:29:23.106334: step 4777, loss -6080.3, acc 0.90625\n",
      "2017-09-12T00:29:23.249688: step 4778, loss -3273.62, acc 0.9375\n",
      "2017-09-12T00:29:23.391178: step 4779, loss -3161.62, acc 0.9375\n",
      "2017-09-12T00:29:23.546284: step 4780, loss -2943.54, acc 0.8125\n",
      "2017-09-12T00:29:23.688655: step 4781, loss -4460.18, acc 0.96875\n",
      "2017-09-12T00:29:23.836956: step 4782, loss -1925.75, acc 0.90625\n",
      "2017-09-12T00:29:23.985323: step 4783, loss -14138.1, acc 0.96875\n",
      "2017-09-12T00:29:24.133800: step 4784, loss -9051.99, acc 0.96875\n",
      "2017-09-12T00:29:24.270850: step 4785, loss -5345.97, acc 0.90625\n",
      "2017-09-12T00:29:24.422086: step 4786, loss -8120.46, acc 0.90625\n",
      "2017-09-12T00:29:24.558438: step 4787, loss -6522.54, acc 1\n",
      "2017-09-12T00:29:24.703291: step 4788, loss -13006.1, acc 1\n",
      "2017-09-12T00:29:24.845839: step 4789, loss -10708.3, acc 0.96875\n",
      "2017-09-12T00:29:24.994239: step 4790, loss -6491.98, acc 0.96875\n",
      "2017-09-12T00:29:25.134325: step 4791, loss -8220.16, acc 0.9375\n",
      "2017-09-12T00:29:25.289972: step 4792, loss -4837.82, acc 0.96875\n",
      "2017-09-12T00:29:25.437710: step 4793, loss -3387.95, acc 0.96875\n",
      "2017-09-12T00:29:25.590272: step 4794, loss -9966.92, acc 0.9375\n",
      "2017-09-12T00:29:25.734908: step 4795, loss -4772.83, acc 0.9375\n",
      "2017-09-12T00:29:25.872413: step 4796, loss -8430.41, acc 0.9375\n",
      "2017-09-12T00:29:26.026356: step 4797, loss -4232.95, acc 0.96875\n",
      "2017-09-12T00:29:26.173179: step 4798, loss 4698.24, acc 0.90625\n",
      "2017-09-12T00:29:26.317088: step 4799, loss -5174.35, acc 0.875\n",
      "2017-09-12T00:29:26.487880: step 4800, loss -2022.69, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:29:28.042983: step 4800, loss -6412.54, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4800\n",
      "\n",
      "2017-09-12T00:29:29.945754: step 4801, loss -5070.07, acc 0.90625\n",
      "2017-09-12T00:29:30.038459: step 4802, loss -900.71, acc 0.8125\n",
      "2017-09-12T00:29:30.137809: step 4803, loss 1432.63, acc 0.84375\n",
      "2017-09-12T00:29:30.235878: step 4804, loss 3011.11, acc 0.90625\n",
      "2017-09-12T00:29:30.331992: step 4805, loss 5070.58, acc 0.78125\n",
      "2017-09-12T00:29:30.425273: step 4806, loss -1509.55, acc 0.90625\n",
      "2017-09-12T00:29:30.520911: step 4807, loss -4917.52, acc 0.90625\n",
      "2017-09-12T00:29:30.605656: step 4808, loss -6590.87, acc 0.90625\n",
      "2017-09-12T00:29:30.698577: step 4809, loss -2157.14, acc 0.90625\n",
      "2017-09-12T00:29:30.789413: step 4810, loss 966.405, acc 0.875\n",
      "2017-09-12T00:29:30.877582: step 4811, loss -285.98, acc 0.9375\n",
      "2017-09-12T00:29:30.970940: step 4812, loss 770.354, acc 0.875\n",
      "2017-09-12T00:29:31.066169: step 4813, loss -1608.98, acc 0.875\n",
      "2017-09-12T00:29:31.154540: step 4814, loss -9631.46, acc 0.9375\n",
      "2017-09-12T00:29:31.250967: step 4815, loss -1962.3, acc 0.9375\n",
      "2017-09-12T00:29:31.339425: step 4816, loss -6335.33, acc 1\n",
      "2017-09-12T00:29:31.431675: step 4817, loss -6156.9, acc 0.9375\n",
      "2017-09-12T00:29:31.522071: step 4818, loss -11525.4, acc 0.9375\n",
      "2017-09-12T00:29:31.747925: step 4819, loss -8168.85, acc 0.9375\n",
      "2017-09-12T00:29:31.905182: step 4820, loss -7919.32, acc 0.875\n",
      "2017-09-12T00:29:32.049488: step 4821, loss -5972, acc 0.90625\n",
      "2017-09-12T00:29:32.206467: step 4822, loss -3185.41, acc 0.9375\n",
      "2017-09-12T00:29:32.365335: step 4823, loss -3856.29, acc 0.90625\n",
      "2017-09-12T00:29:32.515698: step 4824, loss -11966.9, acc 0.96875\n",
      "2017-09-12T00:29:32.657795: step 4825, loss -4882.45, acc 0.9375\n",
      "2017-09-12T00:29:32.832191: step 4826, loss -5504.49, acc 0.9375\n",
      "2017-09-12T00:29:32.981986: step 4827, loss -1516.65, acc 0.90625\n",
      "2017-09-12T00:29:33.131039: step 4828, loss -1820.53, acc 0.9375\n",
      "2017-09-12T00:29:33.265399: step 4829, loss -8510.87, acc 0.9375\n",
      "2017-09-12T00:29:33.406263: step 4830, loss -6771.89, acc 0.96875\n",
      "2017-09-12T00:29:33.556936: step 4831, loss -6404.27, acc 0.9375\n",
      "2017-09-12T00:29:33.688470: step 4832, loss -8333.36, acc 0.90625\n",
      "2017-09-12T00:29:33.841955: step 4833, loss -8168.87, acc 0.96875\n",
      "2017-09-12T00:29:33.982223: step 4834, loss -557.652, acc 0.875\n",
      "2017-09-12T00:29:34.135128: step 4835, loss -2182.39, acc 0.875\n",
      "2017-09-12T00:29:34.288367: step 4836, loss 232.281, acc 0.875\n",
      "2017-09-12T00:29:34.441346: step 4837, loss -539.522, acc 0.84375\n",
      "2017-09-12T00:29:34.582185: step 4838, loss -6825.71, acc 0.90625\n",
      "2017-09-12T00:29:34.731442: step 4839, loss -6311.53, acc 1\n",
      "2017-09-12T00:29:34.882179: step 4840, loss -5973.88, acc 0.9375\n",
      "2017-09-12T00:29:35.043066: step 4841, loss -8140.7, acc 0.9375\n",
      "2017-09-12T00:29:35.176244: step 4842, loss -7030.03, acc 0.9375\n",
      "2017-09-12T00:29:35.326972: step 4843, loss -7898.69, acc 0.96875\n",
      "2017-09-12T00:29:35.479601: step 4844, loss -11906.5, acc 0.96875\n",
      "2017-09-12T00:29:35.628192: step 4845, loss -1739.89, acc 0.90625\n",
      "2017-09-12T00:29:35.783329: step 4846, loss -6494.42, acc 0.90625\n",
      "2017-09-12T00:29:35.932986: step 4847, loss -3219.22, acc 1\n",
      "2017-09-12T00:29:36.084676: step 4848, loss -2094.33, acc 0.84375\n",
      "2017-09-12T00:29:36.238895: step 4849, loss 1449.03, acc 0.90625\n",
      "2017-09-12T00:29:36.379371: step 4850, loss -3099.64, acc 1\n",
      "2017-09-12T00:29:36.533465: step 4851, loss -2307.55, acc 0.84375\n",
      "2017-09-12T00:29:36.693540: step 4852, loss -9848.39, acc 0.9375\n",
      "2017-09-12T00:29:36.835208: step 4853, loss -3462.88, acc 0.9375\n",
      "2017-09-12T00:29:37.045332: step 4854, loss -8428.06, acc 0.90625\n",
      "2017-09-12T00:29:37.222120: step 4855, loss -1718.72, acc 0.90625\n",
      "2017-09-12T00:29:37.369097: step 4856, loss -13502.4, acc 0.96875\n",
      "2017-09-12T00:29:37.524091: step 4857, loss -6443.96, acc 0.9375\n",
      "2017-09-12T00:29:37.671505: step 4858, loss -3259.79, acc 0.90625\n",
      "2017-09-12T00:29:37.834354: step 4859, loss -6541.19, acc 0.96875\n",
      "2017-09-12T00:29:37.972280: step 4860, loss -8121.17, acc 1\n",
      "2017-09-12T00:29:38.124895: step 4861, loss -4894.05, acc 0.9375\n",
      "2017-09-12T00:29:38.269367: step 4862, loss -12894.9, acc 0.96875\n",
      "2017-09-12T00:29:38.423910: step 4863, loss -9494.59, acc 0.96875\n",
      "2017-09-12T00:29:38.576941: step 4864, loss -3756.38, acc 0.96875\n",
      "2017-09-12T00:29:38.726159: step 4865, loss -740.047, acc 0.84375\n",
      "2017-09-12T00:29:38.882303: step 4866, loss -6789.2, acc 0.9375\n",
      "2017-09-12T00:29:39.031052: step 4867, loss -3960.15, acc 0.875\n",
      "2017-09-12T00:29:39.179390: step 4868, loss 95.1398, acc 0.90625\n",
      "2017-09-12T00:29:39.332153: step 4869, loss -6947.94, acc 0.9375\n",
      "2017-09-12T00:29:39.486841: step 4870, loss -12223.3, acc 0.90625\n",
      "2017-09-12T00:29:39.649024: step 4871, loss -10833.3, acc 0.96875\n",
      "2017-09-12T00:29:39.792117: step 4872, loss -2305.3, acc 0.84375\n",
      "2017-09-12T00:29:39.939399: step 4873, loss -4407.89, acc 0.84375\n",
      "2017-09-12T00:29:40.145611: step 4874, loss -3077.19, acc 0.90625\n",
      "2017-09-12T00:29:40.334701: step 4875, loss -7397.75, acc 0.875\n",
      "2017-09-12T00:29:40.492099: step 4876, loss -3897.59, acc 0.96875\n",
      "2017-09-12T00:29:40.655572: step 4877, loss -12096.6, acc 0.96875\n",
      "2017-09-12T00:29:40.831419: step 4878, loss -2168.58, acc 0.9375\n",
      "2017-09-12T00:29:40.968232: step 4879, loss -8884.3, acc 0.9375\n",
      "2017-09-12T00:29:41.118264: step 4880, loss -368.238, acc 0.9375\n",
      "2017-09-12T00:29:41.258098: step 4881, loss -1891.74, acc 0.875\n",
      "2017-09-12T00:29:41.400518: step 4882, loss -8326.22, acc 0.96875\n",
      "2017-09-12T00:29:41.560811: step 4883, loss -3060.69, acc 0.9375\n",
      "2017-09-12T00:29:41.708664: step 4884, loss -11336, acc 0.96875\n",
      "2017-09-12T00:29:41.924699: step 4885, loss -4853.75, acc 0.90625\n",
      "2017-09-12T00:29:42.080776: step 4886, loss -1885.47, acc 0.875\n",
      "2017-09-12T00:29:42.228328: step 4887, loss -50.9628, acc 0.90625\n",
      "2017-09-12T00:29:42.377986: step 4888, loss -6975.02, acc 0.9375\n",
      "2017-09-12T00:29:42.557924: step 4889, loss -13075.6, acc 1\n",
      "2017-09-12T00:29:42.703008: step 4890, loss -18139.8, acc 1\n",
      "2017-09-12T00:29:42.850055: step 4891, loss -15557.4, acc 0.96875\n",
      "2017-09-12T00:29:42.993961: step 4892, loss -3188.29, acc 0.84375\n",
      "2017-09-12T00:29:43.150149: step 4893, loss -10381.7, acc 0.96875\n",
      "2017-09-12T00:29:43.315657: step 4894, loss -11224.4, acc 1\n",
      "2017-09-12T00:29:43.500808: step 4895, loss -2114.64, acc 0.9375\n",
      "2017-09-12T00:29:43.652777: step 4896, loss -13637.2, acc 0.96875\n",
      "2017-09-12T00:29:43.788276: step 4897, loss -5324.64, acc 0.875\n",
      "2017-09-12T00:29:43.970396: step 4898, loss -5253.98, acc 0.875\n",
      "2017-09-12T00:29:44.125100: step 4899, loss -1743.51, acc 0.90625\n",
      "2017-09-12T00:29:44.253597: step 4900, loss 6248.67, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:29:45.542763: step 4900, loss -6709.9, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-4900\n",
      "\n",
      "2017-09-12T00:29:47.533961: step 4901, loss -3879.54, acc 0.9375\n",
      "2017-09-12T00:29:47.641484: step 4902, loss -5192.36, acc 0.96875\n",
      "2017-09-12T00:29:47.734915: step 4903, loss -6680.94, acc 0.96875\n",
      "2017-09-12T00:29:47.826340: step 4904, loss -11764.2, acc 0.90625\n",
      "2017-09-12T00:29:47.943374: step 4905, loss -10259.2, acc 0.96875\n",
      "2017-09-12T00:29:48.038329: step 4906, loss -8673.11, acc 0.96875\n",
      "2017-09-12T00:29:48.137618: step 4907, loss -9126, acc 0.9375\n",
      "2017-09-12T00:29:48.230266: step 4908, loss -10250, acc 0.96875\n",
      "2017-09-12T00:29:48.325140: step 4909, loss -10160, acc 0.96875\n",
      "2017-09-12T00:29:48.418553: step 4910, loss -6543.25, acc 0.90625\n",
      "2017-09-12T00:29:48.510559: step 4911, loss 2780.21, acc 0.8125\n",
      "2017-09-12T00:29:48.633663: step 4912, loss -7906.82, acc 0.96875\n",
      "2017-09-12T00:29:48.756778: step 4913, loss 1361.18, acc 0.9375\n",
      "2017-09-12T00:29:48.849812: step 4914, loss -563.823, acc 0.90625\n",
      "2017-09-12T00:29:48.944606: step 4915, loss -448.776, acc 0.875\n",
      "2017-09-12T00:29:49.039192: step 4916, loss -15510.6, acc 0.9375\n",
      "2017-09-12T00:29:49.134465: step 4917, loss -7280.3, acc 0.84375\n",
      "2017-09-12T00:29:49.229366: step 4918, loss -8309.67, acc 0.96875\n",
      "2017-09-12T00:29:49.479665: step 4919, loss -9693.82, acc 0.9375\n",
      "2017-09-12T00:29:49.639994: step 4920, loss -3647.03, acc 0.96875\n",
      "2017-09-12T00:29:49.791847: step 4921, loss -1823.42, acc 0.9375\n",
      "2017-09-12T00:29:49.932210: step 4922, loss -15371.8, acc 1\n",
      "2017-09-12T00:29:50.099598: step 4923, loss 4834.34, acc 0.84375\n",
      "2017-09-12T00:29:50.243140: step 4924, loss -3869.01, acc 0.9375\n",
      "2017-09-12T00:29:50.412566: step 4925, loss 3437.87, acc 0.90625\n",
      "2017-09-12T00:29:50.665339: step 4926, loss -11842.4, acc 0.9375\n",
      "2017-09-12T00:29:50.786981: step 4927, loss -6391.33, acc 0.9375\n",
      "2017-09-12T00:29:50.933629: step 4928, loss -5177.05, acc 0.875\n",
      "2017-09-12T00:29:51.123652: step 4929, loss -12232.1, acc 0.90625\n",
      "2017-09-12T00:29:51.260187: step 4930, loss -3465.88, acc 0.875\n",
      "2017-09-12T00:29:51.432908: step 4931, loss -8481.15, acc 0.9375\n",
      "2017-09-12T00:29:51.597800: step 4932, loss -10797.3, acc 1\n",
      "2017-09-12T00:29:51.741030: step 4933, loss -6659, acc 0.9375\n",
      "2017-09-12T00:29:51.918081: step 4934, loss -12072.5, acc 0.96875\n",
      "2017-09-12T00:29:52.065954: step 4935, loss -3138.5, acc 0.90625\n",
      "2017-09-12T00:29:52.242001: step 4936, loss -4165.22, acc 0.90625\n",
      "2017-09-12T00:29:52.481387: step 4937, loss -2388.04, acc 0.90625\n",
      "2017-09-12T00:29:52.658320: step 4938, loss -8270.18, acc 0.90625\n",
      "2017-09-12T00:29:52.957918: step 4939, loss -7112.32, acc 0.90625\n",
      "2017-09-12T00:29:53.241320: step 4940, loss -17711.4, acc 1\n",
      "2017-09-12T00:29:53.403301: step 4941, loss -28.7677, acc 0.875\n",
      "2017-09-12T00:29:53.560905: step 4942, loss 2849.76, acc 0.84375\n",
      "2017-09-12T00:29:53.711103: step 4943, loss -10851.5, acc 0.90625\n",
      "2017-09-12T00:29:53.890873: step 4944, loss -4075.25, acc 0.84375\n",
      "2017-09-12T00:29:54.033121: step 4945, loss -10625.7, acc 0.96875\n",
      "2017-09-12T00:29:54.218304: step 4946, loss -3101.1, acc 0.96875\n",
      "2017-09-12T00:29:54.403823: step 4947, loss -1790.88, acc 0.84375\n",
      "2017-09-12T00:29:54.567413: step 4948, loss -8019.23, acc 1\n",
      "2017-09-12T00:29:54.724772: step 4949, loss -7386.32, acc 0.90625\n",
      "2017-09-12T00:29:54.882740: step 4950, loss -10253.2, acc 0.9375\n",
      "2017-09-12T00:29:55.045599: step 4951, loss -6707.41, acc 0.9375\n",
      "2017-09-12T00:29:55.230489: step 4952, loss -10148.7, acc 0.9375\n",
      "2017-09-12T00:29:55.410163: step 4953, loss -8646.15, acc 0.90625\n",
      "2017-09-12T00:29:55.581734: step 4954, loss -4461.19, acc 0.90625\n",
      "2017-09-12T00:29:55.780958: step 4955, loss -9154.51, acc 0.9375\n",
      "2017-09-12T00:29:55.917244: step 4956, loss -12735.1, acc 0.9375\n",
      "2017-09-12T00:29:56.190167: step 4957, loss -5194.78, acc 0.90625\n",
      "2017-09-12T00:29:56.353296: step 4958, loss -14966.7, acc 0.96875\n",
      "2017-09-12T00:29:56.526687: step 4959, loss -9571.06, acc 0.9375\n",
      "2017-09-12T00:29:56.737725: step 4960, loss -5325.46, acc 0.90625\n",
      "2017-09-12T00:29:56.880159: step 4961, loss 5974.18, acc 0.84375\n",
      "2017-09-12T00:29:57.021939: step 4962, loss -6812, acc 0.9375\n",
      "2017-09-12T00:29:57.185951: step 4963, loss -19598.3, acc 0.96875\n",
      "2017-09-12T00:29:57.354990: step 4964, loss -5736.18, acc 0.90625\n",
      "2017-09-12T00:29:57.519700: step 4965, loss -7721.51, acc 0.90625\n",
      "2017-09-12T00:29:57.673018: step 4966, loss -16047.6, acc 0.96875\n",
      "2017-09-12T00:29:57.834266: step 4967, loss -10113.4, acc 1\n",
      "2017-09-12T00:29:57.986918: step 4968, loss -3573.84, acc 0.90625\n",
      "2017-09-12T00:29:58.142677: step 4969, loss 829.788, acc 0.8125\n",
      "2017-09-12T00:29:58.309866: step 4970, loss -4809.44, acc 0.9375\n",
      "2017-09-12T00:29:58.472883: step 4971, loss 3.15723, acc 0.8125\n",
      "2017-09-12T00:29:58.677581: step 4972, loss -6463.49, acc 0.84375\n",
      "2017-09-12T00:29:58.851790: step 4973, loss -7314.01, acc 0.9375\n",
      "2017-09-12T00:29:59.019577: step 4974, loss -14149.9, acc 1\n",
      "2017-09-12T00:29:59.202823: step 4975, loss -11315.6, acc 0.9375\n",
      "2017-09-12T00:29:59.345415: step 4976, loss -6854.73, acc 0.96875\n",
      "2017-09-12T00:29:59.491973: step 4977, loss -0.526367, acc 0.9375\n",
      "2017-09-12T00:29:59.631847: step 4978, loss -8972.9, acc 0.90625\n",
      "2017-09-12T00:29:59.781051: step 4979, loss -1632.12, acc 0.9375\n",
      "2017-09-12T00:29:59.923417: step 4980, loss -8819.28, acc 0.9375\n",
      "2017-09-12T00:30:00.073794: step 4981, loss -9969.21, acc 1\n",
      "2017-09-12T00:30:00.211484: step 4982, loss -8447.71, acc 0.90625\n",
      "2017-09-12T00:30:00.360105: step 4983, loss -3806.07, acc 0.9375\n",
      "2017-09-12T00:30:00.495120: step 4984, loss -4190.64, acc 0.9375\n",
      "2017-09-12T00:30:00.641630: step 4985, loss 736.317, acc 0.875\n",
      "2017-09-12T00:30:00.785302: step 4986, loss -3867.26, acc 0.9375\n",
      "2017-09-12T00:30:00.949747: step 4987, loss -11495.1, acc 0.9375\n",
      "2017-09-12T00:30:01.146971: step 4988, loss -5248.78, acc 1\n",
      "2017-09-12T00:30:01.265115: step 4989, loss -15950.1, acc 0.96875\n",
      "2017-09-12T00:30:01.401889: step 4990, loss -10530.1, acc 0.90625\n",
      "2017-09-12T00:30:01.549233: step 4991, loss -1790.34, acc 0.96875\n",
      "2017-09-12T00:30:01.679343: step 4992, loss 1208.52, acc 0.875\n",
      "2017-09-12T00:30:01.821408: step 4993, loss -4456.43, acc 0.875\n",
      "2017-09-12T00:30:01.960341: step 4994, loss -9233.74, acc 0.96875\n",
      "2017-09-12T00:30:02.121317: step 4995, loss -15411.6, acc 0.96875\n",
      "2017-09-12T00:30:02.289413: step 4996, loss -5223.47, acc 0.875\n",
      "2017-09-12T00:30:02.343893: step 4997, loss -7504.25, acc 0.875\n",
      "2017-09-12T00:30:02.470763: step 4998, loss -2428.61, acc 0.90625\n",
      "2017-09-12T00:30:02.618989: step 4999, loss -2226.57, acc 0.90625\n",
      "2017-09-12T00:30:02.811148: step 5000, loss -10463.6, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:30:04.112879: step 5000, loss -7076.46, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-5000\n",
      "\n",
      "2017-09-12T00:30:05.708426: step 5001, loss 1890.18, acc 0.8125\n",
      "2017-09-12T00:30:05.798670: step 5002, loss -6909.38, acc 0.96875\n",
      "2017-09-12T00:30:05.892111: step 5003, loss -11149.3, acc 0.96875\n",
      "2017-09-12T00:30:06.010630: step 5004, loss -2424.75, acc 0.9375\n",
      "2017-09-12T00:30:06.127829: step 5005, loss -3985.73, acc 0.875\n",
      "2017-09-12T00:30:06.218416: step 5006, loss -3625.73, acc 0.90625\n",
      "2017-09-12T00:30:06.304555: step 5007, loss 6775.15, acc 0.8125\n",
      "2017-09-12T00:30:06.387189: step 5008, loss -7164.39, acc 0.90625\n",
      "2017-09-12T00:30:06.472549: step 5009, loss -2335.58, acc 0.875\n",
      "2017-09-12T00:30:06.560947: step 5010, loss -3082.17, acc 0.96875\n",
      "2017-09-12T00:30:06.649275: step 5011, loss -69.2604, acc 0.96875\n",
      "2017-09-12T00:30:06.738626: step 5012, loss -6079.61, acc 0.96875\n",
      "2017-09-12T00:30:06.826901: step 5013, loss 3050.38, acc 0.875\n",
      "2017-09-12T00:30:06.920936: step 5014, loss -9931.93, acc 0.96875\n",
      "2017-09-12T00:30:07.027505: step 5015, loss -15183.4, acc 0.9375\n",
      "2017-09-12T00:30:07.117551: step 5016, loss -1772.02, acc 0.9375\n",
      "2017-09-12T00:30:07.208546: step 5017, loss -9428.14, acc 0.90625\n",
      "2017-09-12T00:30:07.326018: step 5018, loss -8906.71, acc 0.96875\n",
      "2017-09-12T00:30:07.507308: step 5019, loss -8349.45, acc 0.90625\n",
      "2017-09-12T00:30:07.730295: step 5020, loss -5230.18, acc 0.90625\n",
      "2017-09-12T00:30:07.912314: step 5021, loss -7275.95, acc 0.9375\n",
      "2017-09-12T00:30:08.063537: step 5022, loss -5615.42, acc 0.9375\n",
      "2017-09-12T00:30:08.244666: step 5023, loss -8849.66, acc 0.9375\n",
      "2017-09-12T00:30:08.415695: step 5024, loss -5029.83, acc 0.96875\n",
      "2017-09-12T00:30:08.599363: step 5025, loss -9344.5, acc 0.9375\n",
      "2017-09-12T00:30:08.762475: step 5026, loss -3813.98, acc 0.875\n",
      "2017-09-12T00:30:08.940913: step 5027, loss -6860.82, acc 0.96875\n",
      "2017-09-12T00:30:09.080766: step 5028, loss -3508.54, acc 0.875\n",
      "2017-09-12T00:30:09.228420: step 5029, loss -8109.87, acc 0.84375\n",
      "2017-09-12T00:30:09.375188: step 5030, loss -5547.37, acc 0.90625\n",
      "2017-09-12T00:30:09.513136: step 5031, loss -7761.41, acc 0.9375\n",
      "2017-09-12T00:30:09.660288: step 5032, loss -7525.7, acc 0.875\n",
      "2017-09-12T00:30:09.786202: step 5033, loss -8756.78, acc 0.96875\n",
      "2017-09-12T00:30:09.928426: step 5034, loss -7097.06, acc 1\n",
      "2017-09-12T00:30:10.072304: step 5035, loss -3827.96, acc 0.90625\n",
      "2017-09-12T00:30:10.208249: step 5036, loss -8041.55, acc 0.9375\n",
      "2017-09-12T00:30:10.356960: step 5037, loss -8826.95, acc 1\n",
      "2017-09-12T00:30:10.497553: step 5038, loss 5046.67, acc 0.84375\n",
      "2017-09-12T00:30:10.633202: step 5039, loss -5023.47, acc 0.9375\n",
      "2017-09-12T00:30:10.767847: step 5040, loss -7657.66, acc 0.875\n",
      "2017-09-12T00:30:10.911384: step 5041, loss -7684.58, acc 0.9375\n",
      "2017-09-12T00:30:11.059248: step 5042, loss -3799.03, acc 0.96875\n",
      "2017-09-12T00:30:11.193336: step 5043, loss -7268.78, acc 0.9375\n",
      "2017-09-12T00:30:11.333613: step 5044, loss -14888.9, acc 0.96875\n",
      "2017-09-12T00:30:11.471541: step 5045, loss -7110.57, acc 0.90625\n",
      "2017-09-12T00:30:11.617435: step 5046, loss -5646.7, acc 0.96875\n",
      "2017-09-12T00:30:11.763889: step 5047, loss -3733.88, acc 0.875\n",
      "2017-09-12T00:30:11.906484: step 5048, loss -6209.79, acc 0.9375\n",
      "2017-09-12T00:30:12.043595: step 5049, loss -9402.05, acc 1\n",
      "2017-09-12T00:30:12.186046: step 5050, loss -13368.3, acc 0.96875\n",
      "2017-09-12T00:30:12.321518: step 5051, loss 1620.63, acc 0.90625\n",
      "2017-09-12T00:30:12.484427: step 5052, loss 2542.94, acc 0.84375\n",
      "2017-09-12T00:30:12.649865: step 5053, loss -11052.4, acc 0.96875\n",
      "2017-09-12T00:30:12.788140: step 5054, loss -10954.7, acc 0.96875\n",
      "2017-09-12T00:30:12.934405: step 5055, loss -2550.41, acc 0.84375\n",
      "2017-09-12T00:30:13.127437: step 5056, loss -9241.26, acc 0.96875\n",
      "2017-09-12T00:30:13.263710: step 5057, loss -924.705, acc 0.9375\n",
      "2017-09-12T00:30:13.424175: step 5058, loss -4510.54, acc 0.9375\n",
      "2017-09-12T00:30:13.571619: step 5059, loss 3560.63, acc 0.84375\n",
      "2017-09-12T00:30:13.753178: step 5060, loss -7210.77, acc 0.96875\n",
      "2017-09-12T00:30:13.912189: step 5061, loss -8167.99, acc 0.90625\n",
      "2017-09-12T00:30:14.073412: step 5062, loss -12881.1, acc 0.96875\n",
      "2017-09-12T00:30:14.258009: step 5063, loss -14685.3, acc 1\n",
      "2017-09-12T00:30:14.405313: step 5064, loss -4230.06, acc 0.90625\n",
      "2017-09-12T00:30:14.542151: step 5065, loss 1289.85, acc 0.875\n",
      "2017-09-12T00:30:14.683229: step 5066, loss 1787.81, acc 0.875\n",
      "2017-09-12T00:30:14.825839: step 5067, loss -4409.9, acc 0.84375\n",
      "2017-09-12T00:30:14.959836: step 5068, loss -635.151, acc 0.84375\n",
      "2017-09-12T00:30:15.104457: step 5069, loss -13956.6, acc 0.96875\n",
      "2017-09-12T00:30:15.254442: step 5070, loss -7760.2, acc 0.90625\n",
      "2017-09-12T00:30:15.402460: step 5071, loss -109.938, acc 0.84375\n",
      "2017-09-12T00:30:15.541938: step 5072, loss -2860.42, acc 0.875\n",
      "2017-09-12T00:30:15.696381: step 5073, loss -3558.3, acc 0.96875\n",
      "2017-09-12T00:30:15.832912: step 5074, loss -11459.8, acc 0.9375\n",
      "2017-09-12T00:30:15.974520: step 5075, loss -4135.99, acc 0.90625\n",
      "2017-09-12T00:30:16.132115: step 5076, loss -12750.7, acc 1\n",
      "2017-09-12T00:30:16.275084: step 5077, loss -6350.93, acc 0.9375\n",
      "2017-09-12T00:30:16.422172: step 5078, loss -13230.3, acc 0.9375\n",
      "2017-09-12T00:30:16.568900: step 5079, loss -7404.9, acc 0.96875\n",
      "2017-09-12T00:30:16.709331: step 5080, loss -18213.1, acc 1\n",
      "2017-09-12T00:30:16.859598: step 5081, loss -5411.25, acc 0.9375\n",
      "2017-09-12T00:30:16.998618: step 5082, loss -4201.86, acc 0.9375\n",
      "2017-09-12T00:30:17.156189: step 5083, loss -5448.95, acc 1\n",
      "2017-09-12T00:30:17.347459: step 5084, loss -4553.94, acc 0.875\n",
      "2017-09-12T00:30:17.490182: step 5085, loss -7848.08, acc 0.9375\n",
      "2017-09-12T00:30:17.629894: step 5086, loss -5567.38, acc 0.9375\n",
      "2017-09-12T00:30:17.811880: step 5087, loss -6746.73, acc 0.90625\n",
      "2017-09-12T00:30:17.997085: step 5088, loss -4341.49, acc 0.84375\n",
      "2017-09-12T00:30:18.185340: step 5089, loss 1576.91, acc 0.875\n",
      "2017-09-12T00:30:18.345109: step 5090, loss 1943.77, acc 0.875\n",
      "2017-09-12T00:30:18.490462: step 5091, loss -7135.98, acc 0.9375\n",
      "2017-09-12T00:30:18.675510: step 5092, loss -8363.48, acc 0.9375\n",
      "2017-09-12T00:30:18.823844: step 5093, loss -16300.4, acc 1\n",
      "2017-09-12T00:30:18.967872: step 5094, loss 1878.79, acc 0.90625\n",
      "2017-09-12T00:30:19.109438: step 5095, loss -3856.2, acc 1\n",
      "2017-09-12T00:30:19.244357: step 5096, loss -468.193, acc 0.875\n",
      "2017-09-12T00:30:19.403845: step 5097, loss -3903.44, acc 0.90625\n",
      "2017-09-12T00:30:19.561431: step 5098, loss -6117.87, acc 0.90625\n",
      "2017-09-12T00:30:19.692657: step 5099, loss 1182.23, acc 0.84375\n",
      "2017-09-12T00:30:19.834807: step 5100, loss -2422.08, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:30:21.114781: step 5100, loss -7394.83, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-5100\n",
      "\n",
      "2017-09-12T00:30:22.961902: step 5101, loss -6679.72, acc 1\n",
      "2017-09-12T00:30:23.080665: step 5102, loss -7746.41, acc 0.9375\n",
      "2017-09-12T00:30:23.183062: step 5103, loss -10212.5, acc 0.96875\n",
      "2017-09-12T00:30:23.279038: step 5104, loss -2858.3, acc 0.875\n",
      "2017-09-12T00:30:23.404508: step 5105, loss -14866.7, acc 0.90625\n",
      "2017-09-12T00:30:23.511200: step 5106, loss -6072.62, acc 0.90625\n",
      "2017-09-12T00:30:23.628627: step 5107, loss -15442.8, acc 0.96875\n",
      "2017-09-12T00:30:23.748394: step 5108, loss -7770.28, acc 0.9375\n",
      "2017-09-12T00:30:23.858480: step 5109, loss -13324.5, acc 0.9375\n",
      "2017-09-12T00:30:23.964945: step 5110, loss -6260.53, acc 0.875\n",
      "2017-09-12T00:30:24.062628: step 5111, loss -8843.72, acc 0.96875\n",
      "2017-09-12T00:30:24.157654: step 5112, loss -808.13, acc 0.84375\n",
      "2017-09-12T00:30:24.249852: step 5113, loss -554.391, acc 0.84375\n",
      "2017-09-12T00:30:24.346192: step 5114, loss -3734.76, acc 0.9375\n",
      "2017-09-12T00:30:24.448521: step 5115, loss -5775.49, acc 0.9375\n",
      "2017-09-12T00:30:24.592291: step 5116, loss -3261.35, acc 0.90625\n",
      "2017-09-12T00:30:24.687474: step 5117, loss -5880.71, acc 0.9375\n",
      "2017-09-12T00:30:24.773769: step 5118, loss -1663.68, acc 0.9375\n",
      "2017-09-12T00:30:24.861429: step 5119, loss -3241.91, acc 0.9375\n",
      "2017-09-12T00:30:25.103300: step 5120, loss -3984.93, acc 0.875\n",
      "2017-09-12T00:30:25.261718: step 5121, loss -19018.5, acc 1\n",
      "2017-09-12T00:30:25.385037: step 5122, loss -7540.98, acc 0.9375\n",
      "2017-09-12T00:30:25.523235: step 5123, loss 3852.49, acc 0.875\n",
      "2017-09-12T00:30:25.730413: step 5124, loss -11449.5, acc 0.90625\n",
      "2017-09-12T00:30:25.921878: step 5125, loss -8978.53, acc 0.90625\n",
      "2017-09-12T00:30:26.067493: step 5126, loss -3599.88, acc 0.96875\n",
      "2017-09-12T00:30:26.209616: step 5127, loss 1434.52, acc 0.84375\n",
      "2017-09-12T00:30:26.354451: step 5128, loss -9353.78, acc 0.90625\n",
      "2017-09-12T00:30:26.507911: step 5129, loss -10366.8, acc 0.9375\n",
      "2017-09-12T00:30:26.656842: step 5130, loss -16157, acc 0.96875\n",
      "2017-09-12T00:30:26.807738: step 5131, loss -12844.9, acc 0.96875\n",
      "2017-09-12T00:30:26.964490: step 5132, loss -13416.5, acc 1\n",
      "2017-09-12T00:30:27.101973: step 5133, loss -12869, acc 0.96875\n",
      "2017-09-12T00:30:27.262272: step 5134, loss -5133.61, acc 0.9375\n",
      "2017-09-12T00:30:27.396559: step 5135, loss -5827.41, acc 0.9375\n",
      "2017-09-12T00:30:27.560499: step 5136, loss -20540.1, acc 0.96875\n",
      "2017-09-12T00:30:27.699984: step 5137, loss -11191, acc 0.90625\n",
      "2017-09-12T00:30:27.863360: step 5138, loss -8278.37, acc 0.96875\n",
      "2017-09-12T00:30:27.987691: step 5139, loss 3629.09, acc 0.8125\n",
      "2017-09-12T00:30:28.135765: step 5140, loss -7756.16, acc 0.9375\n",
      "2017-09-12T00:30:28.274751: step 5141, loss -12923.8, acc 1\n",
      "2017-09-12T00:30:28.405274: step 5142, loss 5351.59, acc 0.90625\n",
      "2017-09-12T00:30:28.543590: step 5143, loss -15641.8, acc 0.90625\n",
      "2017-09-12T00:30:28.688833: step 5144, loss -7974.54, acc 0.9375\n",
      "2017-09-12T00:30:28.819635: step 5145, loss -8000.03, acc 0.96875\n",
      "2017-09-12T00:30:28.980772: step 5146, loss -14947.5, acc 0.9375\n",
      "2017-09-12T00:30:29.120626: step 5147, loss 298.158, acc 0.9375\n",
      "2017-09-12T00:30:29.279393: step 5148, loss 203.396, acc 0.90625\n",
      "2017-09-12T00:30:29.431671: step 5149, loss -12128.2, acc 0.875\n",
      "2017-09-12T00:30:29.556044: step 5150, loss 1330.55, acc 0.84375\n",
      "2017-09-12T00:30:29.700995: step 5151, loss -3912.61, acc 1\n",
      "2017-09-12T00:30:29.838878: step 5152, loss -4422.71, acc 0.90625\n",
      "2017-09-12T00:30:29.986862: step 5153, loss -11671.7, acc 0.875\n",
      "2017-09-12T00:30:30.149798: step 5154, loss -7900.5, acc 0.90625\n",
      "2017-09-12T00:30:30.325232: step 5155, loss -6111.41, acc 0.875\n",
      "2017-09-12T00:30:30.465206: step 5156, loss 1955.96, acc 0.90625\n",
      "2017-09-12T00:30:30.609394: step 5157, loss -11113.5, acc 0.96875\n",
      "2017-09-12T00:30:30.743760: step 5158, loss -8434.28, acc 0.96875\n",
      "2017-09-12T00:30:30.906511: step 5159, loss -7868.41, acc 0.9375\n",
      "2017-09-12T00:30:31.091637: step 5160, loss -6117.17, acc 0.9375\n",
      "2017-09-12T00:30:31.358702: step 5161, loss -2090.55, acc 0.875\n",
      "2017-09-12T00:30:31.548568: step 5162, loss -4289.51, acc 0.90625\n",
      "2017-09-12T00:30:31.937050: step 5163, loss -17166.9, acc 0.96875\n",
      "2017-09-12T00:30:32.217530: step 5164, loss -10277.9, acc 0.9375\n",
      "2017-09-12T00:30:32.516644: step 5165, loss -358.228, acc 0.90625\n",
      "2017-09-12T00:30:32.764775: step 5166, loss -10897.5, acc 0.9375\n",
      "2017-09-12T00:30:32.888497: step 5167, loss -3957, acc 0.90625\n",
      "2017-09-12T00:30:33.095525: step 5168, loss -14326.9, acc 0.9375\n",
      "2017-09-12T00:30:33.332442: step 5169, loss -4356.89, acc 0.90625\n",
      "2017-09-12T00:30:33.514390: step 5170, loss -9279.49, acc 0.9375\n",
      "2017-09-12T00:30:33.697093: step 5171, loss -9352.21, acc 0.96875\n",
      "2017-09-12T00:30:33.972755: step 5172, loss -13374.2, acc 0.9375\n",
      "2017-09-12T00:30:34.270233: step 5173, loss -7094.92, acc 0.9375\n",
      "2017-09-12T00:30:34.434514: step 5174, loss -3657.35, acc 0.90625\n",
      "2017-09-12T00:30:34.680083: step 5175, loss 5564.94, acc 0.84375\n",
      "2017-09-12T00:30:34.877357: step 5176, loss -7935.07, acc 0.90625\n",
      "2017-09-12T00:30:35.068356: step 5177, loss -13861, acc 1\n",
      "2017-09-12T00:30:35.349433: step 5178, loss -14323.2, acc 0.9375\n",
      "2017-09-12T00:30:35.529503: step 5179, loss -678.365, acc 0.90625\n",
      "2017-09-12T00:30:35.766746: step 5180, loss -2033.2, acc 0.96875\n",
      "2017-09-12T00:30:35.942567: step 5181, loss -8178.2, acc 1\n",
      "2017-09-12T00:30:36.137649: step 5182, loss -8396.83, acc 0.90625\n",
      "2017-09-12T00:30:36.285826: step 5183, loss -8830.47, acc 0.9375\n",
      "2017-09-12T00:30:36.459357: step 5184, loss 3324.33, acc 0.78125\n",
      "2017-09-12T00:30:36.642452: step 5185, loss -4106.04, acc 0.9375\n",
      "2017-09-12T00:30:36.840639: step 5186, loss 2039.1, acc 0.875\n",
      "2017-09-12T00:30:37.080309: step 5187, loss -9729.24, acc 0.96875\n",
      "2017-09-12T00:30:37.299270: step 5188, loss -911.311, acc 0.84375\n",
      "2017-09-12T00:30:37.567216: step 5189, loss -5921.02, acc 0.9375\n",
      "2017-09-12T00:30:37.752945: step 5190, loss -13120.6, acc 0.96875\n",
      "2017-09-12T00:30:37.921222: step 5191, loss -11460.4, acc 0.9375\n",
      "2017-09-12T00:30:38.129408: step 5192, loss -4073.18, acc 0.90625\n",
      "2017-09-12T00:30:38.305357: step 5193, loss -3794.61, acc 0.9375\n",
      "2017-09-12T00:30:38.444255: step 5194, loss -6531.44, acc 0.90625\n",
      "2017-09-12T00:30:38.591671: step 5195, loss -7192.75, acc 0.875\n",
      "2017-09-12T00:30:38.738160: step 5196, loss -4358.7, acc 0.875\n",
      "2017-09-12T00:30:38.874419: step 5197, loss -4084.61, acc 0.90625\n",
      "2017-09-12T00:30:39.011074: step 5198, loss -15025.3, acc 0.96875\n",
      "2017-09-12T00:30:39.203025: step 5199, loss -2550.47, acc 0.875\n",
      "2017-09-12T00:30:39.415105: step 5200, loss -25450.2, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-09-12T00:30:40.837678: step 5200, loss -7756.8, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/helenahuddy/CNN/runs/1505154151/checkpoints/model-5200\n",
      "\n",
      "2017-09-12T00:30:43.080268: step 5201, loss -6999.26, acc 0.9375\n",
      "2017-09-12T00:30:43.191644: step 5202, loss -8357.53, acc 0.96875\n",
      "2017-09-12T00:30:43.297422: step 5203, loss -736.957, acc 0.875\n",
      "2017-09-12T00:30:43.401210: step 5204, loss -10328.7, acc 0.9375\n",
      "2017-09-12T00:30:43.490875: step 5205, loss -4972.34, acc 0.90625\n",
      "2017-09-12T00:30:43.581902: step 5206, loss 3602.69, acc 0.84375\n",
      "2017-09-12T00:30:43.690026: step 5207, loss -3636.68, acc 0.9375\n",
      "2017-09-12T00:30:43.780007: step 5208, loss -8532.62, acc 0.875\n",
      "2017-09-12T00:30:43.883702: step 5209, loss -4499.57, acc 0.90625\n",
      "2017-09-12T00:30:43.993610: step 5210, loss -2152.01, acc 0.90625\n",
      "2017-09-12T00:30:44.083860: step 5211, loss -8626.04, acc 0.96875\n",
      "2017-09-12T00:30:44.172981: step 5212, loss -8054.96, acc 0.96875\n",
      "2017-09-12T00:30:44.259845: step 5213, loss -10263, acc 0.96875\n",
      "2017-09-12T00:30:44.357051: step 5214, loss -11808.2, acc 1\n",
      "2017-09-12T00:30:44.457257: step 5215, loss -5885.08, acc 0.90625\n",
      "2017-09-12T00:30:44.545957: step 5216, loss -4238.2, acc 0.9375\n",
      "2017-09-12T00:30:44.637513: step 5217, loss -1594.97, acc 0.84375\n",
      "2017-09-12T00:30:44.725442: step 5218, loss -617.201, acc 0.90625\n",
      "2017-09-12T00:30:44.818010: step 5219, loss -7455.42, acc 0.96875\n",
      "2017-09-12T00:30:44.983525: step 5220, loss -11261, acc 0.96875\n",
      "2017-09-12T00:30:45.227723: step 5221, loss -8649.52, acc 0.90625\n",
      "2017-09-12T00:30:45.348816: step 5222, loss -11864.4, acc 0.96875\n",
      "2017-09-12T00:30:45.509210: step 5223, loss -6752.41, acc 0.90625\n",
      "2017-09-12T00:30:45.642939: step 5224, loss -4608.58, acc 0.84375\n",
      "2017-09-12T00:30:45.805792: step 5225, loss -18347, acc 0.96875\n",
      "2017-09-12T00:30:46.079433: step 5226, loss 1421.82, acc 0.875\n",
      "2017-09-12T00:30:46.253995: step 5227, loss -13890.3, acc 0.90625\n",
      "2017-09-12T00:30:46.396310: step 5228, loss -8008.12, acc 0.875\n",
      "2017-09-12T00:30:46.556737: step 5229, loss -1991.33, acc 0.9375\n",
      "2017-09-12T00:30:46.691603: step 5230, loss -659.469, acc 0.84375\n",
      "2017-09-12T00:30:46.827941: step 5231, loss -6520.07, acc 0.9375\n",
      "2017-09-12T00:30:46.969121: step 5232, loss -3940.11, acc 0.875\n",
      "2017-09-12T00:30:47.097752: step 5233, loss -13046.3, acc 1\n",
      "2017-09-12T00:30:47.238387: step 5234, loss -16112.7, acc 1\n",
      "2017-09-12T00:30:47.379492: step 5235, loss -10289.3, acc 0.9375\n",
      "2017-09-12T00:30:47.524118: step 5236, loss -11880.7, acc 0.96875\n",
      "2017-09-12T00:30:47.672967: step 5237, loss 13.4568, acc 0.875\n",
      "2017-09-12T00:30:47.823439: step 5238, loss -7941.87, acc 0.90625\n",
      "2017-09-12T00:30:47.962978: step 5239, loss -11342.1, acc 1\n",
      "2017-09-12T00:30:48.104506: step 5240, loss 3664.69, acc 0.84375\n",
      "2017-09-12T00:30:48.250163: step 5241, loss -11876.5, acc 1\n",
      "2017-09-12T00:30:48.395756: step 5242, loss -8778.48, acc 0.90625\n",
      "2017-09-12T00:30:48.537151: step 5243, loss -5798.33, acc 1\n",
      "2017-09-12T00:30:48.723553: step 5244, loss -12466.9, acc 0.90625\n",
      "2017-09-12T00:30:48.871506: step 5245, loss -8297.3, acc 0.90625\n",
      "2017-09-12T00:30:49.003575: step 5246, loss -4091.2, acc 0.875\n",
      "2017-09-12T00:30:49.199260: step 5247, loss -10321.8, acc 0.96875\n",
      "2017-09-12T00:30:49.392041: step 5248, loss -10432.3, acc 0.96875\n",
      "2017-09-12T00:30:49.537700: step 5249, loss -12501.9, acc 0.9375\n",
      "2017-09-12T00:30:49.669928: step 5250, loss -19016.6, acc 1\n",
      "2017-09-12T00:30:49.811466: step 5251, loss 1624.87, acc 0.90625\n",
      "2017-09-12T00:30:49.988894: step 5252, loss -6115.1, acc 0.8125\n",
      "2017-09-12T00:30:50.160517: step 5253, loss -10480.2, acc 0.9375\n",
      "2017-09-12T00:30:50.317586: step 5254, loss -9877.94, acc 0.96875\n",
      "2017-09-12T00:30:50.463222: step 5255, loss -7301.97, acc 0.96875\n",
      "2017-09-12T00:30:50.677393: step 5256, loss -14276, acc 1\n",
      "2017-09-12T00:30:50.840156: step 5257, loss -12425.8, acc 0.96875\n",
      "2017-09-12T00:30:51.023367: step 5258, loss -20946.5, acc 1\n",
      "2017-09-12T00:30:51.161545: step 5259, loss -346.985, acc 0.9375\n",
      "2017-09-12T00:30:51.210686: step 5260, loss -15076.9, acc 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        \n",
    "        cnn = TextCNN(\n",
    "            sequence_length=x_train.shape[1],\n",
    "            num_classes=2,\n",
    "            vocab_size=len(vocab_processor.vocabulary_),\n",
    "            embedding_size=FLAGS.embedding_dim,\n",
    "            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "            num_filters=FLAGS.num_filters)\n",
    "        \n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "        \n",
    "        \n",
    "        # Output directory for models and summaries\n",
    "        timestamp = str(int(time.time()))\n",
    "        out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "        print(\"Writing to {}\\n\".format(out_dir))\n",
    " \n",
    "        # Summaries for loss and accuracy\n",
    "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    " \n",
    "        # Train Summaries\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph_def)\n",
    " \n",
    "        # Dev summaries\n",
    "        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph_def)\n",
    "        \n",
    "        \n",
    "        # Checkpointing\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        # Tensorflow assumes this directory already exists so we need to create it\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        \n",
    "        \n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        \n",
    "        def train_step(x_batch, y_batch):\n",
    "            \"\"\"\n",
    "            A single training step\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "                cnn.input_x: x_batch,\n",
    "                cnn.input_y: y_batch,\n",
    "                cnn.dropout_keep_prob: FLAGS.dropout_keep_prob\n",
    "            }\n",
    "            _, step, summaries, loss, accuracy = sess.run(\n",
    "                [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "            \n",
    "            \n",
    "        def dev_step(x_batch, y_batch, writer=None):\n",
    "            \"\"\"\n",
    "            Evaluates model on a dev set\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run(\n",
    "                [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "                \n",
    "        # Generate batches\n",
    "        batches = batch_iter(\n",
    "            zip(x_train, y_train), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "        # Training loop. For each batch...\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = zip(*batch)\n",
    "            train_step(x_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            if current_step % FLAGS.evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                print(\"\")\n",
    "            if current_step % FLAGS.checkpoint_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "stemmer = Stemmer.Stemmer('russian')\n",
    "#stemmer.stemWord('ковриков')\n",
    "\n",
    "lists=[]\n",
    "for i in all_examples:\n",
    "    lists.append([stemmer.stemWord(word) for word in i.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train the model Word2Vec\n",
    "num_features = 300                  \n",
    "min_word_count = 40                          \n",
    "num_workers = 4       \n",
    "context = 10                                                                                             \n",
    "downsampling = 1e-3   \n",
    "\n",
    "\n",
    "model = word2vec.Word2Vec(lists, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ипотек', 0.9579096436500549),\n",
       " ('услов', 0.9547955989837646),\n",
       " ('кредитован', 0.9546328186988831),\n",
       " ('лиц', 0.952491044998169),\n",
       " ('автокред', 0.9520655274391174),\n",
       " ('отзыв', 0.9492961168289185),\n",
       " ('физическ', 0.9450693130493164),\n",
       " ('ипотечн', 0.9447919130325317),\n",
       " ('рассчита', 0.9425774812698364),\n",
       " ('оформлен', 0.9424964189529419)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('банк')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeVec(words, model, num_features):   \n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Обучить на куче файлов\n",
    "\"\"\"\"class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line.split()\n",
    " \n",
    "sentences = MySentences('123') # a memory-friendly iterator\n",
    "model2 = word2vec.Word2Vec(sentences)\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\"from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('web_russe.model.bin', binary=True) \n",
    "word_vectors.vocab\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_text=[makeVec(i,model, num_features) for i in all_examples]\n",
    "x_text=np.array(x_text)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
